<!DOCTYPE html>


<html theme="dark" showBanner="true" hasBanner="true" > 
<link href="https://cdn.staticfile.org/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet">
<link href="https://cdn.staticfile.org/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet">
<link href="https://cdn.staticfile.org/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet">
<script src="/js/color.global.min.js" ></script>
<script src="/js/load-settings.js" ></script>
<head>
  <meta charset="utf-8">
  
  
  

  
  <title>Datawhale-二分类任务 | Justin的技术博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="preload" href="/css/fonts/Roboto-Regular.ttf" as="font" type="font/ttf" crossorigin="anonymous">
  <link rel="preload" href="/css/fonts/Roboto-Bold.ttf" as="font" type="font/ttf" crossorigin="anonymous">

  <meta name="description" content="比赛简介「用户新增预测挑战赛」是由科大讯飞主办的一项数据科学竞赛，旨在通过机器学习方法预测用户是否为新增用户 比赛属于二分类任务，评价指标采用F1分数，分数越高表示模型性能越好。 如果你有一份带标签的表格型数据，只要目标是分类、回归或排序，那么 LightGBM 都是最强机器学习模型之一，默认首选。 赛题建模的价值用户新增预测是分析 用户使用场景 以及 预测用户增长情况 的关键步骤，有助于进行其后">
<meta property="og:type" content="article">
<meta property="og:title" content="Datawhale-二分类任务">
<meta property="og:url" content="https://jayli19707.github.io/2025/07/17/Datawhale-%E4%BA%8C%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1/index.html">
<meta property="og:site_name" content="Justin的技术博客">
<meta property="og:description" content="比赛简介「用户新增预测挑战赛」是由科大讯飞主办的一项数据科学竞赛，旨在通过机器学习方法预测用户是否为新增用户 比赛属于二分类任务，评价指标采用F1分数，分数越高表示模型性能越好。 如果你有一份带标签的表格型数据，只要目标是分类、回归或排序，那么 LightGBM 都是最强机器学习模型之一，默认首选。 赛题建模的价值用户新增预测是分析 用户使用场景 以及 预测用户增长情况 的关键步骤，有助于进行其后">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250712143029706.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250712161157877.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250712162416834.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250718021907038.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250718034328455.png">
<meta property="article:published_time" content="2025-07-17T05:54:00.347Z">
<meta property="article:modified_time" content="2025-07-18T14:14:16.157Z">
<meta property="article:author" content="Justin">
<meta property="article:tag" content="二分类">
<meta property="article:tag" content="特征工程">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250712143029706.png">
  
    <link rel="alternate" href="/atom.xml" title="Justin的技术博客" type="application/atom+xml">
  
  
    <link rel="icon" media="(prefers-color-scheme: light)" href="/images/favicon-light-32.png" sizes="32x32">
    <link rel="icon" media="(prefers-color-scheme: light)" href="/images/favicon-light-128.png" sizes="128x128">
    <link rel="icon" media="(prefers-color-scheme: light)" href="/images/favicon-light-180.png" sizes="180x180">
    <link rel="icon" media="(prefers-color-scheme: light)" href="/images/favicon-light-192.png" sizes="192x192">
    <link rel="icon" media="(prefers-color-scheme: dark)" href="/images/favicon-dark-32.png" sizes="32x32">
    <link rel="icon" media="(prefers-color-scheme: dark)" href="/images/favicon-dark-128.png" sizes="128x128">
    <link rel="icon" media="(prefers-color-scheme: dark)" href="/images/favicon-dark-180.png" sizes="180x180">
    <link rel="icon" media="(prefers-color-scheme: dark)" href="/images/favicon-dark-192.png" sizes="192x192">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body>
  
  
    
<div id="banner" class="">
  <img src="/image/background/benjamin_background.jpg" itemprop="image">
  <div id="banner-dim"></div>
</div>
 
   
  <div id="main-grid" class="  ">
    <div id="nav" class=""  >
      <navbar id="navbar">
  <nav id="title-nav">
    <a href="/">
      <div id="vivia-logo">
        <div class="dot"></div>
        <div class="dot"></div>
        <div class="dot"></div>
        <div class="dot"></div>
      </div>
      <div>Justin的技术博客 </div>
    </a>
  </nav>
  <nav id="main-nav">
    
      <a class="main-nav-link" href="/">Home</a>
    
      <a class="main-nav-link" href="/archives">Archives</a>
    
      <a class="main-nav-link" href="/projects">Projects</a>
    
      <a class="main-nav-link" href="/investment">Investment</a>
    
      <a class="main-nav-link" href="/photography">Photography</a>
    
      <a class="main-nav-link" href="/about">About</a>
    
  </nav>
  <nav id="sub-nav">
    <a id="theme-btn" class="nav-icon">
      <span class="light-mode-icon"><svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" width="20"><path d="M438.5-829.913v-48q0-17.452 11.963-29.476 11.964-12.024 29.326-12.024 17.363 0 29.537 12.024t12.174 29.476v48q0 17.452-11.963 29.476-11.964 12.024-29.326 12.024-17.363 0-29.537-12.024T438.5-829.913Zm0 747.826v-48q0-17.452 11.963-29.476 11.964-12.024 29.326-12.024 17.363 0 29.537 12.024t12.174 29.476v48q0 17.452-11.963 29.476-11.964 12.024-29.326 12.024-17.363 0-29.537-12.024T438.5-82.087ZM877.913-438.5h-48q-17.452 0-29.476-11.963-12.024-11.964-12.024-29.326 0-17.363 12.024-29.537t29.476-12.174h48q17.452 0 29.476 11.963 12.024 11.964 12.024 29.326 0 17.363-12.024 29.537T877.913-438.5Zm-747.826 0h-48q-17.452 0-29.476-11.963-12.024-11.964-12.024-29.326 0-17.363 12.024-29.537T82.087-521.5h48q17.452 0 29.476 11.963 12.024 11.964 12.024 29.326 0 17.363-12.024 29.537T130.087-438.5Zm660.174-290.87-34.239 32q-12.913 12.674-29.565 12.174-16.653-.5-29.327-13.174-12.674-12.673-12.554-28.826.12-16.152 12.794-28.826l33-35q12.913-12.674 30.454-12.674t30.163 12.847q12.709 12.846 12.328 30.826-.38 17.98-13.054 30.653ZM262.63-203.978l-32 34q-12.913 12.674-30.454 12.674t-30.163-12.847q-12.709-12.846-12.328-30.826.38-17.98 13.054-30.653l33.239-31q12.913-12.674 29.565-12.174 16.653.5 29.327 13.174 12.674 12.673 12.554 28.826-.12 16.152-12.794 28.826Zm466.74 33.239-32-33.239q-12.674-12.913-12.174-29.565.5-16.653 13.174-29.327 12.673-12.674 28.826-13.054 16.152-.38 28.826 12.294l35 33q12.674 12.913 12.674 30.454t-12.847 30.163q-12.846 12.709-30.826 12.328-17.98-.38-30.653-13.054ZM203.978-697.37l-34-33q-12.674-12.913-13.174-29.945-.5-17.033 12.174-29.707t31.326-13.293q18.653-.62 31.326 13.054l32 34.239q11.674 12.913 11.174 29.565-.5 16.653-13.174 29.327-12.673 12.674-28.826 12.554-16.152-.12-28.826-12.794ZM480-240q-100 0-170-70t-70-170q0-100 70-170t170-70q100 0 170 70t70 170q0 100-70 170t-170 70Zm-.247-82q65.703 0 111.475-46.272Q637-414.544 637-480.247t-45.525-111.228Q545.95-637 480.247-637t-111.475 45.525Q323-545.95 323-480.247t45.525 111.975Q414.05-322 479.753-322ZM481-481Z"/></svg></span>
      <span class="dark-mode-icon"><svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" width="20"><path d="M480.239-116.413q-152.63 0-258.228-105.478Q116.413-327.37 116.413-480q0-130.935 77.739-227.435t206.304-125.043q43.022-9.631 63.87 10.869t3.478 62.805q-8.891 22.043-14.315 44.463-5.424 22.42-5.424 46.689 0 91.694 64.326 155.879 64.325 64.186 156.218 64.186 24.369 0 46.978-4.946 22.609-4.945 44.413-14.076 42.826-17.369 62.967 1.142 20.142 18.511 10.511 61.054Q807.174-280 712.63-198.206q-94.543 81.793-232.391 81.793Zm0-95q79.783 0 143.337-40.217 63.554-40.218 95.793-108.283-15.608 4.044-31.097 5.326-15.49 1.283-31.859.805-123.706-4.066-210.777-90.539-87.071-86.473-91.614-212.092-.24-16.369.923-31.978 1.164-15.609 5.446-30.978-67.826 32.478-108.282 96.152Q211.652-559.543 211.652-480q0 111.929 78.329 190.258 78.329 78.329 190.258 78.329ZM466.13-465.891Z"/></svg></span>
    </a>
    
      <a id="nav-rss-link" class="nav-icon mobile-hide" href="/atom.xml" title="RSS 订阅">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" width="20"><path d="M198-120q-25.846 0-44.23-18.384-18.384-18.385-18.384-44.23 0-25.846 18.384-44.23 18.384-18.385 44.23-18.385 25.846 0 44.23 18.385 18.384 18.384 18.384 44.23 0 25.845-18.384 44.23Q223.846-120 198-120Zm538.385 0q-18.846 0-32.923-13.769-14.076-13.769-15.922-33.23-8.692-100.616-51.077-188.654-42.385-88.039-109.885-155.539-67.5-67.501-155.539-109.885Q283-663.462 182.385-672.154q-19.461-1.846-33.23-16.23-13.769-14.385-13.769-33.846t14.076-32.922q14.077-13.461 32.923-12.23 120.076 8.692 226.038 58.768 105.961 50.077 185.73 129.846 79.769 79.769 129.846 185.731 50.077 105.961 58.769 226.038 1.231 18.846-12.538 32.922Q756.461-120 736.385-120Zm-252 0q-18.231 0-32.423-13.461t-18.653-33.538Q418.155-264.23 348.886-333.5q-69.27-69.27-166.501-84.423-20.077-4.462-33.538-18.961-13.461-14.5-13.461-33.346 0-19.076 13.884-33.23 13.884-14.153 33.115-10.922 136.769 15.384 234.384 112.999 97.615 97.615 112.999 234.384 3.231 19.23-10.538 33.115Q505.461-120 484.385-120Z"/></svg>
      </a>
    
    <div id="nav-menu-btn" class="nav-icon">
      <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" width="20"><path d="M177.37-252.282q-17.453 0-29.477-11.964-12.024-11.963-12.024-29.326t12.024-29.537q12.024-12.174 29.477-12.174h605.26q17.453 0 29.477 11.964 12.024 11.963 12.024 29.326t-12.024 29.537q-12.024 12.174-29.477 12.174H177.37Zm0-186.218q-17.453 0-29.477-11.963-12.024-11.964-12.024-29.326 0-17.363 12.024-29.537T177.37-521.5h605.26q17.453 0 29.477 11.963 12.024 11.964 12.024 29.326 0 17.363-12.024 29.537T782.63-438.5H177.37Zm0-186.217q-17.453 0-29.477-11.964-12.024-11.963-12.024-29.326t12.024-29.537q12.024-12.174 29.477-12.174h605.26q17.453 0 29.477 11.964 12.024 11.963 12.024 29.326t-12.024 29.537q-12.024 12.174-29.477 12.174H177.37Z"/></svg>
    </div>
  </nav>
</navbar>
<div id="nav-dropdown" class="hidden">
  <div id="dropdown-link-list">
    
      <a class="nav-dropdown-link" href="/">Home</a>
    
      <a class="nav-dropdown-link" href="/archives">Archives</a>
    
      <a class="nav-dropdown-link" href="/projects">Projects</a>
    
      <a class="nav-dropdown-link" href="/investment">Investment</a>
    
      <a class="nav-dropdown-link" href="/photography">Photography</a>
    
      <a class="nav-dropdown-link" href="/about">About</a>
    
    
      <a class="nav-dropdown-link" href="/atom.xml" title="RSS 订阅">RSS</a>
     
    </div>
</div>
<script>
  let dropdownBtn = document.getElementById("nav-menu-btn");
  let dropdownEle = document.getElementById("nav-dropdown");
  dropdownBtn.onclick = function() {
    dropdownEle.classList.toggle("hidden");
  }
</script>
    </div>
    <div id="sidebar-wrapper">
      <sidebar id="sidebar">
  
    <div class="widget-wrap">
  <div class="info-card">
    <div class="avatar">
      
        <image src=/image/avatar/avatar_1.png></image>
      
      <div class="img-dim"></div>
    </div>
    <div class="info">
      <div class="username">Justin </div>
      <div class="dot"></div>
      <div class="subtitle">比世界先发现你发光 </div>
      <div class="link-list">
        
          <a class="link-btn" target="_blank" rel="noopener" href="https://github.com/JAYLI19707" title="GitHub"><i class="fa-brands fa-github"></i></a>
        
          <a class="link-btn" href="mailto:your.email@gmail.com" title="Email"><i class="fa-solid fa-envelope"></i></a>
        
          <a class="link-btn" href="/atom.xml" title="RSS"><i class="fa-solid fa-rss"></i></a>
         
      </div>  
    </div>
  </div>
</div>

  
  <div class="sticky">
    
      


  <div class="widget-wrap">
    <div class="widget">
      <h3 class="widget-title">分类</h3>
      <div class="category-box">
            <a class="category-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/">
                计算机
                <div class="category-count">6</div>
            </a>
        
            <a class="category-link" href="/categories/Leetcode/">
                Leetcode
                <div class="category-count">19</div>
            </a>
        
            <a class="category-link" href="/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/">
                开发工具
                <div class="category-count">1</div>
            </a>
        
            <a class="category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                机器学习
                <div class="category-count">17</div>
            </a>
        
            <a class="category-link" href="/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/">
                数学建模
                <div class="category-count">1</div>
            </a>
        
            <a class="category-link" href="/categories/%E9%87%91%E8%9E%8D/">
                金融
                <div class="category-count">7</div>
            </a>
        
            <a class="category-link" href="/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6/">
                统计学
                <div class="category-count">2</div>
            </a>
        
            <a class="category-link" href="/categories/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">
                线性代数
                <div class="category-count">1</div>
            </a>
        
            <a class="category-link" href="/categories/Quant/">
                Quant
                <div class="category-count">2</div>
            </a>
        
            <a class="category-link" href="/categories/AI/">
                AI
                <div class="category-count">1</div>
            </a>
        </div>
    </div>
  </div>


    
      
  <div class="widget-wrap">
    <div class="widget">
      <h3 class="widget-title">标签</h3>
      <ul class="widget-tag-list" itemprop="keywords"><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/Batch/" rel="tag">Batch</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/LSTM/" rel="tag">LSTM</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/Quant/" rel="tag">Quant</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/Shell/" rel="tag">Shell</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E4%B8%B4%E8%BF%91%E7%AE%97%E5%AD%90/" rel="tag">临近算子</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E4%BA%8C%E5%88%86%E7%B1%BB/" rel="tag">二分类</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E5%87%B8%E5%87%BD%E6%95%B0/" rel="tag">凸函数</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/" rel="tag">最大似然估计</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E6%9C%9F%E6%9D%83/" rel="tag">期权</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/" rel="tag">梯度下降</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" rel="tag">特征工程</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/" rel="tag">矩阵乘法</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" rel="tag">线性回归</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E7%BB%9F%E8%AE%A1%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/" rel="tag">统计假设检验</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" rel="tag">计算机网络</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E9%87%8F%E4%BB%B7%E8%B6%8B%E5%8A%BF/" rel="tag">量价趋势</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/tags/%E9%87%91%E8%9E%8D%E6%95%B0%E5%AD%A6/" rel="tag">金融数学</a></li></ul>
    </div>
  </div>


    
  </div>
</sidebar>
    </div>
    <div id="content-body">
       


<article id="post-Datawhale-二分类任务" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
    
   
  <div class="article-inner">
    <div class="article-main">
      <header class="article-header">
        
<div class="main-title-bar">
  <div class="main-title-dot"></div>
  
    
      <h1 class="p-name article-title" itemprop="headline name">
        Datawhale-二分类任务
      </h1>
    
  
</div>

        <div class='meta-info-bar'>
          <div class="meta-info">
  <time class="dt-published" datetime="2025-07-17T05:54:00.347Z" itemprop="datePublished">2025-07-17</time>
</div>
          <div class="need-seperator meta-info">
            <div class="meta-cate-flex">
  
  <a class="meta-cate-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
   
</div>
  
          </div>
          <div class="wordcount need-seperator meta-info">
            12k 词 
          </div>
        </div>
        
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E4%BA%8C%E5%88%86%E7%B1%BB/" rel="tag">二分类</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" rel="tag">特征工程</a></li></ul>

      </header>
      <div class="e-content article-entry" itemprop="articleBody">
        
          <h1 id="比赛简介"><a href="#比赛简介" class="headerlink" title="比赛简介"></a>比赛简介</h1><p>「<a target="_blank" rel="noopener" href="https://challenge.xfyun.cn/h5/detail?type=subscriber-addition-2025&ch=dwsfyc25-1">用户新增预测挑战赛</a>」是由科大讯飞主办的一项数据科学竞赛，旨在通过机器学习方法<strong>预测用户是否为新增用户</strong></p>
<p>比赛属于二分类任务，评价指标采用F1分数，分数越高表示模型性能越好。</p>
<p>如果你有一份带标签的表格型数据，只要目标是分类、回归或排序，那么 <strong>LightGBM 都是最强机器学习模型之一，默认首选</strong>。</p>
<h1 id="赛题建模的价值"><a href="#赛题建模的价值" class="headerlink" title="赛题建模的价值"></a>赛题建模的价值</h1><p>用户新增预测是分析 <strong>用户使用场景</strong> 以及 <strong>预测用户增长情况</strong> 的关键步骤，有助于进行其后续产品和应用的迭代升级，主要有对行业和技术有如下价值：</p>
<p><strong>行业价值：</strong></p>
<ul>
<li><p>精准预测用户增长趋势，优化产品迭代方向</p>
</li>
<li><p>降低用户获取成本，提高营销转化率</p>
</li>
<li><p>为AI能力落地提供量化评估依据</p>
</li>
</ul>
<p><strong>技术价值：</strong></p>
<ul>
<li><p>解决实际业务场景中的用户增长预测问题</p>
</li>
<li><p>验证AI在用户行为分析领域的有效性</p>
</li>
<li><p>建立可复用的用户增长预测方法论</p>
</li>
</ul>
<h1 id="赛题要求："><a href="#赛题要求：" class="headerlink" title="赛题要求："></a>赛题要求：</h1><p>参与算法赛事，一定要仔细理解赛事的 <strong>输入-输出</strong> 究竟是什么，尤其是<strong>提交的格式</strong></p>
<p><strong>输入数据：</strong></p>
<ul>
<li><p>用户行为事件记录</p>
</li>
<li><p>15个原始特征字段</p>
</li>
<li><p>关键字段： <code>udmap</code> (JSON)、 <code>common_ts</code> (时间戳)</p>
</li>
</ul>
<p><strong>输出要求：</strong></p>
<ul>
<li><p>预测用户是否为新增 ( <code>is_new_did</code> )</p>
</li>
<li><p>提交格式：CSV文件包含一列，字段名为<code>is_new_did</code>，值为<code>0/1</code></p>
<ul>
<li><p><code>0</code> 表示不是新增用户</p>
</li>
<li><p><code>1</code> 表示是新增用户</p>
</li>
</ul>
</li>
</ul>
<h1 id="原始数据初步预览"><a href="#原始数据初步预览" class="headerlink" title="原始数据初步预览"></a>原始数据初步预览</h1><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250712143029706.png" alt="image.png"></p>
<p>其中：</p>
<ul>
<li><p><code>mid</code>为用户行为模块id,</p>
</li>
<li><p><code>eid</code>为用户行为事件id,</p>
</li>
</ul>
<p>解析一下两者的区别：</p>
<ul>
<li><p><strong><code>mid</code>（模块ID）</strong>：是<strong>一类行为的编号</strong>，表示用户在做什么“类型”的事情，比如：</p>
<ul>
<li><p>mid = 1：表示“浏览商品模块”</p>
</li>
<li><p>mid = 2：表示“搜索模块”</p>
</li>
<li><p>mid = 3：表示“结算模块”</p>
</li>
</ul>
<p>  所以它更像是一个<strong>大分类</strong>，告诉我们用户当前在哪个模块里操作。
  </p>
</li>
<li><p><strong><code>eid</code>（事件ID）</strong>：是<strong>具体某个行为的编号</strong>，它属于某个模块（mid），但粒度更细，比如：</p>
<ul>
<li><p>在“浏览商品模块”中（mid=1），可能有：</p>
<ul>
<li><p>eid = 101：点击商品详情</p>
</li>
<li><p>eid = 102：滑动商品列表</p>
</li>
</ul>
</li>
<li><p>在“搜索模块”中（mid=2），可能有：</p>
<ul>
<li><p>eid = 201：输入关键词</p>
</li>
<li><p>eid = 202：点击搜索按钮</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p><code>did</code>为用户id,</p>
</li>
<li><p><code>device_brand</code>为设备品牌/厂商,</p>
</li>
<li><p><code>ntt</code>为网络类型,</p>
</li>
<li><p><code>operator</code>为运营商,</p>
</li>
<li><p><code>common_country</code>为国家,</p>
</li>
<li><p><code>common_province</code>为省份,</p>
</li>
<li><p><code>common_city</code>为城市,</p>
</li>
<li><p><code>appver</code>为应用版本,</p>
</li>
<li><p><code>channel</code>为应用渠道,</p>
</li>
<li><p><code>common_ts</code>为事件发生时间（毫秒时间戳）,</p>
</li>
<li><p><code>os_type</code>用于判断Android还是iOS,</p>
</li>
<li><p><code>udmap</code>为事件自定义属性（标准json文本，内含botId助手ID和pluginId插件ID）</p>
</li>
<li><p><code>is_new_did</code>为预测目标，即是否为新增用户</p>
</li>
</ul>
<h1 id="分析训练集与测试集用户重叠度"><a href="#分析训练集与测试集用户重叠度" class="headerlink" title="分析训练集与测试集用户重叠度"></a>分析训练集与测试集用户重叠度</h1><p>然后我们可以通过 经验/资料查阅肉眼观测/代码 等手段，对 <strong>赛事提供的数据</strong> 有大致的理解和把握:</p>
<p>提取了训练集和测试集中的所有唯一用户ID，分别组成集合</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_dids = <span class="built_in">set</span>(train_df[<span class="string">'did'</span>].unique())</span><br><span class="line">test_dids = <span class="built_in">set</span>(test_df[<span class="string">'did'</span>].unique())</span><br></pre></td></tr></table></figure>

<p>计算两者交集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">overlap_dids = train_dids &amp; test_dids</span><br></pre></td></tr></table></figure>

<p>统计数量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">num_overlap = <span class="built_in">len</span>(overlap_dids)</span><br><span class="line">num_train = <span class="built_in">len</span>(train_dids)</span><br><span class="line">num_test = <span class="built_in">len</span>(test_dids)</span><br></pre></td></tr></table></figure>

<p>计算比例:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ratio_in_train = num_overlap / num_train</span><br><span class="line">ratio_in_test = num_overlap / num_test</span><br></pre></td></tr></table></figure>

<p>我们通过数据探索的代码，有一些关键发现：</p>
<ul>
<li><p><strong>测试集</strong>中<strong>93%的用户</strong>出现在<strong>训练集</strong>中</p>
</li>
<li><p><strong>训练集</strong>中88%的用户<code>is_new_did</code>为 0</p>
</li>
</ul>
<h1 id="建模初步思路"><a href="#建模初步思路" class="headerlink" title="建模初步思路"></a>建模初步思路</h1><ul>
<li><p><strong>数据处理与特征工程：</strong> 如处理缺失值、异常值，解析JSON字段，从时间戳中提取特征（年、月、日、小时等），以及构造新的特征以提升模型表现。</p>
</li>
<li><p><strong>分类模型与集成学习：</strong> 了解常用的分类算法（如逻辑回归、决策树、随机森林等），特别是梯度提升树（如LightGBM）的原理和使用。LightGBM是微软开发的高效梯度提升框架，具有训练速度快、内存占用低和精度高等优点。</p>
</li>
<li><p><strong>模型评估与指标：</strong> 掌握二分类问题的评估指标，如精确率（Precision）、召回率（Recall）和F1分数的定义及计算方法。F1分数是精确率和召回率的调和均值，在正负样本不均衡时比准确率更有参考意义。</p>
</li>
<li><p><strong>交叉验证：</strong> 理解交叉验证的作用，能够使用分层K折交叉验证来评估模型性能，避免因随机划分导致的偏差。</p>
</li>
<li><p><strong>超参数调优：</strong> 熟悉如何调整模型的超参数（如学习率、树的深度等）以提高模型效果，常用方法包括网格搜索、随机搜索和贝叶斯优化等。</p>
</li>
<li><p><strong>结果提交与分析：</strong> 了解竞赛提交的格式要求，能够将模型预测结果生成符合要求的CSV文件提交，并通过排行榜成绩分析模型改进方向。</p>
</li>
</ul>
<h1 id="解题-要点和难点"><a href="#解题-要点和难点" class="headerlink" title="解题 要点和难点"></a>解题 要点和难点</h1><ul>
<li><p>用户行为事件数据 → 用户级别预测</p>
</li>
<li><p>高维稀疏特征（设备/地域/行为ID）<br>  像 <code>device_brand</code>, <code>common_city</code>, <code>mid</code>, <code>eid</code> 这类字段，有成百上千种取值。用 One-hot 编码会变成高维稀疏矩阵，容易导致模型训练慢、过拟合，必须小心处理，比如可以做频率编码、embedding、或仅保留Top-N</p>
</li>
<li><p>正负样本不均衡（新增用户占比较少）<br>  <code>is_new_did</code> 的 0 和 1 不平衡，大多数是老用户（0）。这会让模型“只学会预测0”，所以需要：</p>
</li>
<li><p>采样策略（欠采样、过采样）</p>
<ul>
<li>比如统计：</li>
<li>用户一共触发了几个行为（行为数量）</li>
<li>用户用过哪些网络、在哪些城市</li>
<li>用户行为的时间分布（首次时间、活跃时段等）</li>
</ul>
</li>
<li><p>这是建模效果优劣的关键步骤。</p>
</li>
<li><p>合理评价指标（如AUC或F1，而不是Accuracy）</p>
</li>
<li><p>使用内置样本权重的模型（如 LightGBM）</p>
</li>
<li><p>用户行为聚合：如何将事件级数据转化为用户特征<br>  数据是以“行为事件”为单位的，比如用户点击了某个按钮，这样的行为记录很多，但我们的目标是预测“某个用户是否是新用户”，所以我们需要<strong>将多条事件数据合并成一个用户级别的数据</strong>，这是一个“从行到列”的特征聚合问题。</p>
</li>
<li><p>时间敏感特征：用户行为模式随时间变化<br>  比如一个用户一开始很频繁，后面沉寂，也许是老用户；新用户行为更集中在某几个小时；时间戳可以提取：</p>
<ul>
<li>小时、星期几、行为密度</li>
<li>首次行为和最后一次行为的间隔</li>
<li>是否在特定时间段活跃（如晚上活跃）</li>
</ul>
</li>
</ul>
<h2 id="解题思考过程"><a href="#解题思考过程" class="headerlink" title="解题思考过程"></a>解题思考过程</h2><p>关键决策点：</p>
<ol>
<li><p>选择树模型而非神经网络（训练速度/特征处理）</p>
</li>
<li><p>优先构造简单的时间特征而非复杂特征工程</p>
</li>
</ol>
<p>参考资料：</p>
<ul>
<li><p>LightGBM官方文档（分类任务参数配置）</p>
</li>
<li><p>时序特征工程最佳实践（FeatureTools库）</p>
</li>
</ul>
<h1 id="Baseline方案的设计思路"><a href="#Baseline方案的设计思路" class="headerlink" title="Baseline方案的设计思路"></a>Baseline方案的设计思路</h1><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250712161157877.png" alt="image.png"></p>
<h2 id="核心函数1：交叉验证建模"><a href="#核心函数1：交叉验证建模" class="headerlink" title="核心函数1：交叉验证建模"></a>核心函数1：交叉验证建模</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">n_folds = <span class="number">5</span></span><br><span class="line">kf = StratifiedKFold(n_splits=n_folds, shuffle=<span class="literal">True</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> fold, (train_idx, val_idx) <span class="keyword">in</span> <span class="built_in">enumerate</span>(kf.split(X_train, y_train)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"\n======= Fold <span class="subst">{fold+<span class="number">1</span>}</span>/<span class="subst">{n_folds}</span> ======="</span>)</span><br><span class="line">    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]</span><br><span class="line">    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 创建数据集（指定类别特征）</span></span><br><span class="line">    train_set = lgb.Dataset(X_tr, label=y_tr)</span><br><span class="line">    val_set = lgb.Dataset(X_val, label=y_val)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 模型训练</span></span><br><span class="line">    model = lgb.train(</span><br><span class="line">        params,train_set,</span><br><span class="line">        num_boost_round=<span class="number">5000</span>,</span><br><span class="line">        valid_sets=[train_set, val_set],</span><br><span class="line">        callbacks=[</span><br><span class="line">            lgb.early_stopping(stopping_rounds=<span class="number">200</span>, verbose=<span class="literal">False</span>),</span><br><span class="line">            lgb.log_evaluation(period=<span class="number">200</span>)</span><br><span class="line">        ]</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<h3 id="细节补充（什么是k-fold-cross-validation）："><a href="#细节补充（什么是k-fold-cross-validation）：" class="headerlink" title="细节补充（什么是k-fold cross-validation）："></a>细节补充（什么是k-fold cross-validation）：</h3><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250712162416834.png" alt="image.png"></p>
<h3 id="根据题型还要有的改进点："><a href="#根据题型还要有的改进点：" class="headerlink" title="根据题型还要有的改进点："></a>根据题型还要有的改进点：</h3><p>使用<strong>StratifiedKFold</strong><br>如果你在处理的是分类问题，并且正负样本比例不平衡（比如“新增用户”只占很少），那你用的 <code>StratifiedKFold</code> 就更进一步了，它在划分每一份的时候，还会<strong>确保正负样本的比例一致</strong>，这能避免某一折验证集全是负样本，导致模型评估不准。</p>
<h2 id="核心函数2：目标优化函数"><a href="#核心函数2：目标优化函数" class="headerlink" title="核心函数2：目标优化函数"></a>核心函数2：目标优化函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">find_optimal_threshold</span>(<span class="params">y_true, y_pred_proba</span>):</span><br><span class="line">    <span class="string">"""寻找最大化F1分数的阈值"""</span></span><br><span class="line">    best_threshold = <span class="number">0.5</span></span><br><span class="line">    best_f1 = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> threshold <span class="keyword">in</span> [<span class="number">0.1</span>,<span class="number">0.15</span>,<span class="number">0.2</span>,<span class="number">0.25</span>,<span class="number">0.3</span>,<span class="number">0.35</span>,<span class="number">0.4</span>]:</span><br><span class="line">        y_pred = (y_pred_proba &gt;= threshold).astype(<span class="built_in">int</span>)</span><br><span class="line">        f1 = f1_score(y_true, y_pred)</span><br><span class="line">        <span class="keyword">if</span> f1 &gt; best_f1:</span><br><span class="line">            best_f1 = f1</span><br><span class="line">            best_threshold = threshold</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> best_threshold, best_f1</span><br></pre></td></tr></table></figure>

<h3 id="背景："><a href="#背景：" class="headerlink" title="背景："></a>背景：</h3><p>在二分类模型中，很多模型（比如 LightGBM、XGBoost）输出的不是“0”或“1”的标签，而是一个概率（比如这个样本属于正类的概率是 0.73）<br>但我们最终要做出决策：到底是正类（1）还是负类（0）？这就需要设置一个“阈值”来做转换<br>例如：默认是用 0.5，当预测概率大于 0.5 就认为是正类。但这个阈值不是固定的，<strong>在样本不均衡或业务目标特殊时，调整阈值可以显著提升 F1 等指标。</strong></p>
<p><strong>设计特点：</strong></p>
<ol>
<li>候选范围选择<ul>
<li><p>聚焦 0.1-0.4：适用于正例稀少的场景（如欺诈检测）</p>
</li>
<li><p>若正例比例高，可扩展范围至 <code>np.arange(0.05, 0.95, 0.05)</code></p>
</li>
</ul>
</li>
<li>数值稳定性<ul>
<li><p>避免使用 <code>np.ptp</code> 等可能受异常值影响的指标</p>
</li>
<li><p>离散化搜索简单高效，复杂度 O(n)</p>
</li>
</ul>
</li>
</ol>
<h1 id="合并数据做特征工程（补充）"><a href="#合并数据做特征工程（补充）" class="headerlink" title="合并数据做特征工程（补充）"></a>合并数据做特征工程（补充）</h1><h2 id="1-类别特征编码一致性"><a href="#1-类别特征编码一致性" class="headerlink" title="1. 类别特征编码一致性"></a>1. <strong>类别特征编码一致性</strong></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> feature <span class="keyword">in</span> cat_features:</span><br><span class="line">    le = LabelEncoder()</span><br><span class="line">    all_values = pd.concat([train_df[feature], test_df[feature]]).astype(<span class="built_in">str</span>)</span><br><span class="line">    le.fit(all_values)</span><br><span class="line">    <span class="comment"># 确保训练集和测试集使用相同的编码映射</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>le.fit(values)</code> 这一步是“学习”阶段：它会扫描 <code>values</code> 中所有不同的取值，按<strong>字典序排序</strong>，然后给每个唯一类别分配一个整数标签（从 0 开始）。这些映射规则保存在 <code>le.classes_</code> 属性里。</p>
</li>
<li><p>然后用 <code>le.transform(...)</code> 把原始列中的每个值，根据这个映射规则变成整数（比如 <code>['banana', 'apple']</code> → <code>[1, 0]</code>）。</p>
</li>
<li><p>最后，这些编码后的数字会“<strong>回填到数据集的原列里</strong>”，替换掉原来的字符串</p>
</li>
</ul>
<p><strong>关键问题</strong>：如果分别编码，可能出现：</p>
<ul>
<li>训练集中 <code>device_brand='Apple'</code> 编码为 <code>0</code></li>
<li>测试集中 <code>device_brand='Apple'</code> 编码为 <code>1</code></li>
<li>导致模型无法正确识别相同的设备品牌</li>
</ul>
<h2 id="2-统计特征的完整性"><a href="#2-统计特征的完整性" class="headerlink" title="2. 统计特征的完整性"></a>2. <strong>统计特征的完整性</strong></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于合并数据计算统计特征</span></span><br><span class="line">brand_stats = full_df.groupby(<span class="string">'device_brand'</span>).agg({</span><br><span class="line">    <span class="string">'did'</span>: <span class="string">'nunique'</span>,</span><br><span class="line">    <span class="string">'hour'</span>: [<span class="string">'mean'</span>, <span class="string">'std'</span>],</span><br><span class="line">    <span class="string">'dayofweek'</span>: <span class="string">'mean'</span></span><br><span class="line">}).reset_index()</span><br></pre></td></tr></table></figure>

<p><strong>优势</strong>：</p>
<ul>
<li>统计更准确（基于更大的样本）</li>
<li>避免训练集和测试集统计分布不一致</li>
<li>提高特征的泛化能力</li>
</ul>
<h2 id="3-数据泄露检查"><a href="#3-数据泄露检查" class="headerlink" title="3. 数据泄露检查"></a>3. <strong>数据泄露检查</strong></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意：标签信息只在训练集中存在</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"正样本比例: <span class="subst">{train_df[<span class="string">'is_new_did'</span>].mean():<span class="number">.4</span>f}</span>"</span>)</span><br></pre></td></tr></table></figure>

<p><strong>安全性</strong>：</p>
<ul>
<li>测试集中的 <code>is_new_did</code> 列为 <code>NaN</code></li>
<li>只使用特征信息，不使用标签信息</li>
<li><strong>不会造成数据泄露</strong></li>
</ul>
<h1 id="聚合的意义（补充）"><a href="#聚合的意义（补充）" class="headerlink" title="聚合的意义（补充）"></a>聚合的意义（补充）</h1><p>原始数据的真实结构：</p>
<p> <strong>一行 ≠ 一个用户的所有行为</strong><br> <strong>一行 = 一次用户行为事件，不是用户全部行为</strong></p>
<p>从代码中可以看出：</p>
<ul>
<li>训练集大小: <strong>(3,429,925, 15)</strong> - 343万条记录</li>
<li>唯一用户数: <strong>270,837</strong> 个用户</li>
<li>这意味着：<strong>平均每个用户有 12.7 条记录</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 证明：每个用户有多条记录</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"总记录数: <span class="subst">{<span class="built_in">len</span>(train_df)}</span>"</span>)           <span class="comment"># 3,429,925</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"唯一用户数: <span class="subst">{<span class="built_in">len</span>(train_df[<span class="string">'did'</span>].unique())}</span>"</span>)  <span class="comment"># 270,837</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"平均每用户记录数: <span class="subst">{<span class="built_in">len</span>(train_df) / <span class="built_in">len</span>(train_df[<span class="string">'did'</span>].unique()):<span class="number">.1</span>f}</span>"</span>)  <span class="comment"># 12.7</span></span><br></pre></td></tr></table></figure>

<p> 🔍 具体例子说明<br> <strong>原始数据长这样：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">    did      eid    common_ts      device_brand  hour  is_new_did</span><br><span class="line">0   user001  100    1640000000000  Apple         14    1</span><br><span class="line">1   user001  200    1640000001000  Apple         14    1</span><br><span class="line">2   user001  300    1640000002000  Apple         15    1</span><br><span class="line">3   user001  100    1640000003000  Apple         16    1</span><br><span class="line">4   user002  100    1640000000500  Samsung       10    0</span><br><span class="line">5   user002  150    1640000001500  Samsung       11    0</span><br><span class="line">6   user003  200    1640000002000  Xiaomi        20    1</span><br></pre></td></tr></table></figure>
<p> <strong>问题是什么？</strong></p>
<p><strong>每一行只代表用户的一次行为事件</strong>，而不是用户的全部行为！</p>
<ul>
<li>第0行：用户001在14:00触发了事件100</li>
<li>第1行：用户001在14:00触发了事件200  </li>
<li>第2行：用户001在15:00触发了事件300</li>
<li>第3行：用户001在16:00又触发了事件100</li>
<li></li>
</ul>
<p><strong>我们需要用户级别的特征！</strong></p>
<h2 id="🎯-为什么要聚合？"><a href="#🎯-为什么要聚合？" class="headerlink" title="🎯 为什么要聚合？"></a>🎯 为什么要聚合？</h2><h3 id="1-单行信息不足"><a href="#1-单行信息不足" class="headerlink" title="1. 单行信息不足"></a><strong>1. 单行信息不足</strong></h3><ul>
<li>单行只能告诉我们：这个用户在某个时间点做了什么</li>
<li>无法告诉我们：这个用户的整体行为模式</li>
</ul>
<h3 id="2-用户级别特征更重要"><a href="#2-用户级别特征更重要" class="headerlink" title="2. 用户级别特征更重要"></a><strong>2. 用户级别特征更重要</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 没有聚合的情况下，我们只知道：</span></span><br><span class="line"><span class="comment"># - 用户001在14:00触发了事件100</span></span><br><span class="line"><span class="comment"># - 用户001使用Apple设备</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 有了聚合后，我们还知道：</span></span><br><span class="line"><span class="comment"># - 用户001总共触发了4次事件 (frequency)</span></span><br><span class="line"><span class="comment"># - 用户001使用了3种不同事件类型 (monetary)  </span></span><br><span class="line"><span class="comment"># - 用户001最后一次活动在16:00 (recency)</span></span><br><span class="line"><span class="comment"># - 用户001的活跃时间跨度是2小时</span></span><br></pre></td></tr></table></figure>

<h3 id="3-模型需要用户画像"><a href="#3-模型需要用户画像" class="headerlink" title="3. 模型需要用户画像"></a><strong>3. 模型需要用户画像</strong></h3><ul>
<li><strong>活跃用户</strong>: 高频次、多事件类型、最近活跃</li>
<li><strong>不活跃用户</strong>: 低频次、单一事件、很久没活跃</li>
</ul>
<h2 id="💡-实际价值"><a href="#💡-实际价值" class="headerlink" title="💡 实际价值"></a>💡 实际价值</h2><h3 id="聚合特征能回答的问题："><a href="#聚合特征能回答的问题：" class="headerlink" title="聚合特征能回答的问题："></a><strong>聚合特征能回答的问题：</strong></h3><ol>
<li><strong>这个用户活跃吗？</strong> → <code>frequency</code> (行为频次)</li>
<li><strong>这个用户最近活跃吗？</strong> → <code>recency</code> (最近活跃时间)</li>
<li><strong>这个用户行为多样吗？</strong> → <code>monetary</code> (不同事件类型数)</li>
<li><strong>这个用户是重度用户吗？</strong> → 综合RFM得分</li>
</ol>
<h3 id="这些特征对预测”新用户”很重要："><a href="#这些特征对预测”新用户”很重要：" class="headerlink" title="这些特征对预测”新用户”很重要："></a><strong>这些特征对预测”新用户”很重要：</strong></h3><ul>
<li><strong>新用户</strong>: 通常频次低、事件类型少、最近注册</li>
<li><strong>老用户</strong>: 通常频次高、事件类型多、历史悠久</li>
</ul>
<h2 id="🎯-总结"><a href="#🎯-总结" class="headerlink" title="🎯 总结"></a>🎯 总结</h2><p><strong>聚合的核心价值：</strong></p>
<ul>
<li>将用户的<strong>多次行为</strong>汇总成<strong>用户画像</strong></li>
<li>从<strong>事件级别</strong>提升到<strong>用户级别</strong>的特征</li>
<li>为模型提供<strong>更丰富的用户行为信息</strong></li>
</ul>
<p><strong>没有聚合</strong>：只知道用户做了什么<br><strong>有了聚合</strong>：知道用户是什么样的人</p>
<h1 id="Baseline方案的优缺点"><a href="#Baseline方案的优缺点" class="headerlink" title="Baseline方案的优缺点"></a>Baseline方案的优缺点</h1><h2 id="方案优点："><a href="#方案优点：" class="headerlink" title="方案优点："></a><strong>方案优点：</strong></h2><ol>
<li><p>数据预处理完整</p>
<ul>
<li><p>时间特征提取：将毫秒时间戳转换为 <code>day</code> 、 <code>dayofweek</code> 、 <code>hour</code> 等可解释的时序特征，捕捉用户行为的周期性规律。</p>
</li>
<li><p>类别特征编码：对 <code>device_brand</code> 、 <code>operator</code> 等高基数类别特征使用 <code>LabelEncoder</code> 进行编码，避免了独热编码导致的维度爆炸问题。</p>
</li>
<li><p>交叉验证策略：采用 <code>StratifiedKFold</code> 分层交叉验证，确保训练集和验证集的类别分布一致性，减少模型偏差。</p>
</li>
</ul>
</li>
<li><p>模型选择合理</p>
<ul>
<li><p>使用LightGBM作为基模型，适合高维稀疏数据，且对类别特征处理友好（如 <code>udmap</code> 中的JSON字段）。</p>
</li>
<li><p>阈值优化：通过动态调整分类阈值（ <code>find_optimal_threshold</code> ）最大化F1分数，适应类别不平衡问题（新增用户比例较低）。</p>
</li>
</ul>
</li>
<li><p>特征重要性分析</p>
<ul>
<li>输出特征重要性（ <code>gain</code> ），帮助识别关键特征（如 <code>udmap</code> 中的插件ID或助手ID），为后续特征优化提供方向。</li>
</ul>
</li>
</ol>
<h2 id="方案不足："><a href="#方案不足：" class="headerlink" title="方案不足："></a><strong>方案不足：</strong></h2><ol>
<li><p>特征工程深度不足</p>
<ul>
<li><p>未充分挖掘 <code>udmap</code> 字段中的JSON信息（如 <code>botId</code> 、 <code>pluginId</code> ），仅将其作为类别特征处理，未提取组合特征（如 <code>botId+pluginId</code> 的交互）。</p>
</li>
<li><p>忽略用户行为序列模式（如用户访问频次、事件路径），未能构建基于时间窗口的统计特征（如24小时内访问次数、连续登录天数）。</p>
</li>
</ul>
</li>
<li><p>模型调参空间有限</p>
<ul>
<li><p>参数固定（如 <code>max_depth=12</code> 、 <code>num_leaves=63</code> ），未通过网格搜索或贝叶斯优化探索更优参数组合。</p>
</li>
<li><p>未尝试集成模型（如CatBoost、XGBoost）或模型融合策略（如Stacking）提升泛化能力</p>
</li>
</ul>
</li>
</ol>
<h2 id="进阶要点1：如何挖掘用户行为信息"><a href="#进阶要点1：如何挖掘用户行为信息" class="headerlink" title="进阶要点1：如何挖掘用户行为信息"></a>进阶要点1：如何挖掘用户行为信息</h2><p><strong>时间序列特征：</strong></p>
<ul>
<li>滑动窗口统计：计算用户在最近7天、30天内的行为频次（如 <code>eid</code> 事件发生次数）、活跃时长（连续登录天数）。</li>
<li>示例代码：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按用户分组，按时间排序</span></span><br><span class="line">train_df.sort_values([<span class="string">'did'</span>, <span class="string">'common_ts'</span>], inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算用户历史行为频次（滑动窗口）</span></span><br><span class="line">train_df[<span class="string">'user_event_count'</span>] = train_df.groupby(<span class="string">'did'</span>)[<span class="string">'eid'</span>].transform(<span class="string">'cumcount'</span>) + <span class="number">1</span></span><br></pre></td></tr></table></figure>

<h3 id="RFM特征："><a href="#RFM特征：" class="headerlink" title="RFM特征："></a>RFM特征：</h3><ul>
<li><p>Recency（最近一次行为时间）：计算用户最近一次行为距离当前时间的天数。</p>
</li>
<li><p>Frequency（行为频率）：用户总行为次数。</p>
</li>
<li><p>Monetary（行为价值）：假设某些事件（如 <code>eid</code> ）有经济价值，可定义虚拟价值字段。</p>
</li>
<li><p>示例代码：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line"><span class="comment"># 3.1 RFM 特征构建</span></span><br><span class="line"><span class="comment"># 我们在 full_df 上计算这些聚合特征，因为它包含了所有用户的所有行为</span></span><br><span class="line">max_ts = full_df[<span class="string">'ts'</span>].<span class="built_in">max</span>()</span><br><span class="line">rfm_agg = full_df.groupby(<span class="string">'did'</span>).agg({</span><br><span class="line">    <span class="string">'ts'</span>: <span class="keyword">lambda</span> x: (max_ts - x.<span class="built_in">max</span>()).days, <span class="comment"># Recency</span></span><br><span class="line">    <span class="string">'eid'</span>: <span class="string">'count'</span>, <span class="comment"># Frequency</span></span><br><span class="line">    <span class="string">'mid'</span>: <span class="string">'nunique'</span>, <span class="comment"># 行为深度</span></span><br><span class="line">    <span class="string">'common_ts'</span>: [<span class="string">'min'</span>, <span class="string">'max'</span>] <span class="comment"># 首次和末次行为时间</span></span><br><span class="line">})</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.2 列名扁平化处理</span></span><br><span class="line"><span class="comment"># 将多级索引 ('common_ts', 'min') 合并为单级 'common_ts_min'</span></span><br><span class="line">rfm_agg.columns = [<span class="string">'_'</span>.join(col).strip() <span class="keyword">for</span> col <span class="keyword">in</span> rfm_agg.columns.values]</span><br><span class="line">rfm_agg = rfm_agg.reset_index()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.3 特征重命名</span></span><br><span class="line">rfm_agg.rename(columns={</span><br><span class="line">    <span class="string">'ts_&lt;lambda&gt;'</span>: <span class="string">'recency'</span>,</span><br><span class="line">    <span class="string">'eid_count'</span>: <span class="string">'frequency'</span>,</span><br><span class="line">    <span class="string">'mid_nunique'</span>: <span class="string">'mid_nunique'</span>,</span><br><span class="line">    <span class="string">'common_ts_min'</span>: <span class="string">'first_action_ts'</span>,</span><br><span class="line">    <span class="string">'common_ts_max'</span>: <span class="string">'last_action_ts'</span></span><br><span class="line">}, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.4 派生新特征</span></span><br><span class="line"><span class="comment"># 计算首次和末次行为的时间跨度（单位：秒）</span></span><br><span class="line">rfm_agg[<span class="string">'action_timespan_seconds'</span>] = (rfm_agg[<span class="string">'last_action_ts'</span>] - rfm_agg[<span class="string">'first_action_ts'</span>]) / <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.5 合并RFM特征到 train_df 和 test_df</span></span><br><span class="line"><span class="comment"># 为了确保后续流程的变量一致性，我们直接在 train_df 和 test_df 上合并</span></span><br><span class="line">train_df = pd.merge(train_df, rfm_agg, on=<span class="string">'did'</span>, how=<span class="string">'left'</span>)</span><br><span class="line">test_df = pd.merge(test_df, rfm_agg, on=<span class="string">'did'</span>, how=<span class="string">'left'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.6 清理不再需要的 ts 列</span></span><br><span class="line"><span class="keyword">for</span> df <span class="keyword">in</span> [train_df, test_df]:</span><br><span class="line">    df.drop([<span class="string">'ts'</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>聚类之前，我们通常需要构造用户画像，也就是将“用户在某一时刻做了一件事”这一行级别的记录，<strong>转化为用户级别的特征向量</strong>（也可以理解为把行为日志「压缩」成特征摘要），RFM 就是一种典型方式（Recency 最近行为时间、Frequency 总行为次数、Monetary 用户价值或活跃度等）。因为你的原始数据是按行为记录来组织的，每一行是某个用户某个时间的行为，所以我们必须在 <code>full_df</code>（通常是训练集和测试集拼接后）中 <strong>以用户ID为单位聚合</strong>，计算出这些用户级的特征。</p>
<p>这一步就是对每个用户的所有行为求统计量：比如用户最后一次行为距现在多长时间、行为次数是多少、涉及的内容有多少种、最早和最晚的时间戳等。<strong>这些值都是用户的静态画像特征，适合用于聚类或训练模型</strong>。</p>
<p>但问题来了：原始的 <code>train_df</code> 和 <code>test_df</code> 还是按行为来组织的，而我们刚刚生成的是每个用户一行的 <code>rfm_agg</code>。所以我们需要 <strong>把这些用户特征“广播”回去合并到每条行为记录中</strong>（也就是你看到的 merge 操作），使得后续训练模型时，每条行为记录都能携带所属用户的画像。</p>
<p>这一步很关键，它是“先聚合再拆开”的意思：<strong>先在完整数据集上聚合用户级特征，再分别合并到训练集和测试集中</strong>。这样做是因为：</p>
<ol>
<li><p>RFM 特征是用户静态特征，不应该因训练/测试划分而不同；</p>
</li>
<li><p>若只用 <code>train_df</code> 聚合，会导致测试集中部分用户特征缺失；</p>
</li>
<li><p>若不合并，而是直接聚类用户，会失去原始行为粒度的信息，无法训练分类模型。</p>
</li>
</ol>
<hr>
<p>总结一句话就是：<strong>聚类或RFM特征是“以用户为单位的全局视角”，而行为数据是“以行为为单位的局部视角”。我们需要通过聚合（groupby）+ merge（合并）来建立两者之间的桥梁</strong>。这种设计让你既能提取用户画像，又能在每条行为记录中使用这些聚类信息做模型训练</p>
<h3 id="组合特征与高阶交互"><a href="#组合特征与高阶交互" class="headerlink" title="组合特征与高阶交互"></a>组合特征与高阶交互</h3><p>目标：通过特征交叉和非线性组合，捕捉复杂模式。<br>方法：</p>
<ul>
<li>类别特征交叉：<ul>
<li>将 <code>device_brand</code> 与 <code>os_type</code> 组合（如 <code>Android_Samsung</code> ），反映设备-系统的用户偏好。</li>
<li>示例代码：</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_df[<span class="string">'device_os'</span>] = train_df[<span class="string">'device_brand'</span>].astype(<span class="built_in">str</span>) + <span class="string">'_'</span> + train_df[<span class="string">'os_type'</span>].astype(<span class="built_in">str</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>数值特征分桶与交叉：<ul>
<li>将将 <code>common_ts</code> 分桶为时间段（如早高峰、晚高峰），与 <code>hour</code> 特征交叉，分析用户在特定时段的行为差异。</li>
<li>示例代码：</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分桶：将时间戳转换为时间段（如0-6: 0, 6-12:1...）</span></span><br><span class="line">train_df[<span class="string">'time_bucket'</span>] = pd.cut(train_df[<span class="string">'hour'</span>], bins=[<span class="number">0</span>,<span class="number">6</span>,<span class="number">12</span>,<span class="number">18</span>,<span class="number">24</span>], labels=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<h2 id="进阶要点2：选择什么样的建模思路"><a href="#进阶要点2：选择什么样的建模思路" class="headerlink" title="进阶要点2：选择什么样的建模思路"></a>进阶要点2：选择什么样的建模思路</h2><h3 id="1、按-did-聚合后的分层建模"><a href="#1、按-did-聚合后的分层建模" class="headerlink" title="1、按 did 聚合后的分层建模"></a><strong>1、按</strong> <code>did</code> <strong>聚合后的分层建模</strong></h3><p><strong>核心思想：</strong><br>将问题拆解为两层：用户层和事件层，通过分层建模捕捉用户级特征与事件级特征的交互。<br><strong>具体步骤：</strong></p>
<ol>
<li>用户层建模：<ul>
<li>对每个 <code>did</code> 进行特征聚合（如行为频次、时间分布、RFM特征等），训练一个用户级模型（如LightGBM/XGBoost），预测该 <code>did</code> 的标签（或概率）。</li>
<li>例如：使用每个 <code>did</code> 的累计行为次数、最近一次行为时间间隔等作为输入特征。</li>
</ul>
</li>
<li>事件层建模：<ul>
<li>在事件级别（即原始样本）引入用户级预测结果作为特征，构建混合模型。</li>
<li>例如：将用户级模型的输出（如预测概率）与事件级特征（如 <code>eid</code> 、时间戳、设备信息）拼接，输入到最终模型（如神经网络或集成树）中进行预测。<br><strong>优势：</strong></li>
</ul>
</li>
</ol>
<ul>
<li>用户层模型可捕捉全局用户行为模式，事件层模型可结合局部事件特征，提升模型鲁棒性。</li>
<li>对于测试集中重复的 <code>did</code> ，用户层预测结果可直接复用，减少冗余计算。</li>
</ul>
<h3 id="2、半监督学习策略"><a href="#2、半监督学习策略" class="headerlink" title="2、半监督学习策略"></a><strong>2、半监督学习策略</strong></h3><p><strong>核心思想：</strong></p>
<p>利用测试数据中重复的 <code>did</code> （部分标签已知但不唯一）作为伪标签，结合训练数据进行半监督训练。</p>
<p><strong>具体步骤：</strong></p>
<ol>
<li>筛选伪标签：<ul>
<li>对测试集中重复的 <code>did</code> ，若其在训练集中有多个样本且标签一致，可直接使用该标签作为伪标签。</li>
<li>若标签不一致，可通过以下方式处理：<ul>
<li>投票机制：选择训练集中该 <code>did</code> 的多数类标签。</li>
<li>置信度阈值：对预测概率较高的样本（如阈值&gt;0.95）生成伪标签。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>优势：</strong></p>
<ul>
<li><p>利用测试数据中的隐式信息（重复 <code>did</code> 的已知标签），提升模型泛化能力。</p>
</li>
<li><p>对标签不唯一的场景，通过置信度筛选降低噪声风险。</p>
</li>
</ul>
<h3 id="3、动态标签映射与修正"><a href="#3、动态标签映射与修正" class="headerlink" title="3、动态标签映射与修正"></a>3、动态标签映射与修正</h3><p><strong>核心思想：</strong><br>针对测试集中重复的 <code>did</code> ，动态修正其预测标签，结合训练数据中的历史行为模式。<br><strong>具体步骤：</strong></p>
<ol>
<li>标签冲突检测：<ul>
<li><p>对于测试集中某个 <code>did</code> ，若其在训练集中有多个标签，统计标签分布（如出现次数、时间趋势）。</p>
</li>
<li><p>例如：若某 <code>did</code> 在训练集中同时存在0和1标签，但1标签集中在近期事件中，则优先选择1作为预测值。</p>
</li>
</ul>
</li>
<li>动态修正策略：<ul>
<li><p>时间加权平均：根据训练集中 <code>did</code> 的标签时间分布，加权计算预测值。</p>
</li>
<li><p>行为相似度匹配：将测试样本与训练集中该 <code>did</code> 的相似行为样本匹配，提取标签分布。</p>
</li>
</ul>
</li>
</ol>
<p><strong>优势：</strong></p>
<ul>
<li><p>精细化处理标签不唯一的场景，避免简单投票导致的偏差。</p>
</li>
<li><p>结合时间动态性和行为相似性，提升预测的合理性。</p>
</li>
</ul>
<h1 id="最终模型改进"><a href="#最终模型改进" class="headerlink" title="最终模型改进"></a>最终模型改进</h1><ol>
<li><p>用户层建模：（0.63-&gt;0.86）</p>
<ul>
<li>对每个 <code>did</code> 进行特征聚合（如行为频次、时间分布、RFM特征等），训练一个用户级模型（如LightGBM/XGBoost），预测该 <code>did</code> 的标签（或概率）。</li>
</ul>
</li>
<li><p>修改模型调参空间(0.86-&gt;0.94)</p>
<ul>
<li>参数固定（如 <code>max_depth=12</code> 、 <code>num_leaves=63</code> ），未通过网格搜索或贝叶斯优化探索更优参数组合。</li>
</ul>
</li>
<li><p>解析udmap和联合其他特征做特征工程：（0.94-0.95）</p>
<ul>
<li>未充分挖掘 <code>udmap</code> 字段中的JSON信息</li>
</ul>
</li>
<li><p>修复数据泄露问题<br> RFM特征是在 full_df 上聚合的，可能无意间“偷看了测试集”。我立即调整逻辑，确保所有特征只基于训练集统计。<br> 📉 分数略降，但汇总能力更真实可靠！</p>
</li>
<li><p>udmap 探掘 &amp; 组合特征（0.94 ➔ 0.95）<br>开始深入 JSON 字段 <code>udmap</code>，探索了 <code>botId</code>, <code>pluginId</code> 等关键信息，还构造了组合特征：</p>
<ul>
<li><p><code>device_brand + os_type</code></p>
</li>
<li><p><code>hour</code> + 活跃时段</p>
</li>
</ul>
<p>虽然提升不大，但对理解数据有很大帮助🧠</p>
</li>
<li><p>第五步：规则提分策略（0.95 ➔ 0.97）</p>
</li>
</ol>
<pre><code>670K测试用户里，**93%在训练集里出现过**——我灵机一動✨：

将 `did` 直接作为特征加入模型，让模型学会“重复用户 = 老用户 = 0” 的强规则

🚀 结果：F1爆炸提升至**0.97**！
</code></pre>
<h2 id="网格搜索-Grid-Search"><a href="#网格搜索-Grid-Search" class="headerlink" title="网格搜索 (Grid Search)"></a><strong>网格搜索 (Grid Search)</strong></h2><ul>
<li><p><strong>适用场景</strong>: 参数空间较小，需要全面探索</p>
</li>
<li><p><strong>优势</strong>: 保证找到搜索范围内的最优组合</p>
</li>
<li><p><strong>时间复杂度</strong>: O(n^k) - n为每个参数的候选值数，k为参数个数</p>
</li>
<li><p><strong>实现</strong>: 分两阶段搜索，先结构参数后正则化参数</p>
</li>
</ul>
<h3 id="核心结构参数-影响最大"><a href="#核心结构参数-影响最大" class="headerlink" title="核心结构参数 (影响最大)"></a>核心结构参数 (影响最大)</h3><ol>
<li><p><strong>max_depth</strong> &amp; <strong>num_leaves</strong>: 控制模型复杂度，防止过拟合</p>
</li>
<li><p><strong>learning_rate</strong>: 控制训练速度和最终性能的平衡</p>
</li>
<li><p><strong>min_child_samples</strong>: 叶子节点最小样本数，影响泛化能力</p>
</li>
</ol>
<h3 id="正则化参数-精细调节"><a href="#正则化参数-精细调节" class="headerlink" title="正则化参数 (精细调节)"></a>正则化参数 (精细调节)</h3><ol start="4">
<li><p><strong>feature_fraction</strong>: 特征采样比例，防止过拟合</p>
</li>
<li><p><strong>bagging_fraction</strong> &amp; <strong>bagging_freq</strong>: 样本采样，提高鲁棒性</p>
</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250718021907038.png" alt="image.png"></p>
<p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250718034328455.png" alt="image.png"></p>
<h2 id="特征的重要性："><a href="#特征的重要性：" class="headerlink" title="特征的重要性："></a>特征的重要性：</h2><p>一开始的相关性矩阵（如皮尔逊相关系数）<strong>可以提供一定的参考</strong>，但它<strong>不能充分或准确判断特征对模型预测的“重要性”</strong>，原因如下：</p>
<ol>
<li><p><strong>相关性只是线性关联</strong>：相关系数（如 Pearson）只衡量两个变量之间的<strong>线性关系</strong>。如果一个特征与目标变量有非线性关系（例如 U 型、对数型等），它可能在相关性矩阵中显示“相关性弱”，但在非线性模型（如 LightGBM）中却是一个重要特征。</p>
</li>
<li><p><strong>不能考虑特征交互</strong>：相关性分析是逐个特征和标签的“单变量分析”，不考虑特征之间的联合作用。而像 LightGBM 这样的树模型可以利用多个特征之间的组合关系（交叉特征）来进行分裂和判断。</p>
</li>
<li><p><strong>对目标变量的影响可能被遮蔽</strong>：某些变量与目标变量本身相关性不强，但它与其他强变量结合后具有很强的预测力。相关性矩阵无法体现这种“边际贡献”或“条件重要性”。</p>
</li>
</ol>
<p>相关性矩阵可以用于初筛（如去除明显冗余的高度相关特征），但无法替代模型训练后的特征重要性分析。</p>

        
      </div>

         
    </div>
    
     
  </div>
  
    
<nav id="article-nav">
  <a class="article-nav-btn left "
    
      href="/2025/07/18/%E6%9C%9F%E6%9D%83%EF%BC%9A%E4%B8%80%E5%BC%A0%E6%9C%AA%E6%9D%A5%E4%B9%B0%E5%8D%96%E7%9A%84%E4%BC%98%E6%83%A0%E5%88%B8/"
      title="期权：一张未来买卖的优惠券"
     >
    <i class="fa-solid fa-angle-left"></i>
    <p class="title-text">
      
        期权：一张未来买卖的优惠券
        
    </p>
  </a>
  <a class="article-nav-btn right "
    
      href="/2025/07/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%20ChatGPT/"
      title="机器学习-深入理解 ChatGPT"
     >

    <p class="title-text">
      
        机器学习-深入理解 ChatGPT
        
    </p>
    <i class="fa-solid fa-angle-right"></i>
  </a>
</nav>


  
</article>





    </div>
    <div id="footer-wrapper">
      <footer id="footer">
  
  <div id="footer-info" class="inner">
    
    &copy; 2025 Justin<br>
    Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> & Theme <a target="_blank" rel="noopener" href="https://github.com/saicaca/hexo-theme-vivia">Vivia</a>
  </div>
</footer>

    </div>
    <div class="back-to-top-wrapper">
    <button id="back-to-top-btn" class="back-to-top-btn hide" onclick="topFunction()">
        <i class="fa-solid fa-angle-up"></i>
    </button>
</div>

<script>
    function topFunction() {
        window.scroll({ top: 0, behavior: 'smooth' });
    }
    let btn = document.getElementById('back-to-top-btn');
    function scrollFunction() {
        if (document.body.scrollTop > 600 || document.documentElement.scrollTop > 600) {
            btn.classList.remove('hide')
        } else {
            btn.classList.add('hide')
        }
    }
    window.onscroll = function() {
        scrollFunction();
    }
</script>

  </div>
  <script src="/js/light-dark-switch.js"></script>
</body>
</html>
