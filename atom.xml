<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Justin的技术博客</title>
  
  <subtitle>比世界先发现你发光</subtitle>
  <link href="https://jayli19707.github.io/atom.xml" rel="self"/>
  
  <link href="https://jayli19707.github.io/"/>
  <updated>2025-07-02T03:54:59.623Z</updated>
  <id>https://jayli19707.github.io/</id>
  
  <author>
    <name>Justin</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="https://jayli19707.github.io/2025/08/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E6%8D%AE%E6%A0%87%E8%AE%B0/"/>
    <id>https://jayli19707.github.io/2025/08/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%95%B0%E6%8D%AE%E6%A0%87%E8%AE%B0/</id>
    <published>2025-08-04T19:51:53.683Z</published>
    <updated>2025-07-02T03:54:59.623Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据标记"><a href="#数据标记" class="headerlink" title="数据标记"></a>数据标记</h1><p>机器学习中的“数据标记”（data labeling），是指给原始数据赋予<strong>明确、结构化的标签或目标变量</strong>的过程，使其可以被用于训练<strong>监督学习模型</strong>。</p><p>例如：</p><ul><li><p>图像识别：给每张图片打上“猫”或“狗”的标签；</p></li><li><p>语音识别：给音频文件标注对应的文本内容；</p></li><li><p>文本分类：将一段新闻标记为“体育”或“财经”；</p></li><li><p>信用评估：将用户贷款申请标记为“违约”或“正常”。</p></li></ul><p>简言之，数据标记就是告诉机器“这是什么”，使模型能学到输入与输出之间的对应关系。这个过程通常需要人工完成（尤其是在深度学习中），也可以借助半自动化工具或众包平台（如Amazon Mechanical Turk）进行。数据标记的质量直接影响模型的性能，是监督学习系统成功的关键基础。</p><p>数据标记是为数据分配上下文或含义的活动，以便机器学习算法可以从标签中学习以获得所需的结果。</p><h1 id="什么是数据标签"><a href="#什么是数据标签" class="headerlink" title="什么是数据标签"></a>什么是数据标签</h1><p>为了更好地理解数据标注，我们首先回顾一下机器学习的类型以及需要标注的不同类型的数据。机器学习大致分为三大类：监督学习、无监督学习和强化学习。我们将在“<a href="https://scale.com/guides/data-labeling-authoritative-guide#why-is-data-annotation-important?">数据标注为何重要</a>？ ”一文中更详细地介绍每种类型的机器学习。</p><p>监督式机器学习算法利用大量带标签的数据来“训练”神经网络或模型，使其能够识别数据中对特定应用有用的模式。数据标注员定义数据的“地面实况”注释，机器学习工程师将这些数据输入机器学习算法。例如，数据标注员会为自动驾驶汽车物体识别模型标注给定场景中的所有汽车。然后，机器学习模型将学习识别带标签数据集中的模式。这些模型随后会对从未见过的数据进行预测。</p><h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><h2 id="结构化数据与非结构化数据"><a href="#结构化数据与非结构化数据" class="headerlink" title="结构化数据与非结构化数据"></a>结构化数据与非结构化数据</h2><p>结构化数据是高度组织化的数据，例如关系数据库 (RDBMS) 或电子表格中的信息。客户信息、电话号码、社保号、收入、序列号和产品描述都是结构化数据。</p><p>非结构化数据是未通过预定义模式进行结构化的数据，包括图像、视频、激光雷达、雷达、一些文本数据和音频数据等。</p><h2 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h2><p>相机传感器最初以原始格式输出数据，然后转换为 .png 或更佳的 .jpg 文件，这些文件经过压缩，占用的存储空间比 .png 格式更小，这在处理训练机器学习模型所需的大量数据时是一个值得认真考虑的问题。图像数据也可以从互联网上抓取或由第三方服务收集。图像数据支持许多应用，从人脸识别到制造缺陷检测，再到诊断成像。</p><h2 id="视频"><a href="#视频" class="headerlink" title="视频"></a>视频</h2><p>视频数据也以原始格式来自摄像头传感器，由一系列以 .mp4、.mov 或其他视频文件格式存储的帧组成。MP4 因其文件大小较小（类似于图像数据的 .jpg）而成为机器学习应用的标准。视频数据支持自动驾驶汽车和健身应用等应用。</p><h2 id="3D数据（激光雷达、雷达）"><a href="#3D数据（激光雷达、雷达）" class="headerlink" title="3D数据（激光雷达、雷达）"></a>3D数据（激光雷达、雷达）</h2><p>3D 数据可帮助模型克服传统 RGB 相机传感器等 2D 数据缺乏深度信息的问题，帮助机器学习模型更深入地了解场景。</p><p>LiDAR（光探测和测距）是一种利用光生成场景精确 3D 图像的遥感方法。LiDAR 数据以 RAW 格式和 .las 文件格式的点云形式存储，通常会转换为 JSON 文件格式，以供机器学习应用程序处理。</p><p>雷达（无线电探测和测距）是一种遥感方法，它使用无线电波来确定物体相对于雷达源的距离、角度和径向速度。</p><h2 id="音频"><a href="#音频" class="headerlink" title="音频"></a>音频</h2><p>音频数据通常存储为 .mp3 或 .wav 文件格式，可为您最喜欢的智能助手提供语音识别和实时多语言机器翻译。</p><h2 id="文本"><a href="#文本" class="headerlink" title="文本"></a>文本</h2><p>文本数据由表示信息的字符组成，通常存储在 .txt、.docx 或 .html 文件中。文本为自然语言处理 (NLP) 应用程序提供支持，例如虚拟助手解答您的问题、自动翻译、文本转语音、语音转文本以及文档信息提取。</p><h1 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h1><p>机器学习赋能革命性的应用，而这些应用正是由海量高质量数据驱动的。为了更好地理解数据标记的重要性，了解机器学习的不同类型至关重要：监督学习、无监督学习和强化学习。</p><p><strong>强化学习</strong>利用算法在特定环境中采取行动，以最大化奖励。例如，DeepMind 的 AlphaGo 利用强化学习与自己对弈，最终掌握了围棋技巧，成为历史上最强的棋手。<a href="https://exchange.scale.com/home/blogs/build-better-reinforcement-learning-with-world-models-and-self-attention?__hstc=159041573.e3252e209316c8bf013d9f4d646f1fdd.1660697429166.1660697429166.1660697429166.1&__hssc=159041573.6.1660697429166&__hsfp=1562363153">强化学习</a>不依赖于标记数据，而是最大化奖励函数以实现目标。</p><h1 id="监督学习与无监督学习"><a href="#监督学习与无监督学习" class="headerlink" title="监督学习与无监督学习"></a>监督学习与无监督学习</h1><p><strong>监督学习</strong>是众多最常见、最强大的机器学习应用的背后支撑，从垃圾邮件检测到自动驾驶汽车识别行人、车辆和其他障碍物。监督学习使用大量 <strong>标记数据</strong> 来训练模型，使其能够准确地对数据进行分类或预测结果。</p><p><strong>无监督学习</strong> 有助于分析和聚类 <strong>未标记数据</strong>，从而驱动推荐引擎等系统。这些模型从数据集本身的特征中学习，无需任何标记数据来“教”算法预期的输出。一种常见的方法是 K 均值聚类，其目标是将 n 个观测值划分为 k 个聚类，并将每个观测值分配给最接近的均值。</p><p>虽然无监督学习有许多出色的应用，但监督学习凭借其高准确性和预测能力推动了最具影响力的应用。</p><p>机器学习从业者已将注意力从模型改进转向数据改进，从而创造了一个新范式：以数据为中心的人工智能。现实世界中，只有极小一部分机器学习系统是由机器学习代码组成的。更高质量的数据和更精准的数据标签对于驱动更强大的人工智能至关重要。随着创建更佳机器学习模型的方法转向以数据为中心，了解定义明确的数据流水线的整个流程至关重要，从数据收集方法到数据标记再到数据管理。</p><h1 id="如何注释数据"><a href="#如何注释数据" class="headerlink" title="如何注释数据"></a>如何注释数据</h1><p>要创建高质量的监督学习模型，您需要大量带有高质量标签的数据。那么，如何标记数据呢？首先，您需要确定谁来标记您的数据。组建标记团队有几种不同的方法，每种方法都有其优缺点和注意事项。让我们首先考虑一下，是让人工参与标记过程，还是完全依赖自动化数据标记，或者将这两种方法结合起来。</p><h2 id="1-在人类和机器之间做出选择"><a href="#1-在人类和机器之间做出选择" class="headerlink" title="1.在人类和机器之间做出选择"></a>1.在人类和机器之间做出选择</h2><h3 id="自动数据标记"><a href="#自动数据标记" class="headerlink" title="自动数据标记"></a>自动数据标记</h3><p>对于包含常见对象的大型数据集，可以实现数据标记的自动化或部分自动化。经过训练以标记特定数据类型的自定义机器学习模型将自动将标签应用于数据集。</p><p>尽早建立高质量的真实数据集，才能充分利用自动化数据标记技术。即使拥有高质量的真实数据集，要涵盖所有极端情况并完全信任自动化数据标记技术能够提供最高质量的标签，仍然极具挑战性。</p><h3 id="仅人类标记"><a href="#仅人类标记" class="headerlink" title="仅人类标记"></a>仅人类标记</h3><p>人类在机器学习应用领域中，尤其擅长处理我们关注的许多模态任务，例如视觉和自然语言处理。在许多领域，人类提供的标签质量比自动化数据标注更高。</p><p>然而，人类的经验在不同程度上存在主观性，训练人类对同一数据进行一致标记是一项挑战。此外，对于特定任务，人工标记的速度明显慢于自动标记，成本也更高。</p><h3 id="人在环-HITL-标记"><a href="#人在环-HITL-标记" class="headerlink" title="人在环 (HITL) 标记"></a>人在环 (HITL) 标记</h3><p>人机交互标记利用人类高度专业化的能力来增强自动化数据标记。HITL 数据标记可以采用人工审核的自动标记数据形式，也可以采用主动工具来提高标记效率和质量。自动标记与人机<a href="https://arxiv.org/abs/2109.00574">交互相</a>结合，其准确性和效率几乎总是优于单独使用其中任何一种方式。</p><p>“人在环”（Human-in-the-Loop, 简称 HITL）标记，是指在机器学习的数据标记过程中，<strong>人类与算法协同合作</strong>，共同完成数据标注、纠错或验证的机制。其核心理念是：<strong>人类标注者在训练闭环中起到监督和干预的作用，以提升数据质量与模型性能</strong>。</p><p>具体流程通常如下：</p><ol><li><p><strong>初步标注</strong>：由机器学习模型（可能是预训练模型或旧模型）对数据进行自动初始标注；</p></li><li><p><strong>人工介入</strong>：人类标注员对模型结果进行审核、纠正或补充，特别是对不确定性高或重要性高的数据；</p></li><li><p><strong>反馈循环</strong>：将人工修正过的数据重新喂给模型，用于训练或微调，从而提高模型的准确性；</p></li><li><p><strong>持续优化</strong>：这种“人-机协同”可以不断迭代，构成半自动化的智能标注系统。</p></li></ol><p><strong>优点</strong>：</p><ul><li><p>显著减少纯人工标注成本；</p></li><li><p>提高标注效率和一致性；</p></li><li><p>解决模型不确定性区域的问题；</p></li><li><p>可用于“主动学习”（active learning）框架中，优先标注对模型提升最有价值的数据。</p></li></ul><p><strong>常见应用场景</strong>包括：医疗影像分析、自然语言处理、自动驾驶感知系统、风控系统等对准确性要求极高的领域。</p><p>简而言之，HITL 标记结合了机器的高效率和人的判断力，使数据标注既快又准。</p><h2 id="2-组建标签队伍"><a href="#2-组建标签队伍" class="headerlink" title="2. 组建标签队伍"></a>2. 组建标签队伍</h2><p>如果您选择在数据标注团队中聘用人工（我们强烈建议），您需要弄清楚如何招募标注人员。您会选择聘请内部团队、说服亲朋好友免费标注数据，还是选择第三方标注公司？我们提供了一个框架，帮助您做出以下决定。</p><h4 id="内部团队"><a href="#内部团队" class="headerlink" title="内部团队"></a>内部团队</h4><p>小型初创公司可能没有足够的资金在数据标注方面进行大规模投资，因此最终可能会让包括CEO在内的所有团队成员自行标注数据。对于小型原型而言，这种方法可能有效，但不是一种可扩展的解决方案。</p><p>资金充足的大型机构可能会选择保留内部标记团队，以控制整个数据流程。这种方法虽然控制力强、灵活性高，但成本高昂，管理工作量也大。</p><p>有隐私顾虑或敏感数据的公司可能会选择内部标签团队。虽然这种方法非常有效，但规模化难度较大。</p><p>优点：专业知识、对数据管道的严格控制</p><p>缺点：培训和管理贴标员的费用昂贵</p><h4 id="众包"><a href="#众包" class="headerlink" title="众包"></a>众包</h4><p>众包平台提供了一种快速简便的方法，让大量人员能够快速完成各种任务。这些平台非常适合标记没有隐私问题的数据，例如带有基本注释和说明的开放数据集。但是，如果需要更复杂的标签或涉及敏感数据，那么来自众包平台的未经训练的资源库就不是好选择。众包平台上的资源训练不足，缺乏领域专业知识，通常会导致标记质量低下。</p><p>优点：可以接触到更多的贴标机</p><p>缺点：质量值得怀疑；培训和管理贴标机的开销很大</p><h4 id="第三方数据标签合作伙伴"><a href="#第三方数据标签合作伙伴" class="headerlink" title="第三方数据标签合作伙伴"></a>第三方数据标签合作伙伴</h4><p>第三方数据标签公司能够高效地提供高质量的数据标签，并且通常拥有深厚的机器学习专业知识。这些公司可以作为技术合作伙伴，为您提供整个机器学习生命周期的最佳实践建议，包括如何以最佳方式收集、整理和标记数据。凭借训练有素的资源池以及先进的自动化数据标签工作流程和工具集，这些公司能够以最低的成本提供高质量的标签。</p><p>要在大型数据集上实现极高的质量（99% 以上），需要大量的人力（任何项目都需要超过 1,000 名数据标注员）。仅靠内部团队和众包平台很难以高质量扩展至如此规模。然而，这些公司的成本也可能很高，而且，如果他们不是值得信赖的顾问，可能会说服您标注超出特定应用所需的数据。</p><p>优点：技术专长、成本最低、质量高；顶级数据标签公司拥有  SOC2 和 HIPAA 等<a href="https://scale.com/blog/soc2-hipaa?__hstc=159041573.0e8306a6623d8cb5a8cda8466e0bc1d7.1659467210061.1660627648464.1660655610758.51&__hssc=159041573.1.1660655610758&__hsfp=1562363153">领域相关认证。</a></p><p>缺点：放弃对标签流程的控制；需要拥有适当认证的可信赖合作伙伴来处理敏感数据</p><h2 id="3-选择您的数据标签平台"><a href="#3-选择您的数据标签平台" class="headerlink" title="3. 选择您的数据标签平台"></a>3. 选择您的数据标签平台</h2><p>确定了数据标注人员后，您需要找到一个数据标注平台。平台有很多选择，包括内部构建、使用开源工具或利用商业标注平台。</p><h3 id="开源工具"><a href="#开源工具" class="headerlink" title="开源工具"></a>开源工具</h3><p>这些工具可供任何人免费使用，但商业用途有一些限制。它们非常适合学习和开发机器学习和人工智能、个人项目或测试人工智能的早期商业应用。虽然免费，但它们的缺点是可扩展性或复杂程度不如某些商业平台。本指南中讨论的某些标签类型可能不适用于这些开源工具。</p><p>以下列表具有代表性，但并不详尽，因此可能未包括许多优秀的开源替代方案。</p><ul><li><p><strong>CVAT</strong>：CVAT 最初由英特尔开发，是一个免费的开源网页数据标注平台。CVAT 支持多种标准标签类型，包括矩形、多边形和长方体。CVAT 是一款协作工具，非常适合入门级或小型项目。然而，网页版用户的数据量限制为 500 MB，且每位用户只能执行 10 个任务，这降低了网页版协作功能的吸引力。CVAT 可在本地使用，从而规避这些数据限制。</p></li><li><p><strong>LabelMe</strong>：由 CSAIL 创建的 LabelMe 是一个免费的开源数据标注平台，支持社区协作完成计算机视觉研究数据集。您可以通过标注开放数据集为其他项目做出贡献，也可以下载该工具来标注您的数据。与 CVAT 相比，LabelMe 的功能相当有限，而且网页版不再接受新账户。</p></li><li><p><strong>斯坦福核心 NLP：斯坦福</strong>的 CoreNLP 是一个功能齐全的 NLP 标签和自然语言处理平台，是一个强大的开源工具，提供命名实体识别 (NER)、链接、文本处理等功能。</p></li></ul><p><strong>内部工具</strong></p><p><a href="https://scale.com/blog/build-vs-buy">一些大型组织希望更严格地控​​制其机器学习流程，因此会选择构建内部工具</a>。您可以直接控制要构建的功能、支持所需的用例以及应对特定的挑战。然而，这种方法成本高昂，而且这些工具需要维护和更新才能跟上最新的技术。</p><p><strong>商业平台</strong></p><p>商业平台提供高质量的工具、专业的支持和经验丰富的标签团队，帮助您扩展规模，并提供有关标签和机器学习最佳实践的指导。支持众多客户可以提升平台对所有客户的服务质量，让您能够使用在内部或开源标签平台上可能无法获得的先进功能。</p><p><a href="https://scale.com/studio">Scale Studio</a>是业界领先的商业平台，提供一流的标签基础架构，加速您的团队发展，并配备支持任何用例的标签工具和编排功能，以优化员工绩效。轻松注释、监控并提升数据质量。</p><h1 id="高质量数据注释"><a href="#高质量数据注释" class="headerlink" title="高质量数据注释"></a>高质量数据注释</h1><p>无论您使用什么注释平台，最大限度地提高数据标签的质量对于充分利用机器学习应用程序至关重要。</p><p>经典的计算机科学公理“垃圾进垃圾出”在机器学习中尤为突出，因为数据是学习过程的主要输入。如果数据或标签质量不佳，结果也会不佳。我们旨在为您提供最关键的质量指标，并探讨最佳实践，确保您最大限度地提高标签质量。</p><h3 id="衡量质量的不同方法"><a href="#衡量质量的不同方法" class="headerlink" title="衡量质量的不同方法"></a>衡量质量的不同方法</h3><p>我们涵盖一些最关键的质量指标，然后讨论最佳实践以确保标签流程的质量。</p><h4 id="标签准确度"><a href="#标签准确度" class="headerlink" title="标签准确度"></a>标签准确度</h4><p>分析标签是否严格遵循您的指示并符合您的预期至关重要。例如，假设您已将任务分配给数据标注员，让他们标注行人。在指示中，您指定标签应包含任何携带的物品（例如手机或背包），但不包括任何被推或被拉的物品。当您查看示例任务时，是否遵循了指示，或者标注中是否包含婴儿车（被推）和行李箱（被拉）？</p><p>标注员在基准测试任务上的准确率如何？这些测试任务旨在确定标注员的整体准确率，并让您更有信心地确保其他标注数据也同样准确。不同标注员或不同类型的数据的标注是否一致？如果不同标注员的标注准确率不一致，这可能表明您的指示不明确，或者您需要为标注员提供更多培训。</p><h4 id="模型性能改进"><a href="#模型性能改进" class="headerlink" title="模型性能改进"></a>模型性能改进</h4><p>你的模型在指定任务上的准确率有多高？这个输出指标不仅仅取决于标签质量，数据的数量和质量也起着重要作用，但标签质量也是一个需要考虑的重要因素。</p><p>让我们回顾一些最关键的模型性能指标。</p><h4 id="精确"><a href="#精确" class="headerlink" title="精确"></a>精确</h4><p>准确率定义了阳性识别的正确比例，计算方法如下：</p><p>准确率 &#x3D; 真实阳性 &#x2F; 真实阳性 + 假阳性</p><p>没有产生假阳性的模型的精度为 1.0</p><h4 id="记起"><a href="#记起" class="headerlink" title="记起"></a>记起</h4><p>召回率定义了模型正确识别的实际阳性比例，计算方法如下：</p><p>召回率 &#x3D; 真正例 &#x2F; 真正例 + 假阴性</p><p>不产生假阴性的模型召回率为 1.0</p><h4 id="📦-场景设定：垃圾邮件识别"><a href="#📦-场景设定：垃圾邮件识别" class="headerlink" title="📦 场景设定：垃圾邮件识别"></a>📦 场景设定：垃圾邮件识别</h4><p>假设你有一批 100 封邮件，其中：</p><ul><li><p>实际上有 20 封是垃圾邮件（positive class）</p></li><li><p>80 封是正常邮件（negative class）</p></li></ul><p>你的模型预测出：</p><ul><li><p>15 封邮件是垃圾邮件，其中有 10 封是真的垃圾邮件（true positives），5 封是误报（false positives）</p></li><li><p>剩下的 85 封被判定为正常邮件，但其中其实有 10 封是<strong>漏掉的垃圾邮件</strong>（false negatives）</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250702115455944.png" alt="image.png"></p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;数据标记&quot;&gt;&lt;a href=&quot;#数据标记&quot; class=&quot;headerlink&quot; title=&quot;数据标记&quot;&gt;&lt;/a&gt;数据标记&lt;/h1&gt;&lt;p&gt;机器学习中的“数据标记”（data</summary>
        
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://jayli19707.github.io/2025/08/05/%E6%A0%91%E6%A8%A1%E5%9E%8B/"/>
    <id>https://jayli19707.github.io/2025/08/05/%E6%A0%91%E6%A8%A1%E5%9E%8B/</id>
    <published>2025-08-04T19:51:53.683Z</published>
    <updated>2025-07-23T15:01:57.563Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Entropy"><a href="#Entropy" class="headerlink" title="Entropy"></a>Entropy</h1><p><strong>熵（entropy）不是用来量化分类效果的</strong>，而是用来衡量<strong>信息的不确定性或纯度</strong>，它更多地用于<strong>构建分类模型</strong>中的分裂准则，比如在决策树（如 ID3、C4.5）中选择最佳特征时评估每个特征的“信息增益”。</p><p>具体地说，设一个离散随机变量 $Y$表示类别标签，若其取值为 ${c_1, c_2, \dots, c_k}$，概率分布为 $P(Y &#x3D; c_i) &#x3D; p_i$​，则熵的定义为：<br>$$<br>H(Y)&#x3D;-\sum_{i&#x3D;1}^k p_i \log_2 p_i​<br>$$<br>这个值反映了一个样本集合在类别上的混乱程度。当熵越高时，表示类别分布越不纯；熵为0表示完全纯（即所有样本属于同一类）。因此，熵用于指导模型分裂，而不是直接评估分类效果。</p><h1 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h1><p><strong>信息增益（Information Gain）就是在某个特征划分之后，数据集的“混乱程度”减少的那部分信息量</strong>。这种“混乱程度”是通过**信息熵（entropy）**来衡量的。</p><p>更具体地说：</p><ul><li><p>初始的熵 $H(D)$表示整个数据集中标签（例如“好瓜”与“坏瓜”）的不确定性；</p></li><li><p>当我们用某个特征（比如“色泽”）把数据集划分成若干子集后，每个子集的标签分布可能变得更“纯”（即大部分样本属于同一类），那么子集的熵会降低；</p></li><li><p>这些子集熵的加权平均值是划分后的条件熵 $H(D∣A)$；</p></li><li><p>那么信息增益就是：</p></li></ul><p>$$\text{Gain}(D, A) &#x3D; H(D) - H(D|A)$$</p><p>它表示的正是：<strong>通过特征 A 进行划分，数据集的标签混乱度（熵）减少了多少</strong>。</p><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250723225911556.png" alt="image.png"></p><h1 id="西瓜分类过程"><a href="#西瓜分类过程" class="headerlink" title="西瓜分类过程"></a>西瓜分类过程</h1><p>你有一个西瓜数据集，要判断“是否为好瓜”（是&#x2F;否）。ID3 算法的执行流程如下：</p><ol><li><p><strong>第一层（根节点）</strong>：</p><ul><li><p>对每一个候选特征（色泽、根蒂、敲声、纹理、脐部、触感等）都计算它的信息增益；</p></li><li><p>找出信息增益最大的那个特征，比如说是“纹理”，那就用“纹理”来作为根节点进行划分。</p></li></ul></li><li><p><strong>第二层（纹理的子节点）</strong>：</p><ul><li><p>每个子节点只包含一部分数据（比如纹理&#x3D;清晰的子集）；</p></li><li><p>在这个子集中，继续对剩余特征（不包括已经使用的“纹理”）计算信息增益；</p></li><li><p>选出信息增益最大的特征作为这一层的划分依据。</p></li></ul></li><li><p><strong>第三层、第四层……</strong>：</p><ul><li><p>继续递归这个过程，每次都用“最大信息增益”的特征来划分；</p></li><li><p>一直到子集中标签已经纯净（熵为0），或者特征用完为止</p></li></ul></li></ol><h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250723223826959.png" alt="image.png"><br>随机森林：训练多个决策树，确保稳定</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;Entropy&quot;&gt;&lt;a href=&quot;#Entropy&quot; class=&quot;headerlink&quot;</summary>
        
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://jayli19707.github.io/2025/08/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BB%BA%E6%A8%A1%E6%A1%86%E6%9E%B6/"/>
    <id>https://jayli19707.github.io/2025/08/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BB%BA%E6%A8%A1%E6%A1%86%E6%9E%B6/</id>
    <published>2025-08-04T19:51:53.681Z</published>
    <updated>2025-07-13T18:50:22.419Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-EDA（Exploratory-Data-Analysis）"><a href="#1-EDA（Exploratory-Data-Analysis）" class="headerlink" title="1.EDA（Exploratory Data Analysis）"></a>1.EDA（Exploratory Data Analysis）</h1><table><thead><tr><th>步骤</th><th>操作</th><th>工具&#x2F;方法</th></tr></thead><tbody><tr><td>1️⃣ 数据概览</td><td><code>.shape</code>, <code>.info()</code>, <code>.describe()</code></td><td>Pandas</td></tr><tr><td>2️⃣ 缺失值分析</td><td>缺失值比例、可视化</td><td><code>df.isnull().sum()</code>、heatmap</td></tr><tr><td>3️⃣ 数据分布</td><td>查看每列的分布类型</td><td>直方图（hist）、箱线图（boxplot）</td></tr><tr><td>4️⃣ 标签分析</td><td>标签的分布情况</td><td><code>value_counts()</code>、饼图</td></tr><tr><td>5️⃣ 特征间关系</td><td>相关性矩阵、散点图、groupby 聚合</td><td><code>df.corr()</code>, seaborn pairplot</td></tr><tr><td>6️⃣ 离群值检测</td><td>IQR 方法、Z-score、箱线图</td><td><code>scipy.stats.zscore</code>, 箱线图</td></tr><tr><td>7️⃣ 类别变量分析</td><td>类别分布、target encoding</td><td>条形图、堆叠柱状图等</td></tr></tbody></table>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;1-EDA（Exploratory-Data-Analysis）&quot;&gt;&lt;a href=&quot;#1-EDA（Exploratory-Data-Analysis）&quot; class=&quot;headerlink&quot; title=&quot;1.EDA（Exploratory Data</summary>
        
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://jayli19707.github.io/2025/08/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-Regression/"/>
    <id>https://jayli19707.github.io/2025/08/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-Regression/</id>
    <published>2025-08-04T19:51:53.679Z</published>
    <updated>2025-07-17T18:55:44.924Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Homework-baseline-Q-A"><a href="#Homework-baseline-Q-A" class="headerlink" title="Homework-baseline Q&amp;A"></a>Homework-baseline Q&amp;A</h1><p>作业的 baseline 中看到 loss 在训练过程中不收敛，甚至来回震荡，通常是由以下几个核心原因造成的，其中<strong>学习率（Learning Rate）过高</strong>是最常见的主谋。</p><h3 id="1-学习率-Learning-Rate-过高"><a href="#1-学习率-Learning-Rate-过高" class="headerlink" title="1. 学习率 (Learning Rate) 过高"></a>1. 学习率 (Learning Rate) 过高</h3><ul><li><p><strong>现象</strong>：Loss 在训练初期迅速下降，但很快就开始在一个较高的值附近剧烈震荡，甚至可能突然增大（发散）。</p></li><li><p><strong>原理</strong>：想象一下你正在下山（寻找 loss 的最低点）。学习率决定了你每一步迈出去的“步子”有多大。</p><ul><li>如果步子太大（学习率过高），你可能一步就迈过了山谷的最低点，跑到了对面更高的山坡上。下一步你再往回迈，又可能再次越过最低点。如此反复，你就在谷底来回“横跳”，永远无法稳定在最低点。</li></ul></li><li><p><strong>解决方案</strong>：</p><ul><li><p><strong>调低学习率</strong>：这是最直接的方法。尝试将当前的学习率降低一个数量级，例如从 <code>0.01</code> 降到 <code>0.001</code>，或者从 <code>1e-4</code> 降到 <code>1e-5</code>，看看 loss 曲线是否变得平滑并持续下降。</p></li><li><p><strong>使用学习率衰减 (Learning Rate Decay)</strong>：在训练初期使用较大的学习率让模型快速收敛，随着训练的进行，逐渐减小学习率，让模型可以在最低点附近进行“精细微调”，从而稳定下来。</p></li></ul></li></ul><h3 id="2-数据未进行标准化或归一化-Normalization-Standardization"><a href="#2-数据未进行标准化或归一化-Normalization-Standardization" class="headerlink" title="2. 数据未进行标准化或归一化 (Normalization&#x2F;Standardization)"></a>2. 数据未进行标准化或归一化 (Normalization&#x2F;Standardization)</h3><ul><li><p><strong>现象</strong>：Loss 下降非常缓慢，或者在下降过程中很不稳定。</p></li><li><p><strong>原理</strong>：如果你的输入特征（Features）数值范围差异巨大（例如，一个特征在 0-1 之间，另一个在 1000-10000 之间），会导致损失函数的“等高线图”变成一个非常扁长的椭圆形。在这样的“地形”上，梯度下降算法会走很多“冤枉路”，更新方向会来回摇摆，很难高效地找到最低点。</p></li><li><p><strong>解决方案</strong>：</p><ul><li><p><strong>标准化 (Standardization)</strong>：将每个特征的数据都处理成均值为 0，标准差为 1 的分布。这是最常用的方法。</p></li><li><p><strong>归一化 (Normalization)</strong>：将每个特征的数据缩放到一个固定的范围，比如 [0, 1] 或 [-1, 1]。</p></li><li><p><strong>检查 Baseline 代码</strong>：确保你理解并正确地运行了数据预处理的部分。通常 baseline 会提供这部分代码，但需要你用训练集的均值和标准差去处理验证集和测试集，而不是对每个数据集单独计算。</p></li></ul></li></ul><h3 id="3-Mini-Batch-带来的噪声"><a href="#3-Mini-Batch-带来的噪声" class="headerlink" title="3. Mini-Batch 带来的噪声"></a>3. Mini-Batch 带来的噪声</h3><p>Baseline 代码通常使用 Mini-Batch Gradient Descent 进行训练，而不是一次性将所有数据喂给模型。</p><ul><li><p><strong>现象</strong>：你看到的 loss 是在每个 batch 计算后打印出来的，它本身就是有噪声的，所以会上下波动。</p></li><li><p><strong>原理</strong>：每个 mini-batch 只是全体数据的一个小子集，用它计算出的梯度只是对“全局真实梯度”的一个近似估计。因此，每个 batch 之间的 loss 有波动是<strong>完全正常</strong>的。我们真正关心的是<strong>整体趋势</strong>是否在下降。</p></li><li><p><strong>解决方案</strong>：</p><ul><li><p><strong>观察 Epoch Loss</strong>：不要只看每个 step&#x2F;batch 的 loss。你应该计算并观察<strong>每个 epoch (所有 batch 跑完一遍) 的平均 loss</strong>。这个值应该呈现出平滑下降并最终收敛的趋势。</p></li><li><p><strong>观察验证集 Loss (Validation Loss)</strong>：验证集 loss 更能反映模型的泛化能力，并且由于它通常是在整个验证集上计算的，所以曲线会比训练过程中的 batch loss 平滑得多。如果验证集 loss 能够稳定下降并收敛，那你的模型训练就是健康的。</p></li></ul></li></ul><h3 id="4-其他可能原因"><a href="#4-其他可能原因" class="headerlink" title="4. 其他可能原因"></a>4. 其他可能原因</h3><ul><li><p><strong>数据本身有脏数据&#x2F;异常值 (Outliers)</strong>：某些样本的数值特别异常，会导致计算出的梯度突然变得很大，让模型“学歪了”，引起 loss 剧烈波动。</p></li><li><p><strong>Batch Size 过小</strong>：过小的 Batch Size 会导致梯度估计的方差过大，使得训练过程震荡更剧烈。可以尝试适当增大 Batch Size。</p></li><li><p><strong>代码 Bug</strong>：检查一下你在实现模型、损失函数或梯度更新时是否有笔误。</p></li></ul><h1 id="特征值选取-sklearn"><a href="#特征值选取-sklearn" class="headerlink" title="特征值选取(sklearn)"></a>特征值选取(sklearn)</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">select_feat</span>(<span class="params">train_data, valid_data, test_data, select_all=<span class="literal">True</span></span>):</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Selects useful features to perform regression&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    y_train, y_valid = train_data[:,-<span class="number">1</span>], valid_data[:,-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-<span class="number">1</span>], valid_data[:,:-<span class="number">1</span>], test_data</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> select_all:</span><br><span class="line"></span><br><span class="line">        feat_idx = <span class="built_in">list</span>(<span class="built_in">range</span>(raw_x_train.shape[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">        feat_idx = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">35</span>, raw_x_train.shape[<span class="number">1</span>])) <span class="comment"># <span class="doctag">TODO:</span> Select suitable feature columns.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid</span><br></pre></td></tr></table></figure><h2 id="如何选特征："><a href="#如何选特征：" class="headerlink" title="如何选特征："></a>如何选特征：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  <span class="comment"># 确保导入 numpy</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest, f_regression</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- 数据加载和准备 (这部分没问题) ---</span></span><br><span class="line">feature_new = pd.read_csv(<span class="string">&#x27;covid_train.csv&#x27;</span>)</span><br><span class="line">x_data = feature_new.iloc[:, <span class="number">1</span>:<span class="number">89</span>]</span><br><span class="line">y_data = feature_new.iloc[:, -<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- 特征选择 ---</span></span><br><span class="line">k = <span class="number">20</span></span><br><span class="line">selector = SelectKBest(f_regression, k=k)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拟合数据</span></span><br><span class="line">selector.fit(x_data, y_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接获取最佳的 k 个特征的索引</span></span><br><span class="line">selected_feat_indices = selector.get_support(indices=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 你可以直接使用这个索引列表</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最佳的20个特征的索引是:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(selected_feat_indices)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果你想用它来筛选你的特征名，可以这样做</span></span><br><span class="line">selected_feat_names = x_data.columns[selected_feat_indices]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n最佳的20个特征的名称是:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(selected_feat_names)</span><br></pre></td></tr></table></figure><ul><li><p><strong><code>.scores_</code></strong> 告诉你<strong>每个特征的“分数”是多少</strong>，让你知道每个特征与目标值的相关性强弱。</p></li><li><p><strong><code>.get_support()</code></strong> 告诉你<strong>哪些特征“被选中”了</strong>，是一个直接的结果。</p></li></ul><h2 id="最终改后代码："><a href="#最终改后代码：" class="headerlink" title="最终改后代码："></a>最终改后代码：</h2><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250717054946635.png" alt="image.png"><br>最后k&#x3D;17是bossline</p><h1 id="修改网结构和修改优化器"><a href="#修改网结构和修改优化器" class="headerlink" title="修改网结构和修改优化器"></a>修改网结构和修改优化器</h1><p>原本模型可能层数少、每层维度小，无法学习足够复杂的映射关系。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">My_Model</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim</span>):</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>(My_Model, <span class="variable language_">self</span>).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span> modify model&#x27;s structure, be aware of dimensions.</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.layers = nn.Sequential(</span><br><span class="line"></span><br><span class="line">            nn.Linear(input_dim, <span class="number">16</span>),</span><br><span class="line"></span><br><span class="line">            nn.ReLU(),</span><br><span class="line"></span><br><span class="line">            nn.Linear(<span class="number">16</span>, <span class="number">8</span>),</span><br><span class="line"></span><br><span class="line">            nn.ReLU(),</span><br><span class="line"></span><br><span class="line">            nn.Linear(<span class="number">8</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line"></span><br><span class="line">        x = <span class="variable language_">self</span>.layers(x)</span><br><span class="line"></span><br><span class="line">        x = x.squeeze(<span class="number">1</span>) <span class="comment"># (B, 1) -&gt; (B)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">trainer</span>(<span class="params">train_loader, valid_loader, model, config, device</span>):</span><br><span class="line">  </span><br><span class="line">    criterion = nn.MSELoss(reduction=<span class="string">&#x27;mean&#x27;</span>) </span><br><span class="line">    <span class="comment"># Define your loss function, do not modify this.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define your optimization algorithm.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> Please check https://pytorch.org/docs/stable/optim.html to get more available algorithms.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> L2 regularization (optimizer(weight decay...) or implement by your self).</span></span><br><span class="line">    optimizer = torch.optim.SGD(model.parameters(), lr=config[<span class="string">&#x27;learning_rate&#x27;</span>], momentum=<span class="number">0.7</span>)</span><br></pre></td></tr></table></figure><h3 id="1-修改神经网络结构"><a href="#1-修改神经网络结构" class="headerlink" title="1. 修改神经网络结构"></a>1. 修改神经网络结构</h3><ul><li><p><strong>做了什么</strong>：</p><ul><li><p>它定义了一个包含三个全连接层 (<code>nn.Linear</code>) 的神经网络。</p></li><li><p><strong>结构是</strong>：输入层 → 隐藏层1 → 隐藏层2 → 输出层。</p></li><li><p><strong>网络宽度&#x2F;神经元数量</strong>：</p><ul><li><p><code>nn.Linear(input_dim, 64)</code>：接收输入数据，并将其转换为一个64维的向量（第一层有64个神经元）。</p></li><li><p><code>nn.Linear(64, 16)</code>：接收上面的64维向量，并压缩成一个16维的向量（第二层有16个神经元）。</p></li><li><p><code>nn.Linear(16, 1)</code>：接收16维向量，并最终输出1个数值（用于回归预测）。</p></li></ul></li><li><p><strong>激活函数</strong>：在层与层之间使用了 <code>nn.ReLU()</code>，这是为了给模型增加非线性能力，让它可以学习更复杂的数据模式。</p></li></ul></li></ul><table><thead><tr><th>任务类型</th><th>推荐层数</th><th>说明</th></tr></thead><tbody><tr><td>简单回归 &#x2F; 分类（结构化数据）</td><td>1–3 层</td><td>64 → 16 → 1 是经典配置</td></tr><tr><td>特征维度大 &#x2F; 非线性强</td><td>3–5 层</td><td>可以逐层减少宽度，如 128 → 64 → 32 → 8</td></tr><tr><td>图像分类（CNN）</td><td>10 层以上</td><td>可用 ResNet、VGG 等已有结构</td></tr><tr><td>文本分类（Transformer）</td><td>通常 ≥ 6 层 encoder</td><td>层数越多捕捉的语义越深</td></tr></tbody></table><h3 id="2-修改优化器和学习率"><a href="#2-修改优化器和学习率" class="headerlink" title="2. 修改优化器和学习率"></a>2. 修改优化器和学习率</h3><ul><li><p><strong>做了什么</strong>：- <code>weight_decay=1e-3</code> 相当于 L2 正则化，有助于缓解过拟合。</p><ul><li><strong>更换优化器</strong>：原始方案用的是<strong>SGD</strong>（随机梯度下降法）。新的代码 <code>optimizer = torch.optim.Adam(...)</code> 启用了 <strong>Adam</strong> 优化器。</li><li><strong>Adam 优化器</strong>融合了动量（momentum）与自适应学习率（AdaGrad 思想），在大多数任务中比 SGD 收敛更快、更稳定；</li></ul></li></ul><h2 id="3-学习率"><a href="#3-学习率" class="headerlink" title="3.学习率"></a>3.学习率</h2><ul><li>原先使用 <code>1e-5</code> 的学习率太小导致“无法收敛”，即模型更新步伐太小，训练效果几乎没有提升；</li></ul><h3 id="CosineAnnealingWarmRestarts："><a href="#CosineAnnealingWarmRestarts：" class="headerlink" title="CosineAnnealingWarmRestarts："></a>CosineAnnealingWarmRestarts：</h3><ul><li><p><strong>余弦退火调度器</strong>让学习率逐步减小（从高值逐步衰减到 eta_min）；</p></li><li><p><code>WarmRestarts</code> 机制：每隔一定轮数重新将学习率拉高，有助于<strong>跳出局部最优</strong>；</p></li><li><p><code>T_0=2, T_mult=2</code> 表示第一次退火周期为2轮，每次重启周期翻倍。</p></li></ul><h3 id="学习率乘以-75？"><a href="#学习率乘以-75？" class="headerlink" title="学习率乘以 75？"></a>学习率乘以 75？</h3><ul><li><p>表明默认学习率（如 1e-5）太小，收敛太慢或模型停滞；</p></li><li><p>放大初始学习率后再用 cosine 调度衰减，更灵活地调控收敛速度</p></li></ul><h3 id="最终改后代码：-1"><a href="#最终改后代码：-1" class="headerlink" title="最终改后代码："></a>最终改后代码：</h3><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250717055141799.png" alt="image.png"></p><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250717055100400.png" alt="image.png"></p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;Homework-baseline-Q-A&quot;&gt;&lt;a href=&quot;#Homework-baseline-Q-A&quot; class=&quot;headerlink&quot; title=&quot;Homework-baseline Q&amp;amp;A&quot;&gt;&lt;/a&gt;Homework-baseline</summary>
        
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://jayli19707.github.io/2025/08/05/%E6%89%8B%E6%92%95%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>https://jayli19707.github.io/2025/08/05/%E6%89%8B%E6%92%95%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</id>
    <published>2025-08-04T19:51:53.675Z</published>
    <updated>2025-08-02T16:19:55.785Z</updated>
    
    <content type="html"><![CDATA[<h1 id="理解里面的广播细节点："><a href="#理解里面的广播细节点：" class="headerlink" title="理解里面的广播细节点："></a>理解里面的广播细节点：</h1><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250803001932742.png" alt="image.png"></p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;理解里面的广播细节点：&quot;&gt;&lt;a href=&quot;#理解里面的广播细节点：&quot; class=&quot;headerlink&quot; title=&quot;理解里面的广播细节点：&quot;&gt;&lt;/a&gt;理解里面的广播细节点：&lt;/h1&gt;&lt;p&gt;&lt;img</summary>
        
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://jayli19707.github.io/2025/08/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-Classification/"/>
    <id>https://jayli19707.github.io/2025/08/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-Classification/</id>
    <published>2025-08-04T19:51:53.675Z</published>
    <updated>2025-07-21T22:29:31.059Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Classification和regression区别"><a href="#Classification和regression区别" class="headerlink" title="Classification和regression区别"></a>Classification和regression区别</h1><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250716021451208.png" alt="image.png"><br>如果有偏移很多的点，regression会为了减少残差，而使得函数趋向减少error的方向。</p><h1 id="选择loss-function"><a href="#选择loss-function" class="headerlink" title="选择loss function"></a>选择loss function</h1><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250716021907362.png" alt="image.png"></p><p><img src="/" alt="Uploading file...ilh93"></p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;Classification和regression区别&quot;&gt;&lt;a href=&quot;#Classification和regression区别&quot; class=&quot;headerlink&quot;</summary>
        
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://jayli19707.github.io/2025/08/05/%E5%93%88%E5%B8%8C%E8%A1%A8/"/>
    <id>https://jayli19707.github.io/2025/08/05/%E5%93%88%E5%B8%8C%E8%A1%A8/</id>
    <published>2025-08-04T19:51:53.673Z</published>
    <updated>2025-08-03T14:50:57.733Z</updated>
    
    <content type="html"><![CDATA[<h1 id="哈希表的查表流程"><a href="#哈希表的查表流程" class="headerlink" title="哈希表的查表流程"></a>哈希表的查表流程</h1><h2 id="Step-1：哈希定位（Hashing）"><a href="#Step-1：哈希定位（Hashing）" class="headerlink" title="Step 1：哈希定位（Hashing）"></a>Step 1：<strong>哈希定位（Hashing）</strong></h2><p>通过 <code>hash(key) % N</code>（模表长），快速定位到桶数组中的某个位置。</p><p>📌 即便多个 key 哈希结果相同，它们都只会落到同一个桶里 —— 所以时间复杂度仍然近似 O(1)。</p><hr><h2 id="Step-2：逐个比较-key（冲突处理）"><a href="#Step-2：逐个比较-key（冲突处理）" class="headerlink" title="Step 2：逐个比较 key（冲突处理）"></a>Step 2：<strong>逐个比较 key（冲突处理）</strong></h2><p>由于冲突可能发生，所以在该桶中的链表（或数组）中：</p><ul><li><p>遍历每一个节点的 key；</p></li><li><p>用 <code>==</code> 或 <code>__eq__()</code> 判断是不是我们要找的 key。</p></li></ul><p>这一步保证了即使哈希值一样，<strong>最终提取的也是对应 key 的正确 value</strong>。</p><hr><h2 id="Step-3：返回-value（或更新、删除）"><a href="#Step-3：返回-value（或更新、删除）" class="headerlink" title="Step 3：返回 value（或更新、删除）"></a>Step 3：<strong>返回 value（或更新、删除）</strong></h2><p>如果找到了匹配的 key，就可以：</p><ul><li><p>读取它的 <code>value</code>（查找）；</p></li><li><p>修改它的 <code>value</code>（更新）；</p></li><li><p>从链表中删掉它（删除）。</p></li></ul><h1 id="循环录入哈希字典"><a href="#循环录入哈希字典" class="headerlink" title="循环录入哈希字典"></a>循环录入哈希字典</h1><p> <code>dict[key] = value</code> 的语法含义就是：<br>用 <code>key</code> 作为键，在字典中存储对应的 <code>value</code>。</p><hr><h3 id="举个例子："><a href="#举个例子：" class="headerlink" title="举个例子："></a>举个例子：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = ListNode(<span class="number">3</span>)</span><br><span class="line">b = ListNode(<span class="number">2</span>)</span><br><span class="line">a.<span class="built_in">next</span> = b</span><br><span class="line"></span><br><span class="line">my_dict = &#123;&#125;</span><br><span class="line">my_dict[a] = <span class="number">0</span></span><br><span class="line">my_dict[b] = <span class="number">1</span></span><br></pre></td></tr></table></figure><p>此时字典 <code>my_dict</code> 结构大致是这样的（逻辑视角）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &lt;ListNode <span class="built_in">object</span> at <span class="number">0x1234</span>...&gt;: <span class="number">0</span>,</span><br><span class="line">    &lt;ListNode <span class="built_in">object</span> at <span class="number">0x5678</span>...&gt;: <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h3 id="补充说明："><a href="#补充说明：" class="headerlink" title="补充说明："></a>补充说明：</h3><p>你还可以用 <code>.get()</code> 来读取值，避免 key 不存在时报错：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">my_dict.get(node, default_value)</span><br></pre></td></tr></table></figure><hr>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;哈希表的查表流程&quot;&gt;&lt;a href=&quot;#哈希表的查表流程&quot; class=&quot;headerlink&quot; title=&quot;哈希表的查表流程&quot;&gt;&lt;/a&gt;哈希表的查表流程&lt;/h1&gt;&lt;h2 id=&quot;Step-1：哈希定位（Hashing）&quot;&gt;&lt;a</summary>
        
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="https://jayli19707.github.io/2025/08/05/Accelerating%20Data%20Science%20with%20AI/"/>
    <id>https://jayli19707.github.io/2025/08/05/Accelerating%20Data%20Science%20with%20AI/</id>
    <published>2025-08-04T19:51:53.671Z</published>
    <updated>2025-08-04T19:41:41.553Z</updated>
    
    <content type="html"><![CDATA[<h2 id="搞懂Docker核心概念"><a href="#搞懂Docker核心概念" class="headerlink" title="搞懂Docker核心概念"></a><strong>搞懂Docker核心概念</strong></h2><h4 id="第一站：初识Cursor与开发容器-Dev-Container"><a href="#第一站：初识Cursor与开发容器-Dev-Container" class="headerlink" title="第一站：初识Cursor与开发容器(Dev Container)"></a><strong>第一站：初识Cursor与开发容器(Dev Container)</strong></h4><p>一切的开端，是AI为我总结了视频内容：一个名为Cursor的AI代码编辑器，可以通过自然语言，自动为一个项目配置好包含Docker的<strong>开发容器（Dev Container）</strong>。</p><p>我的第一个疑问是：“这不就是把项目打个包吗？有什么用？”</p><p><strong>学习笔记1：为什么需要开发容器？为了解决“环境一致性”</strong></p><p>我了解到，这“简单的一步”解决了开发者最大的噩梦之一：“在我电脑上能跑，在你电脑上就不行”。</p><ul><li><p><strong>传统痛点</strong>：团队成员的电脑系统、软件版本、库版本各不相同，导致代码无法统一运行，大量时间浪费在搭建和调试环境上。</p></li><li><p><strong>容器化解决方案</strong>：通过一个配置文件（<code>devcontainer.json</code>和<code>docker-compose.yml</code>），将项目的运行环境（操作系统、Python版本、所有依赖库、甚至数据库服务）代码化。</p></li><li><p><strong>最终效果</strong>：任何拿到这个项目的人，只需一键（视频中是Cursor的AI指令，传统方法是<code>docker-compose up</code>），就能在几分钟内复刻出一个与我100%一致、完全隔离的开发环境。</p></li></ul><h4 id="第二站：深入Docker的核心——Image与Container之辨"><a href="#第二站：深入Docker的核心——Image与Container之辨" class="headerlink" title="第二站：深入Docker的核心——Image与Container之辨"></a><strong>第二站：深入Docker的核心——Image与Container之辨</strong></h4><p>为了搞清楚这一切是如何实现的，我决定深入学习Docker本身。我首先要理解最基础的两个概念：<code>Dockerfile</code>与<code>Image</code>（镜像）和<code>Container</code>（容器）的关系。</p><p><strong>学习笔记2：一个绝佳的比喻——蓝图、新车与行驶的车</strong></p><p>经过几轮问答，我们最终确定了一个非常清晰的比喻：</p><ol><li><p>Dockerfile &#x3D; 建筑蓝图&#x2F;设计图</p><p> 它是一份纯文本文件，里面写满了指令，详细描述了一个应用程序的“标准运行环境”应该是什么样的。它只是一个静态的计划。</p></li><li><p>Image (镜像) &#x3D; 一辆根据蓝图造好的新车</p><p> 当你运行docker build命令时，Docker会严格按照Dockerfile（蓝图）去构建，最终得到一个镜像。这个镜像就像一辆刚从生产线下来的、崭新的、完整的车。它是静态的、只读的、包含了所有必要部件的模板。</p></li><li><p>Container (容器) &#x3D; 一辆正在路上行驶的车</p><p> 当你运行docker run命令时，Docker会根据Image（新车模板）创建一个容器。这个容器是动态的、活生生的、正在运行的实例。它在消耗资源（CPU&#x2F;内存），有自己的状态（日志、临时文件），并对外提供服务。你可以根据一个镜像，创建无数个互不干扰的容器，就像马路上有成千上万辆同型号的车在行驶。</p></li></ol><h4 id="第三站：打通“次元壁”——理解端口映射-Port-Mapping"><a href="#第三站：打通“次元壁”——理解端口映射-Port-Mapping" class="headerlink" title="第三站：打通“次元壁”——理解端口映射 (Port Mapping)"></a><strong>第三站：打通“次元壁”——理解端口映射 (Port Mapping)</strong></h4><p>我很快遇到了下一个逻辑难题：“既然容器是隔离的，那我电脑上的浏览器，怎么访问到容器里运行的程序呢？”</p><p><strong>学习笔记3：端口映射就是“酒店总机”或“快递代收点”</strong></p><p>这里的关键在于理解两个隔离的网络世界：<strong>主机世界</strong>和<strong>容器世界</strong>。</p><ul><li><p><strong>目标</strong>：让主机世界的浏览器，能访问到容器世界里运行在某个端口（比如<code>8008</code>）上的程序。</p></li><li><p><strong>问题</strong>：两个世界默认互不相通。</p></li><li><p><strong>解决方案</strong>：“构建一座桥梁”，也就是<strong>端口映射</strong>。</p></li></ul><p>通过docker run -p 12345:8008命令，我们建立了一条规则：</p><p>“所有发送到主机12345端口的网络请求，请全部转交给容器的8008端口。”</p><p>这个操作就像酒店前台的总机，把外部打给某个特定分机的电话，准确无误地转接给对应的房间。这样，我们就通过这个“桥梁”，打通了主机与容器之间的通信。</p><h4 id="第四站：从单打独斗到团队协作——docker-compose-yml的威力"><a href="#第四站：从单打独斗到团队协作——docker-compose-yml的威力" class="headerlink" title="第四站：从单打独斗到团队协作——docker-compose.yml的威力"></a><strong>第四站：从单打独斗到团队协作——<code>docker-compose.yml</code>的威力</strong></h4><p>当我理解了如何运行一个容器后，一个实际问题浮出水面：“我把项目给同事时，难道要让他手动输入一长串复杂的<code>docker run</code>命令吗？”</p><p><strong>学习笔记4：<code>docker-compose.yml</code>是标准化的“启动说明书”</strong></p><p>这个问题的完美答案就是<code>docker-compose.yml</code>。</p><ul><li><p><strong>对于简单应用</strong>：<code>Dockerfile</code>定义了<strong>如何构建镜像</strong>。</p></li><li><p><strong>对于复杂应用或团队协作</strong>：<code>docker-compose.yml</code>定义了<strong>如何运行容器（或一组容器）</strong>。</p></li></ul><p>在这个YAML文件里，我们可以把所有运行参数都固化下来，包括：</p><ul><li><p>要运行的服务以及它们各自的镜像。</p></li><li><p>端口映射规则（比如<code>ports: - &quot;12345:8008&quot;</code>）。</p></li><li><p>数据卷挂载。</p></li><li><p>容器间的网络关系和依赖。</p></li></ul><p>最终，我的同事拿到我的项目后，不再需要知道任何复杂的<code>docker run</code>命令。他只需要在项目根目录下，运行一句<strong>永不改变的简单命令：<code>docker-compose up</code></strong>，就能得到和我一模一样的、正在运行的应用。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;搞懂Docker核心概念&quot;&gt;&lt;a href=&quot;#搞懂Docker核心概念&quot; class=&quot;headerlink&quot; title=&quot;搞懂Docker核心概念&quot;&gt;&lt;/a&gt;&lt;strong&gt;搞懂Docker核心概念&lt;/strong&gt;&lt;/h2&gt;&lt;h4</summary>
        
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Leetcode-141.环形链表</title>
    <link href="https://jayli19707.github.io/2025/08/02/Leetcode-141.%E7%8E%AF%E5%BD%A2%E9%93%BE%E8%A1%A8/"/>
    <id>https://jayli19707.github.io/2025/08/02/Leetcode-141.%E7%8E%AF%E5%BD%A2%E9%93%BE%E8%A1%A8/</id>
    <published>2025-08-02T13:25:37.754Z</published>
    <updated>2025-08-02T13:25:30.969Z</updated>
    
    <content type="html"><![CDATA[<h1 id="dict和set"><a href="#dict和set" class="headerlink" title="dict和set"></a>dict和set</h1><h3 id="1-结构上的区别："><a href="#1-结构上的区别：" class="headerlink" title="1. 结构上的区别："></a>1. 结构上的区别：</h3><table><thead><tr><th>类型</th><th>键（Key）</th><th>值（Value）</th><th>示例</th></tr></thead><tbody><tr><td><code>dict</code></td><td>有</td><td>有</td><td><code>{'a': 1, 'b': 2}</code></td></tr><tr><td><code>set</code></td><td>有</td><td><strong>没有</strong></td><td><code>{'a', 'b'}</code></td></tr></tbody></table><ul><li><p><code>dict</code> 是**键值对（key-value）**的集合。</p></li><li><p><code>set</code> 是<strong>只有键（key）没有值</strong>的一组唯一元素。</p></li></ul><hr><h3 id="2-用途上的区别："><a href="#2-用途上的区别：" class="headerlink" title="2. 用途上的区别："></a>2. 用途上的区别：</h3><ul><li><p><code>dict</code> 用于<strong>建立键与值的映射</strong>，例如地址到位置、用户名到ID等。</p></li><li><p><code>set</code> 用于<strong>快速查找是否存在</strong>、<strong>去重</strong>、<strong>集合运算</strong>等，例如判断某个元素是否出现过。</p></li></ul><hr><h3 id="3-操作上的区别："><a href="#3-操作上的区别：" class="headerlink" title="3. 操作上的区别："></a>3. 操作上的区别：</h3><h4 id="dict-常见操作："><a href="#dict-常见操作：" class="headerlink" title="dict 常见操作："></a><code>dict</code> 常见操作：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">d = {<span class="string">'x'</span>: <span class="number">1</span>, <span class="string">'y'</span>: <span class="number">2</span>}</span><br><span class="line">d[<span class="string">'z'</span>] = <span class="number">3</span>             <span class="comment"># 添加键值对</span></span><br><span class="line">value = d.get(<span class="string">'x'</span>)     <span class="comment"># 查找键对应的值</span></span><br><span class="line"><span class="keyword">del</span> d[<span class="string">'y'</span>]             <span class="comment"># 删除键值对</span></span><br></pre></td></tr></table></figure><h4 id="set-常见操作："><a href="#set-常见操作：" class="headerlink" title="set 常见操作："></a><code>set</code> 常见操作：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s = {<span class="string">'a'</span>, <span class="string">'b'</span>}</span><br><span class="line">s.add(<span class="string">'c'</span>)             <span class="comment"># 添加元素</span></span><br><span class="line">s.remove(<span class="string">'a'</span>)          <span class="comment"># 删除元素</span></span><br><span class="line">exists = <span class="string">'b'</span> <span class="keyword">in</span> s      <span class="comment"># 判断是否存在</span></span><br></pre></td></tr></table></figure><hr><h3 id="4-底层实现的共同点和不同点："><a href="#4-底层实现的共同点和不同点：" class="headerlink" title="4. 底层实现的共同点和不同点："></a>4. 底层实现的共同点和不同点：</h3><ul><li><p>相同点：都使用<strong>哈希表</strong>，所以查找、插入、删除的时间复杂度平均为 O(1)O(1)。</p></li><li><p>不同点：</p><ul><li><p><code>dict</code> 哈希表存储的是 (key, value) 对，插入更复杂。</p></li><li><p><code>set</code> 只存 key，没有 value，占用空间略小，操作略快。</p></li></ul></li></ul><hr><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250802212208715.png" alt="image.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"># Definition for singly-linked list.</span><br><span class="line"></span><br><span class="line"># class ListNode:</span><br><span class="line"></span><br><span class="line">#     def __init__(self, x):</span><br><span class="line"></span><br><span class="line">#         self.val = x</span><br><span class="line"></span><br><span class="line">#         self.next = None</span><br><span class="line">class Solution:</span><br><span class="line"></span><br><span class="line">    def hasCycle(self, head: Optional[ListNode]) -&gt; bool:</span><br><span class="line"></span><br><span class="line">        seen=set()</span><br><span class="line"></span><br><span class="line">        while head:</span><br><span class="line"></span><br><span class="line">            if head in seen:</span><br><span class="line"></span><br><span class="line">                return True</span><br><span class="line"></span><br><span class="line">            seen.add(head)</span><br><span class="line"></span><br><span class="line">            head=head.next</span><br><span class="line"></span><br><span class="line">        return False</span><br></pre></td></tr></table></figure><h3 id="思路："><a href="#思路：" class="headerlink" title="思路："></a>思路：</h3><p>利用集合 <code>seen</code> 记录遍历过程中出现过的节点引用（即内存地址）。若遍历某个节点时发现它已经在 <code>seen</code> 中，说明这个节点之前已经访问过，即链表存在环。否则，将当前节点加入集合并继续向后遍历。</p><hr><h3 id="🧠解题过程："><a href="#🧠解题过程：" class="headerlink" title="🧠解题过程："></a>🧠解题过程：</h3><ol><li><p>创建一个空集合 <code>seen</code>；</p></li><li><p>从头节点 <code>head</code> 开始，逐个遍历每个节点；</p></li><li><p>如果当前节点 <code>head</code> 已存在于 <code>seen</code> 中，说明链表出现了环，返回 <code>True</code>；</p></li><li><p>否则将当前节点加入集合，继续向下一个节点遍历；</p></li><li><p>若遍历到 <code>None</code>，说明链表无环，返回 <code>False</code>。</p></li></ol>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;dict和set&quot;&gt;&lt;a href=&quot;#dict和set&quot; class=&quot;headerlink&quot; title=&quot;dict和set&quot;&gt;&lt;/a&gt;dict和set&lt;/h1&gt;&lt;h3 id=&quot;1-结构上的区别：&quot;&gt;&lt;a href=&quot;#1-结构上的区别：&quot;</summary>
        
      
    
    
    
    <category term="Leetcode" scheme="https://jayli19707.github.io/categories/Leetcode/"/>
    
    
  </entry>
  
  <entry>
    <title>Leetcode-234.回文链表</title>
    <link href="https://jayli19707.github.io/2025/08/02/Leetcode-234.%E5%9B%9E%E6%96%87%E9%93%BE%E8%A1%A8/"/>
    <id>https://jayli19707.github.io/2025/08/02/Leetcode-234.%E5%9B%9E%E6%96%87%E9%93%BE%E8%A1%A8/</id>
    <published>2025-08-01T18:00:00.000Z</published>
    <updated>2025-08-01T17:59:35.111Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250802015304836.png" alt="image.png"></p><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>判断链表是否为回文，可以通过快慢指针找到链表中点，然后反转后半部分链表，接着从头和反转后的部分逐一比较值是否相等。为了达到 O(1) 空间复杂度，我们不能使用数组或栈辅助存储值，必须在原链表上操作。</p><h2 id="解题过程"><a href="#解题过程" class="headerlink" title="解题过程"></a>解题过程</h2><p>边界判断：如果链表为空或只有一个节点，直接返回 True。</p><p>找中点：使用快慢指针，fast 每次走两步，slow 每次走一步，slow 停下时刚好位于链表中点。</p><p>反转后半部分：从 slow 开始反转链表，获得 reverse_head。</p><p>比较是否相等：用两个指针，分别从 head 和 reverse_head 出发，同时遍历并比较值是否一致。</p><p>返回结果：只要有任意一组值不一致，就返回 False；否则返回 True。</p><h2 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h2><p>时间复杂度：O(n)<br>找中点：O(n)<br>反转链表：O(n)<br>比较两半链表：O(n)<br>空间复杂度：O(1)<br>只用了若干指针变量，无额外数据结构</p><h2 id="实现链表翻转功能"><a href="#实现链表翻转功能" class="headerlink" title="实现链表翻转功能"></a>实现链表翻转功能</h2><p>双指针解法：<br>定义好一个cur和一个pre的指针<br>cur=head<br>pre=none<br>现在的目的是把链表的指向改变。<br>先考虑第一个元素时<br>在链没断之前，先用temp指针保存好第二个节点。<br>修改第一个节点的指向。直接就是cur.next=pre,第一个节点指向pre的节点。<br>紧接着pre后移动一位移到cur，cur移动到temp</p><h2 id="实现找中点功能"><a href="#实现找中点功能" class="headerlink" title="实现找中点功能"></a>实现找中点功能</h2><p>找中点：<br>使用快慢指针，fast 每次走两步，slow 每次走一步，slow 停下时刚好位于链表中点。偶数个节点，最终选的是靠右边的节点。终止的信号是快指针或者快指针的next为空指针。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reverseList</span>(<span class="params">self,head: <span class="type">Optional</span>[ListNode]</span>) -&gt; <span class="type">Optional</span>[ListNode]:</span><br><span class="line"></span><br><span class="line">        pre,cur=<span class="literal">None</span>,head</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> cur:</span><br><span class="line"></span><br><span class="line">            temp=cur.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">            cur.<span class="built_in">next</span>=pre</span><br><span class="line"></span><br><span class="line">            pre=cur</span><br><span class="line"></span><br><span class="line">            cur=temp</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> pre</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">middleNote</span>(<span class="params">self,head: <span class="type">Optional</span>[ListNode]</span>) -&gt; <span class="type">Optional</span>[ListNode]:</span><br><span class="line"></span><br><span class="line">        slow=fast=head</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> fast <span class="keyword">and</span> fast.<span class="built_in">next</span>:</span><br><span class="line"></span><br><span class="line">            slow=slow.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">            fast=fast.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> slow</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isPalindrome</span>(<span class="params">self, head: <span class="type">Optional</span>[ListNode]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line"></span><br><span class="line">        mid=<span class="variable language_">self</span>.middleNote(head)</span><br><span class="line"></span><br><span class="line">        reverse=<span class="variable language_">self</span>.reverseList(mid)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> reverse:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> head.val!=reverse.val:</span><br><span class="line"></span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            head=head.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">            reverse=reverse.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250802015304836.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
&lt;h2</summary>
        
      
    
    
    
    <category term="Leetcode" scheme="https://jayli19707.github.io/categories/Leetcode/"/>
    
    
  </entry>
  
  <entry>
    <title>机器学习环境配置</title>
    <link href="https://jayli19707.github.io/2025/08/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    <id>https://jayli19707.github.io/2025/08/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</id>
    <published>2025-07-31T17:30:00.000Z</published>
    <updated>2025-07-31T17:55:54.428Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><p>【终极指南】吃透机器学习环境配置：从Conda、CUDA到Docker容器化<br>大家好！在机器学习的旅程中，一个稳定、可复现的环境是成功的基石。</p><h3 id="第一部分：核心理念——为何环境配置如此重要？"><a href="#第一部分：核心理念——为何环境配置如此重要？" class="headerlink" title="第一部分：核心理念——为何环境配置如此重要？"></a><strong>第一部分：核心理念——为何环境配置如此重要？</strong></h3><p>任何机器学习模型的运行，都离不开一个精确配置的环境 。一个好的环境配置实践，能为您带来以下核心优势：</p><ul><li><p><strong>隔离性</strong>：确保不同项目间的依赖库互不干扰，避免版本冲突 。</p></li><li><p><strong>可复现性</strong>：让您的代码在任何机器上都能得到相同的结果，这在学术研究和工业生产中至关重要 。</p></li><li><p><strong>易于迁移</strong>：方便地将整个工作环境打包、迁移，实现快速部署 。</p></li></ul><hr><h3 id="第二部分：入门必备——包管理工具-Conda-Pipenv"><a href="#第二部分：入门必备——包管理工具-Conda-Pipenv" class="headerlink" title="第二部分：入门必备——包管理工具 (Conda & Pipenv)"></a><strong>第二部分：入门必备——包管理工具 (Conda &amp; Pipenv)</strong></h3><p>包管理工具是环境配置的第一步，它们帮助我们创建独立的虚拟环境并管理项目所需的各种软件包。</p><h4 id="1-Conda"><a href="#1-Conda" class="headerlink" title="1. Conda"></a><strong>1. Conda</strong></h4><p>Conda是一个开源、跨平台的包和环境管理系统，功能强大且社区支持广泛 。</p><ul><li><p><strong>创建环境</strong>: <code>conda create -n test_env</code></p></li><li><p><strong>安装包 (以PyTorch为例)</strong>: <code>conda install -n test_env pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch</code></p></li><li><p><strong>激活与退出</strong>: <code>conda activate test_env</code> 和 <code>conda deactivate</code></p></li></ul><h4 id="2-Pipenv"><a href="#2-Pipenv" class="headerlink" title="2. Pipenv"></a><strong>2. Pipenv</strong></h4><p>Pipenv旨在将</p><p><code>pip</code>（包安装）和<code>virtualenv</code>（虚拟环境）的功能合二为一，让依赖管理更自动化 。</p><ul><li><p><strong>安装包</strong>: <code>pipenv install numpy torch</code></p></li><li><p><strong>激活与退出</strong>: <code>pipenv shell</code> 和 <code>Ctrl + D</code></p></li></ul><hr><h3 id="第三部分：进阶核心——深入理解GPU、驱动与CUDA"><a href="#第三部分：进阶核心——深入理解GPU、驱动与CUDA" class="headerlink" title="第三部分：进阶核心——深入理解GPU、驱动与CUDA"></a><strong>第三部分：进阶核心——深入理解GPU、驱动与CUDA</strong></h3><p>仅仅安装好软件包是不够的，要让代码在GPU上跑起来，我们必须理解硬件、驱动和CUDA之间的关系。</p><h4 id="Q1：NVIDIA驱动和CUDA有什么区别？"><a href="#Q1：NVIDIA驱动和CUDA有什么区别？" class="headerlink" title="Q1：NVIDIA驱动和CUDA有什么区别？"></a><strong>Q1：NVIDIA驱动和CUDA有什么区别？</strong></h4><p>这是一个非常关键的问题。简单来说，<strong>驱动是基础，CUDA是建立在该基础之上的应用开发平台</strong>。</p><ul><li><p><strong>NVIDIA驱动 (NVIDIA Driver)</strong>：它是连接操作系统和GPU硬件的“桥梁” 。没有驱动，您的电脑根本无法识别GPU 。驱动程序本身包含一个版本的CUDA API，称为</p><p>  <strong>驱动CUDA版本 (Driver CUDA Version)</strong>，您可以通过在终端运行<code>nvidia-smi</code>命令查看。这个版本代表了该驱动<strong>最高能够支持</strong>的CUDA功能 。</p></li><li><p><strong>CUDA运行时 (CUDA Runtime)</strong>：当我们说“为PyTorch安装CUDA”时，通常指的是安装<strong>CUDA运行时</strong> 。它是一个并行的计算平台和编程接口（API），允许像PyTorch这样的框架利用GPU强大的并行计算能力（如矩阵运算）来加速模型训练 。</p></li></ul><p><strong>最重要的兼容性法则</strong>：<strong>驱动的CUDA版本必须大于或等于运行时的CUDA版本</strong> 。例如，如果</p><p><code>nvidia-smi</code>显示CUDA版本是11.6，那么您为项目安装的运行时CUDA版本（如11.3）不能超过11.6 。</p><hr><h3 id="第四部分：高手之路——拥抱容器化-Docker"><a href="#第四部分：高手之路——拥抱容器化-Docker" class="headerlink" title="第四部分：高手之路——拥抱容器化 (Docker)"></a><strong>第四部分：高手之路——拥抱容器化 (Docker)</strong></h3><p>当环境变得异常复杂时（例如，需要在最新的GPU上运行依赖旧版CUDA的旧项目），容器化技术就成了我们的终极武器。</p><h4 id="Q2：虚拟机和容器有什么区别？我应该用哪个？"><a href="#Q2：虚拟机和容器有什么区别？我应该用哪个？" class="headerlink" title="Q2：虚拟机和容器有什么区别？我应该用哪个？"></a><strong>Q2：虚拟机和容器有什么区别？我应该用哪个？</strong></h4><ul><li><p><strong>虚拟机 (Virtual Machine, VM)</strong>：它虚拟化了<strong>整个操作系统</strong> 。就像在Windows上安装一个软件，运行一个完整的Linux系统。这使得它非常“重”，但隔离性极强 。</p></li><li><p><strong>容器 (Container)</strong>：它运行在<strong>同一个主机操作系统之上</strong>，共享系统内核 。它虚拟的不是操作系统，而是</p><p>  <strong>应用程序及其所有依赖项</strong>的运行环境。这使得容器非常“轻量”，启动极快 。</p></li></ul><p>对于机器学习开发，<strong>容器通常是更好的选择</strong>，因为它在提供了足够隔离性的同时，性能开销更小。</p><h4 id="Q3：为什么要使用容器？它解决了什么问题？"><a href="#Q3：为什么要使用容器？它解决了什么问题？" class="headerlink" title="Q3：为什么要使用容器？它解决了什么问题？"></a><strong>Q3：为什么要使用容器？它解决了什么问题？</strong></h4><p>使用容器的核心原因是为了<strong>解决环境的复杂性、可移植性和兼容性难题</strong>。</p><ol><li><p><strong>处理复杂依赖</strong>：当您需要特定版本的库（如cuDNN、NCCL）来进行分布式训练时，容器可以将这一切完美打包 。</p></li><li><p><strong>解决兼容性噩梦</strong>：您可以在容器里打包旧版的PyTorch和它依赖的旧版CUDA，然后在安装了最新驱动和GPU的机器上无缝运行 。</p></li><li><p><strong>行业标准</strong>：无论是工业界的Kubernetes还是学术界的Slurm，都广泛采用容器作为应用部署的标准单元 。</p></li></ol><h4 id="Q4：为什么文件推荐使用NVIDIA自己的容器？"><a href="#Q4：为什么文件推荐使用NVIDIA自己的容器？" class="headerlink" title="Q4：为什么文件推荐使用NVIDIA自己的容器？"></a><strong>Q4：为什么文件推荐使用NVIDIA自己的容器？</strong></h4><p>因为标准的Docker容器无法很好地适配GPU。如果在普通容器里使用GPU，会要求容器内的驱动版本必须和主机的驱动版本</p><p><strong>完全一致</strong>，这极大地破坏了容器的“可移植性” 。</p><p><strong>NVIDIA Docker是完美的解决方案</strong> 。</p><ul><li><p><strong>核心优势</strong>：您<strong>无需在容器内安装任何NVIDIA驱动</strong> 。NVIDIA Docker会自动将主机的驱动和GPU设备安全地映射到容器中。</p></li><li><p><strong>带来的好处</strong>：这让在容器中使用GPU变得极其简单，并且让您的容器镜像具有了真正的可移植性，可以在任何安装了NVIDIA Docker的机器上运行 。</p></li></ul><p><strong>使用NVIDIA Docker的流程</strong>：</p><ol><li><p>在主机上安装好NVIDIA驱动和NVIDIA Docker 。</p></li><li><p>从Docker Hub拉取官方预构建的镜像 (如</p><p> <code>docker pull pytorch/pytorch:1.9.1-cuda11.1-cudnn8-runtime</code>) 。</p></li><li><p>使用</p><p> <code>--gpus all</code> 参数启动容器，即可在容器内访问GPU 。</p></li></ol><hr><h3 id="最终总结"><a href="#最终总结" class="headerlink" title="最终总结"></a><strong>最终总结</strong></h3><ol><li><p><strong>驱动先行</strong>：无论采用何种方案，<strong>必须</strong>在主机上正确安装NVIDIA驱动 。</p></li><li><p><strong>版本兼容</strong>：牢记，运行时的CUDA版本不能高于驱动支持的CUDA版本 。</p></li><li><p><strong>拥抱容器</strong>：对于复杂的GPU环境，<strong>强烈推荐使用NVIDIA Docker</strong>。它能为您免去无数环境配置的烦恼，让您专注于算法和模型本身。</p></li></ol>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;p&gt;【终极指南】吃透机器学习环境配置：从Conda、CUDA到Docker容器化&lt;br&gt;大家好！在机器学习的旅程中，一个稳定、可复现的环境是成功的基石。&lt;/p&gt;
&lt;h3</summary>
        
      
    
    
    
    <category term="机器学习" scheme="https://jayli19707.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>Leetcode-206.反转链表</title>
    <link href="https://jayli19707.github.io/2025/07/31/Leetcode-206.%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/"/>
    <id>https://jayli19707.github.io/2025/07/31/Leetcode-206.%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/</id>
    <published>2025-07-31T15:30:00.000Z</published>
    <updated>2025-07-31T15:44:22.380Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250731234151006.png" alt="image.png"></p><ul><li><p><strong>思路概述</strong></p><ul><li><p>利用栈的 <strong>先进后出（LIFO）</strong> 特性，先顺序遍历链表，把所有节点压入栈；</p></li><li><p>弹出栈顶节点时正好是原链表的尾节点，依次连接即可得到反转链表。</p></li></ul></li><li><p><strong>具体步骤</strong></p><ol><li><p>初始化空栈 <code>st</code>；</p></li><li><p>遍历链表 <code>head</code>，将每个节点压入栈中；</p></li><li><p>栈顶弹出节点作为新链表头 <code>new_head</code>，并维护一个可移动尾指针 <code>cur</code>；</p></li><li><p>每次出栈一个节点：</p><ul><li><p>先断开该节点原来的 <code>next</code>（防止形成环）；</p></li><li><p>接在新链表尾部 <code>cur.next = node</code>；</p></li><li><p>移动尾指针 <code>cur = node</code>；</p></li></ul></li><li><p>循环结束后，<code>cur.next = None</code> 并返回 <code>new_head</code>。</p></li></ol></li></ul><p><strong>复杂度分析</strong></p><ul><li><p>时间复杂度：O(n)，遍历一次压栈，一次出栈；</p></li><li><p>空间复杂度：O(n)，栈存储了全部节点引用。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reverseList</span>(<span class="params">self, head: <span class="type">Optional</span>[ListNode]</span>) -&gt; <span class="type">Optional</span>[ListNode]:</span><br><span class="line">        p=head</span><br><span class="line">        st=[]</span><br><span class="line">        <span class="keyword">while</span> p!=<span class="literal">None</span>:</span><br><span class="line">            st.append(p)</span><br><span class="line">            p=p.<span class="built_in">next</span></span><br><span class="line">        dummy = ListNode(<span class="number">0</span>)</span><br><span class="line">        tail = dummy</span><br><span class="line">        <span class="keyword">while</span> st:</span><br><span class="line">            node=st.pop()</span><br><span class="line">            tail.<span class="built_in">next</span>=node</span><br><span class="line">            tail=node</span><br><span class="line">        tail.<span class="built_in">next</span> = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> dummy.<span class="built_in">next</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250731234151006.png&quot;</summary>
        
      
    
    
    
    <category term="Leetcode" scheme="https://jayli19707.github.io/categories/Leetcode/"/>
    
    
  </entry>
  
  <entry>
    <title>从函数到大模型</title>
    <link href="https://jayli19707.github.io/2025/07/31/%E4%BB%8E%E5%87%BD%E6%95%B0%E5%88%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    <id>https://jayli19707.github.io/2025/07/31/%E4%BB%8E%E5%87%BD%E6%95%B0%E5%88%B0%E5%A4%A7%E6%A8%A1%E5%9E%8B/</id>
    <published>2025-07-30T18:30:00.000Z</published>
    <updated>2025-07-30T18:18:24.318Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深度学习与人工智能的核心原理解析"><a href="#深度学习与人工智能的核心原理解析" class="headerlink" title="深度学习与人工智能的核心原理解析"></a>深度学习与人工智能的核心原理解析</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>人工智能的本质是什么？从早期的符号主义到现代的大规模神经网络，人工智能的发展经历了诸多变革。本文以一个函数为起点，带领读者逐步理解人工智能背后的核心思想，包括神经网络的构建、训练方法，及其在自然语言处理中的应用。通过深入浅出的讲解，你将掌握深度学习如何通过不断调整参数，实现对复杂现实世界的有效建模，为理解当下大模型技术打下坚实基础。</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>人工智能早期的思路是符号主义，试图用精确的函数描述世界的所有规律。然而，现实世界的复杂性远超人类编写明确函数的能力，例如图像识别中简单的“猫”与“母”的判别，对计算机来说却是难题。为此，人们转向连接主义，通过构造近似函数模型来处理复杂问题。这一思路催生了神经网络，通过层层非线性变换实现对复杂数据的拟合。训练神经网络的核心在于寻找最佳参数，使得模型输出与真实数据误差最小。随着技术进步，深度学习模型逐渐发展出多种结构以适应不同类型数据，如卷积神经网络（CNN）处理图像，循环神经网络（RNN）处理序列数据，进而到Transformer架引领的自然语言处理革命。</p><h2 id="主要观点"><a href="#主要观点" class="headerlink" title="主要观点"></a>主要观点</h2><h3 id="1-连接主义与函数拟合的基本思想"><a href="#1-连接主义与函数拟合的基本思想" class="headerlink" title="1. 连接主义与函数拟合的基本思想"></a>1. 连接主义与函数拟合的基本思想</h3><p><img src="https://oss.vidseekapp.com/video/screenshots/19a6ee53-b44c-459f-a61f-dcfb77b843ce/89.0.jpg"></p><p><img src="https://oss.vidseekapp.com/video/screenshots/19a6ee53-b44c-459f-a61f-dcfb77b843ce/120.0.jpg"></p><p>传统符号主义假设存在一个精确函数能描述现实中的所有规律，但面对诸如图像识别的复杂任务，这种方式难以实现。连接主义放弃寻找精确函数，采用“猜测”并反复调整参数的方式，通过近似函数来拟合数据。以简单的线性函数 ( y = wx + b ) 为例，通过不断调整参数 ( w ) 和 ( b )，使得线性模型尽可能拟合给定数据点。这种“猜与改”的方法体现了现代人工智能的核心思路。  </p><h3 id="2-神经网络：激活函数与非线性变换"><a href="#2-神经网络：激活函数与非线性变换" class="headerlink" title="2. 神经网络：激活函数与非线性变换"></a>2. 神经网络：激活函数与非线性变换</h3><p><img src="https://oss.vidseekapp.com/video/screenshots/19a6ee53-b44c-459f-a61f-dcfb77b843ce/229.0.jpg"></p><p><img src="https://oss.vidseekapp.com/video/screenshots/7da6e129-5593-43d1-9555-deb6e86a4a93/343.0.jpg"></p><p>仅用线性函数无法表达复杂关系，故引入激活函数（如平方、sin、指数函数）将线性组合转变为非线性函数。神经网络由输入层、隐藏层和输出层组成，每层包含多个神经元，层与层之间进行线性变换后套用激活函数，形成复杂的非线性映射。多层网络结构可理论上逼近任意连续函数。  </p><h3 id="3-损失函数与梯度下降：模型训练的数学基础"><a href="#3-损失函数与梯度下降：模型训练的数学基础" class="headerlink" title="3. 损失函数与梯度下降：模型训练的数学基础"></a>3. 损失函数与梯度下降：模型训练的数学基础</h3><p><img src="https://oss.vidseekapp.com/video/screenshots/7da6e129-5593-43d1-9555-deb6e86a4a93/551.0.jpg"></p><p><img src="https://oss.vidseekapp.com/video/screenshots/7da6e129-5593-43d1-9555-deb6e86a4a93/812.0.jpg"></p><p>训练神经网络的目标是最小化损失函数，常用的均方误差（MSE）衡量预测值与真实值的差距。通过计算损失函数相对于参数的偏导数（梯度），利用梯度下降法不断调整参数，使损失函数逐渐减小，模型拟合效果逐步提升。复杂神经网络的参数众多，直接求解解析解不可行，梯度下降结合链式法则（反向传播）实现高效训练。  </p><h3 id="4-网络结构进阶：从全连接层到卷积神经网络（CNN）"><a href="#4-网络结构进阶：从全连接层到卷积神经网络（CNN）" class="headerlink" title="4. 网络结构进阶：从全连接层到卷积神经网络（CNN）"></a>4. 网络结构进阶：从全连接层到卷积神经网络（CNN）</h3><p><img src="https://oss.vidseekapp.com/video/screenshots/a39af8d5-0881-43f5-8dbd-8a028272bda2/1739.0.jpg"></p><p><img src="https://oss.vidseekapp.com/video/screenshots/a39af8d5-0881-43f5-8dbd-8a028272bda2/1824.0.jpg"></p><p>全连接层中，每个神经元与上一层所有神经元连接，参数量庞大且难以保持输入数据的局部特征。卷积神经网络通过卷积核滑动窗口操作提取局部空间特征，大幅减少参数数量，同时保留图像的空间结构信息。卷积层与池化层交替使用，构成高效的图像识别网络。  </p><h3 id="5-自然语言处理中的词嵌入与循环神经网络（RNN）"><a href="#5-自然语言处理中的词嵌入与循环神经网络（RNN）" class="headerlink" title="5. 自然语言处理中的词嵌入与循环神经网络（RNN）"></a>5. 自然语言处理中的词嵌入与循环神经网络（RNN）</h3><p><img src="https://oss.vidseekapp.com/video/screenshots/a39af8d5-0881-43f5-8dbd-8a028272bda2/2174.0.jpg"></p><p><img src="https://oss.vidseekapp.com/video/screenshots/4b2216e5-fd82-4bb3-b617-310b255550db/2329.0.jpg"></p><p>自然语言的输入需先通过编码转换为计算机可识别的向量，词嵌入（embedding）通过训练获得，能反映词语间的语义相关性。经典神经网络无法处理词序信息，RNN引入隐藏状态，逐步传递序列信息，具备捕捉上下文的能力。尽管RNN存在长期依赖题，改进型模型如LSTM和GRU缓解了部分问题。  </p><h3 id="6-Transformer与注意力机制：自然语言处理的新纪元"><a href="#6-Transformer与注意力机制：自然语言处理的新纪元" class="headerlink" title="6. Transformer与注意力机制：自然语言处理的新纪元"></a>6. Transformer与注意力机制：自然语言处理的新纪元</h3><p><img src="https://oss.vidseekapp.com/video/screenshots/4b2216e5-fd82-4bb3-b617-310b255550db/2561.0.jpg"></p><p><img src="https://oss.vidseekapp.com/video/screenshots/4b2216e5-fd82-4bb3-b617-310b255550db/2792.0.jpg"></p><p>Transformer架构通过多头自注意力机制，打破RNN顺序计算限制，实现并行处理序列信息。词向量加上位置编码后，通过查询（Q）、键（K）、值（V）矩阵计算词间相关性权重动态聚合上下文信息。多头注意力允许模型从多视角学习词间关系，极大提升表达能力，是现代大模型如GPT系列的基础。  </p><h3 id="7-模型泛化与正则化：防止过拟合的策略"><a href="#7-模型泛化与正则化：防止过拟合的策略" class="headerlink" title="7. 模型泛化与正则化：防止过拟合的策略"></a>7. 模型泛化与正则化：防止过拟合的策略</h3><p><img src="https://oss.vidseekapp.com/video/screenshots/850b231e-d5c0-4332-88d8-99d023277b7d/1147.0.jpg"></p><p><img src="https://oss.vidseekapp.com/video/screenshots/850b231e-d5c0-4332-88d8-99d023277b7d/1258.0.jpg"></p><p>过拟合是模型在训练数据上表现优异但泛化能力差的现象。防止过拟合策略包括简化模型结构、增加训练数据、数据增强（如图像旋转、裁剪）、早停训练、以及正则化（L1、L2正则化）限制参数过大增长。此外，Dropout随机丢弃部分神经元训练，也是常用有效的方法。针对训练中梯度消失、梯度爆炸问题，还引入梯度裁剪、合理权重初始化、优化器改进等技术。  </p><h3 id="8-大模型生态与发展趋势"><a href="#8-大模型生态与发展趋势" class="headerlink" title="8. 大模型生态与发展趋势"></a>8. 大模型生态与发展趋势</h3><p>随着模型规模激增，训练成本高昂，模型压缩、蒸馏、稀疏化、优化微调方法层出不穷。同时，AI服务生态完善，包含硬件（GPU、TPU、NPU）、开发工具（PyTorch、TensorFlow、HuggingFace）、推理引擎以及智能体和工作流框架。大模型虽强，但仍面临边际收益递减，未来更多聚焦效率提升和多模态融合。开源与闭源模型并存，推动技术普及与创新。  </p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>理解人工智能的本质，即将复杂现实世界抽象为可调节函数的过程，是深入掌握度学习技术的关键。通过神经网络构建非线性函数模型，结合损失函数最小化和梯度下降训练方法，AI系统能够逐步逼近真实数据规律。不同网络结构（如CNN、RNN、Transformer）针对不同数据类型发挥优势，推动了图像识别与自然语言处理的飞跃发展。防止过拟合和提升训练效率的各种技巧，确保模型具备良好泛化能力。未来，模型规模与能力持续增长的同时，技术创新将更注重模型轻量化、多模态融合及应用生态建设。全面理解这些核心原理，不仅有助于领会现有AI技术的运行机制，也为未来AI的研究与应用奠定坚实基础。</p><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><p>笔记仅用于学习<br>本文内容总结自抖音视频 @飞天闪客：一小时从函数到transformer<br>[[<a href="https://www.douyin.com/root/search/%E9%A3%9E%E5%A4%A9%E9%97%AA%E5%AE%A21?modal_id=7529550345501035791&type=video%5D%5D">https://www.douyin.com/root/search/%E9%A3%9E%E5%A4%A9%E9%97%AA%E5%AE%A21?modal_id=7529550345501035791&amp;type=video]]</a></p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;深度学习与人工智能的核心原理解析&quot;&gt;&lt;a href=&quot;#深度学习与人工智能的核心原理解析&quot; class=&quot;headerlink&quot; title=&quot;深度学习与人工智能的核心原理解析&quot;&gt;&lt;/a&gt;深度学习与人工智能的核心原理解析&lt;/h1&gt;&lt;h2 id=&quot;引言&quot;&gt;&lt;a</summary>
        
      
    
    
    
    <category term="机器学习" scheme="https://jayli19707.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>LeetCode 160：相交链表</title>
    <link href="https://jayli19707.github.io/2025/07/30/LeetCode%20160%EF%BC%9A%E7%9B%B8%E4%BA%A4%E9%93%BE%E8%A1%A8/"/>
    <id>https://jayli19707.github.io/2025/07/30/LeetCode%20160%EF%BC%9A%E7%9B%B8%E4%BA%A4%E9%93%BE%E8%A1%A8/</id>
    <published>2025-07-30T15:30:00.000Z</published>
    <updated>2025-07-30T15:17:58.495Z</updated>
    
    <content type="html"><![CDATA[<p>先补充数组和动态数组的区别，再比较动态数组和链表的区别，最后讲解本题题解。</p><span id="more"></span><h1 id="数组和动态数组"><a href="#数组和动态数组" class="headerlink" title="数组和动态数组"></a>数组和动态数组</h1><h2 id="1-普通数组（静态数组，Static-Array）"><a href="#1-普通数组（静态数组，Static-Array）" class="headerlink" title="1. 普通数组（静态数组，Static Array）"></a>1. 普通数组（静态数组，Static Array）</h2><ul><li><p><strong>内存分配</strong>：一旦定义，大小固定（如 C 语言中的 <code>int arr[5]</code>）。</p></li><li><p><strong>缺点</strong>：如果满了就不能再加元素，想扩容必须手动申请新数组并复制数据。</p></li><li><p><strong>优点</strong>：结构简单，内存连续，访问下标 O(1)。</p></li></ul><hr><h2 id="2-动态数组（Dynamic-Array）"><a href="#2-动态数组（Dynamic-Array）" class="headerlink" title="2. 动态数组（Dynamic Array）"></a>2. 动态数组（Dynamic Array）</h2><ul><li><p><strong>内存分配</strong>：底层还是数组，但容量不足时会<strong>自动申请更大空间并复制元素</strong>，对用户是透明的。</p></li><li><p><strong>扩容策略</strong>：常见是扩容为当前容量的 1.5~2 倍，以减少频繁复制。</p></li><li><p><strong>典型实现</strong>：</p><ul><li><p>Python 的 <code>list</code></p></li><li><p>Java 的 <code>ArrayList</code></p></li><li><p>C++ 的 <code>std::vector</code></p></li></ul></li></ul><h1 id="动态数组（Dynamic-Array）和链表（Linked-List）"><a href="#动态数组（Dynamic-Array）和链表（Linked-List）" class="headerlink" title="动态数组（Dynamic Array）和链表（Linked List）"></a>动态数组（Dynamic Array）和链表（Linked List）</h1><p>两种典型的线性数据结构，它们在<strong>内存分配、访问方式、插入删除效率</strong>等方面有明显区别：</p><hr><h2 id="1-内存分配方式"><a href="#1-内存分配方式" class="headerlink" title="1. 内存分配方式"></a>1. 内存分配方式</h2><ul><li><p><strong>动态数组</strong>（如 Python 的 <code>list</code>）：</p><ul><li><p>在内存中分配一块<strong>连续的空间</strong>来存放元素。</p></li><li><p>如果容量不够，会一次性申请更大的空间（通常是扩容 1.5~2 倍），然后把旧数据拷贝过去。</p></li></ul></li><li><p><strong>链表</strong>：</p><ul><li><p>每个元素是一个<strong>节点</strong>，包含数据和指向下一个节点的指针（<code>next</code>）。</p></li><li><p>节点分散在内存中，通过指针链接，不要求连续内存。</p></li></ul></li></ul><hr><h2 id="2-元素访问效率"><a href="#2-元素访问效率" class="headerlink" title="2. 元素访问效率"></a>2. 元素访问效率</h2><ul><li><p><strong>动态数组</strong>：支持随机访问，<code>arr[i]</code> 时间复杂度 <strong>O(1)</strong>，因为可以直接通过偏移量定位。</p></li><li><p><strong>链表</strong>：只能从头节点开始依次遍历，查找第 <code>i</code> 个元素的时间复杂度 <strong>O(n)</strong>。</p></li></ul><hr><h2 id="3-插入与删除效率"><a href="#3-插入与删除效率" class="headerlink" title="3. 插入与删除效率"></a>3. 插入与删除效率</h2><ul><li><p><strong>动态数组</strong>：</p><ul><li><p>在尾部插入/删除：<strong>O(1)</strong>（摊销）</p></li><li><p>在中间插入/删除：<strong>O(n)</strong>，因为需要移动大量元素。</p></li></ul></li><li><p><strong>链表</strong>：</p><ul><li><p>已知节点的前驱节点时，插入/删除节点：<strong>O(1)</strong></p></li><li><p>但如果要先找到插入位置，查找过程是 <strong>O(n)</strong>。</p></li></ul></li></ul><hr><h2 id="4-空间利用率"><a href="#4-空间利用率" class="headerlink" title="4. 空间利用率"></a>4. 空间利用率</h2><ul><li><p><strong>动态数组</strong>：可能存在额外的预留空间（扩容时会浪费部分内存）。</p></li><li><p><strong>链表</strong>：每个节点需要额外的指针域，指针占用额外内存，尤其数据量小的时候浪费更明显。</p></li></ul><hr><h2 id="5-适用场景总结"><a href="#5-适用场景总结" class="headerlink" title="5. 适用场景总结"></a>5. 适用场景总结</h2><ul><li><p>如果<strong>访问多、随机读取多</strong>：用动态数组更高效（例如 Python 的 <code>list</code>）。</p></li><li><p>如果<strong>频繁插入删除</strong>，尤其在中间或两端：链表更适合（如 <code>collections.deque</code> 用的是双向链表+块结构）。</p></li></ul><hr><h3 id="直观对比表"><a href="#直观对比表" class="headerlink" title="直观对比表"></a>直观对比表</h3><table><thead><tr><th>特性</th><th>动态数组（Python list）</th><th>链表（Linked List）</th></tr></thead><tbody><tr><td>内存结构</td><td>连续内存</td><td>分散内存</td></tr><tr><td>随机访问效率</td><td>O(1)</td><td>O(n)</td></tr><tr><td>插入/删除效率</td><td>中间 O(n)，尾部 O(1)</td><td>已知节点 O(1)，查找 O(n)</td></tr><tr><td>空间开销</td><td>可能有预留空间</td><td>每个节点多一个指针</td></tr><tr><td>扩容成本</td><td>有扩容成本（复制数据）</td><td>无扩容成本</td></tr></tbody></table><hr><h1 id="LeetCode-160：相交链表"><a href="#LeetCode-160：相交链表" class="headerlink" title="LeetCode 160：相交链表"></a>LeetCode 160：相交链表</h1><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250730231251725.png" alt="image.png"></p><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>在单链表题里，传进来的两个“头节点”headA、headB 就分别代表两条链表：每个头节点是第一个实际节点的引用，你可以从它开始沿着 .next 指针一直走到结尾把整条链表遍历出来。相交判定是看节点是否同一对象（p is q），不是看 val 是否相等</p><h3 id="解题过程"><a href="#解题过程" class="headerlink" title="解题过程"></a>解题过程</h3><blockquote><p>把两个头节点headA，headB先赋值分别赋值给p，q，为了不改变头节点信息，当p的val和q的val不为null时，p走一步，q走一步，相同时返回，不相同一直遍历下去，A遍历完遍历B，B遍历完遍历A</p></blockquote><h3 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h3><ul><li><p>时间复杂度: O(m+n)O(m+n)O(m+n)</p></li><li><p>空间复杂度: O(1) O(1) O(1)</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;先补充数组和动态数组的区别，再比较动态数组和链表的区别，最后讲解本题题解。&lt;/p&gt;</summary>
    
    
    
    <category term="Leetcode" scheme="https://jayli19707.github.io/categories/Leetcode/"/>
    
    
  </entry>
  
  <entry>
    <title>Leetcode-.42接雨水</title>
    <link href="https://jayli19707.github.io/2025/07/24/Leetcode-.42%E6%8E%A5%E9%9B%A8%E6%B0%B4/"/>
    <id>https://jayli19707.github.io/2025/07/24/Leetcode-.42%E6%8E%A5%E9%9B%A8%E6%B0%B4/</id>
    <published>2025-07-24T11:30:00.000Z</published>
    <updated>2025-07-24T11:36:26.983Z</updated>
    
    <content type="html"><![CDATA[<p>动态规划，记录i数组前后缀的最大值</p><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250724191937062.png" alt="image.png"></p><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250724191714298.png" alt="image.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">trap</span>(<span class="params">self, height: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line"></span><br><span class="line">        n=<span class="built_in">len</span>(height)</span><br><span class="line"></span><br><span class="line">        pre_max=n*[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        pre_max[<span class="number">0</span>]=height[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n):</span><br><span class="line"></span><br><span class="line">            pre_max[i]=<span class="built_in">max</span>(pre_max[i-<span class="number">1</span>],height[i])</span><br><span class="line"></span><br><span class="line">        suf_max=[<span class="number">0</span>]*n</span><br><span class="line"></span><br><span class="line">        suf_max[-<span class="number">1</span>]=height[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span> (n-<span class="number">2</span>,-<span class="number">1</span>,-<span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">            suf_max[i]=<span class="built_in">max</span>(suf_max[i+<span class="number">1</span>],height[i])</span><br><span class="line"></span><br><span class="line">        ans=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> h,pre,suf <span class="keyword">in</span> <span class="built_in">zip</span>(height,pre_max,suf_max):</span><br><span class="line"></span><br><span class="line">            ans+=<span class="built_in">min</span>(pre,suf)-h</span><br><span class="line">  </span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure><ul><li><code>pre_max[i]</code>：表示<strong>从最左边到当前位置 <code>i</code></strong> 为止的最大柱子高度；<br>  <mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="50.464ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 22305.1 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(954,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(499,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mi" transform="translate(2123.8,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(2652.8,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(3224.8,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mi" transform="translate(3502.8,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(3847.8,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g><g data-mml-node="mo" transform="translate(4403.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(5459.4,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6337.4,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(6866.4,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(7438.4,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(7438.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(7827.4,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(8403.4,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(8869.4,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(9214.4,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(9691.4,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(10267.4,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(10628.4,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mn" transform="translate(10906.4,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mo" transform="translate(11406.4,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g><g data-mml-node="mo" transform="translate(11684.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(12129.1,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(12705.1,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(13171.1,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(13516.1,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(13993.1,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(14569.1,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(14930.1,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mn" transform="translate(15208.1,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(15708.1,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g><g data-mml-node="mo" transform="translate(15986.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(16430.7,0)"><path data-c="2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path></g><g data-mml-node="mo" transform="translate(17769.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(18214.1,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(18790.1,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(19256.1,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(19601.1,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(20078.1,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(20654.1,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(21015.1,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mi" transform="translate(21293.1,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(21638.1,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g><g data-mml-node="mo" transform="translate(21916.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></li><li><code>suf_max[i]</code>：表示<strong>从当前位置 <code>i</code> 到最右边</strong>的最大柱子高度；<br>  <mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="58.385ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 25806 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(469,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(1041,0)"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mi" transform="translate(2234.8,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(2763.8,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(3335.8,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mi" transform="translate(3613.8,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(3958.8,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g><g data-mml-node="mo" transform="translate(4514.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(5570.4,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6448.4,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(6977.4,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(7549.4,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mo" transform="translate(7549.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(7938.4,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(8514.4,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(8980.4,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(9325.4,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(9802.4,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(10378.4,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(10739.4,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mi" transform="translate(11017.4,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(11362.4,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g><g data-mml-node="mo" transform="translate(11640.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(12085.1,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(12661.1,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(13127.1,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(13472.1,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(13949.1,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(14525.1,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(14886.1,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mi" transform="translate(15164.1,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(15731.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(16731.5,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(17231.5,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g><g data-mml-node="mo" transform="translate(17509.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(17954.2,0)"><path data-c="2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path></g><g data-mml-node="mo" transform="translate(19292.8,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(19737.5,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(20313.5,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(20779.5,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(21124.5,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(21601.5,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mi" transform="translate(22177.5,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(22538.5,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mi" transform="translate(22816.5,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(23638.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(24639,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(25139,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g><g data-mml-node="mo" transform="translate(25417,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></li></ul><p>对于下标 i，下雨后水能到达的最大高度等于下标 i 两边的最大高度的最小值，下标 i 处能接的雨水量等于下标 i 处的水能到达的最大高度减去 height[i]。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;动态规划，记录i数组前后缀的最大值&lt;/p&gt;</summary>
    
    
    
    <category term="Leetcode" scheme="https://jayli19707.github.io/categories/Leetcode/"/>
    
    
  </entry>
  
  <entry>
    <title>梯度下降</title>
    <link href="https://jayli19707.github.io/2025/07/24/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    <id>https://jayli19707.github.io/2025/07/24/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/</id>
    <published>2025-07-24T06:30:00.000Z</published>
    <updated>2025-07-24T06:28:18.593Z</updated>
    
    <content type="html"><![CDATA[<p>Gradient Descent ，Stochastic Gradient Descent 和Adaptive Moment Estimation</p><span id="more"></span><h1 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h1><p>我们来<strong>一步一步推导前两轮（epoch）梯度下降更新过程</strong>，以你提供的代码为基础，展示每轮如何更新参数<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="2.049ex" height="1.97ex" role="img" focusable="false" viewBox="0 -705 905.6 870.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g></svg></mjx-container> ,<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.049ex" height="1.934ex" role="img" focusable="false" viewBox="0 -705 905.6 855"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container>​。我们使用如下训练集：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="43.127ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 19062.1 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(1129.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(2185.6,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mn" transform="translate(2463.6,0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(3463.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(3908.2,0)"><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(4908.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(5352.9,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(6852.9,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(7297.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(8797.6,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g><g data-mml-node="mi" transform="translate(9075.6,0)"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path></g><g data-mml-node="mo" transform="translate(10116.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(11172.1,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mn" transform="translate(11450.1,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(12950.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(13394.8,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(14894.8,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(15339.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(16839.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(17284.1,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(1000,0)"></path></g><g data-mml-node="mo" transform="translate(18784.1,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container><br>$$<br>初始化：</p><p>θ_0=0 \quad<br>θ_1​=0<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="0.036ex" height="0.036ex" role="img" focusable="false" viewBox="0 0 16 16"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"></g></g></svg></mjx-container>学习率: \quad η=0.0001$$</p><p>每个样本的损失函数为：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.666ex;" xmlns="http://www.w3.org/2000/svg" width="27.895ex" height="2.666ex" role="img" focusable="false" viewBox="0 -883.9 12329.5 1178.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(681,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(1070,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(1975.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(2420.2,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(3325.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3992.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(5048.3,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(5437.3,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(6565.1,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msub" transform="translate(7565.3,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="msub" transform="translate(8470.9,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(9639.4,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(10639.7,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="msup" transform="translate(11504,0)"><g data-mml-node="mo"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mn" transform="translate(422,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g></g></g></svg></mjx-container></p><p>对参数求导得：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.971ex;" xmlns="http://www.w3.org/2000/svg" width="42.686ex" height="5.074ex" role="img" focusable="false" viewBox="0 -1371.3 18867.2 2242.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtable"><g data-mml-node="mtr" transform="translate(0,-19.7)"><g data-mml-node="mtd"><g data-mml-node="mfrac"><g data-mml-node="mrow" transform="translate(332.3,676)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="msub" transform="translate(566,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g><rect width="1671.6" height="60" x="120" y="220"></rect></g></g><g data-mml-node="mtd" transform="translate(1911.6,0)"><g data-mml-node="mi"></g><g data-mml-node="mo" transform="translate(277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1333.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(1833.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(2222.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(3309.1,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(4309.3,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(5173.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mtext" transform="translate(5562.7,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mfrac" transform="translate(5812.7,0)"><g data-mml-node="mrow" transform="translate(332.3,676)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="msub" transform="translate(566,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><rect width="1671.6" height="60" x="120" y="220"></rect></g></g><g data-mml-node="mtd" transform="translate(11635.8,0)"><g data-mml-node="mi"></g><g data-mml-node="mo" transform="translate(277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1333.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(1833.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(2222.6,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(3309.1,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(4309.3,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(5173.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(5784.9,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="msub" transform="translate(6285.1,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></g></g></g></g></svg></mjx-container></p><p>GD:<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="46.21ex" height="2.262ex" role="img" focusable="false" viewBox="0 -705 20424.8 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(905.6,0)"><g data-mml-node="mo"><path data-c="200B" d=""></path></g></g><g data-mml-node="mo" transform="translate(1183.3,0)"><g data-mml-node="text"><path data-c="3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="text" transform="translate(278,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g></g><g data-mml-node="msub" transform="translate(2517.1,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(3422.7,0)"><g data-mml-node="mo"><path data-c="200B" d=""></path></g></g><g data-mml-node="mo" transform="translate(3644.9,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(4645.1,0)"><path data-c="1D702" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(5364.3,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(5864.6,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(6393.6,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="msub" transform="translate(6878.6,0)"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(510,-150) scale(0.707)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g></g><g data-mml-node="mi" transform="translate(7775.8,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(8226.8,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="msub" transform="translate(8755.8,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mn" transform="translate(553,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mstyle" transform="translate(9712.4,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msub" transform="translate(10712.4,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(11617.9,0)"><g data-mml-node="mo"><path data-c="200B" d=""></path></g></g><g data-mml-node="mo" transform="translate(11895.7,0)"><g data-mml-node="text"><path data-c="3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="text" transform="translate(278,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g></g><g data-mml-node="msub" transform="translate(13229.5,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(14135.1,0)"><g data-mml-node="mo"><path data-c="200B" d=""></path></g></g><g data-mml-node="mo" transform="translate(14357.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(15357.5,0)"><path data-c="1D702" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(16076.7,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(16576.9,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(17105.9,0)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="msub" transform="translate(17590.9,0)"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(510,-150) scale(0.707)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g></g><g data-mml-node="mi" transform="translate(18488.2,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(18939.2,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="msub" transform="translate(19468.2,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mn" transform="translate(553,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(20424.8,0)"><g data-mml-node="mo"><path data-c="200B" d=""></path></g></g></g></g></svg></mjx-container></p><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250724022935144.png" alt="image.png"><br><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250724022950999.png" alt="image.png"></p><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250724023009480.png" alt="image.png"><br><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250724023021821.png" alt="image.png"></p><h1 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h1><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250724033107477.png" alt="image.png"></p><p>SGD 省略了因子 2，直接用：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="35.632ex" height="2.398ex" role="img" focusable="false" viewBox="0 -810 15749.6 1060"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(477,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(928,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="msub" transform="translate(1457,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mn" transform="translate(553,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(2691.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(3747.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4136.1,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(4848.3,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(5848.6,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(6338.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mstyle" transform="translate(6727.6,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mi" transform="translate(7727.6,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(8204.6,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(8655.6,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="msub" transform="translate(9184.6,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mn" transform="translate(553,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(10418.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(11474.7,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(11863.7,0)"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(12575.9,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(13576.1,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(14066.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(14677.3,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(15177.6,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></svg></mjx-container></p><p>每个样本更新时立即使用该梯度进行参数调整：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.489ex;" xmlns="http://www.w3.org/2000/svg" width="39.467ex" height="2.084ex" role="img" focusable="false" viewBox="0 -705 17444.2 921"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(1183.3,0)"><path data-c="2190" d="M944 261T944 250T929 230H165Q167 228 182 216T211 189T244 152T277 96T303 25Q308 7 308 0Q308 -11 288 -11Q281 -11 278 -11T272 -7T267 2T263 21Q245 94 195 151T73 236Q58 242 55 247Q55 254 59 257T73 264Q121 283 158 314T215 375T247 434T264 480L267 497Q269 503 270 505T275 509T288 511Q308 511 308 500Q308 493 303 475Q293 438 278 406T246 352T215 315T185 287T165 270H929Q944 261 944 250Z"></path></g><g data-mml-node="msub" transform="translate(2461.1,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(3588.9,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(4589.1,0)"><path data-c="1D702" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(5308.3,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(5808.6,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(6285.6,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6736.6,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="msub" transform="translate(7265.6,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mn" transform="translate(553,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mstyle" transform="translate(8222.1,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="msub" transform="translate(9222.1,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(10405.4,0)"><path data-c="2190" d="M944 261T944 250T929 230H165Q167 228 182 216T211 189T244 152T277 96T303 25Q308 7 308 0Q308 -11 288 -11Q281 -11 278 -11T272 -7T267 2T263 21Q245 94 195 151T73 236Q58 242 55 247Q55 254 59 257T73 264Q121 283 158 314T215 375T247 434T264 480L267 497Q269 503 270 505T275 509T288 511Q308 511 308 500Q308 493 303 475Q293 438 278 406T246 352T215 315T185 287T165 270H929Q944 261 944 250Z"></path></g><g data-mml-node="msub" transform="translate(11683.2,0)"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mn" transform="translate(502,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(12811,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(13811.2,0)"><path data-c="1D702" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(14530.4,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(15030.7,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(15507.7,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(15958.7,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="msub" transform="translate(16487.7,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mn" transform="translate(553,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container></p><h1 id="Adaptive-Moment-Estimation"><a href="#Adaptive-Moment-Estimation" class="headerlink" title="Adaptive Moment Estimation"></a>Adaptive Moment Estimation</h1><p><strong>Adam = 动量 + 自适应学习率</strong></p><p>Adam 优化器非常聪明地将这两个想法结合了起来。它同时做了两件事：</p><ol><li>它像 <strong>Momentum</strong> 一样，计算梯度的<strong>一阶矩估计</strong>（就是梯度的平均值，可以理解为<strong>速度</strong>）。</li><li>它像 <strong>RMSProp</strong> 一样，计算梯度的<strong>二阶矩估计</strong>（就是梯度平方的平均值，可以理解为<strong>颠簸程度或速度的变化</strong>）。</li></ol><p>然后，它用这两个值来动态地、为每一个参数计算出独立的、最合适的更新步长。</p><p><strong>最终效果</strong>：Adam 这辆智能小车，<strong>既有方向感（动量），又能感知地形（自适应学习率）</strong>，所以它在绝大多数情况下都能又快又稳地找到山谷的最低点。</p><h1 id="Warm-Restarts-in-SGD-热重启"><a href="#Warm-Restarts-in-SGD-热重启" class="headerlink" title="Warm Restarts (in SGD) 热重启"></a>Warm Restarts (in SGD) 热重启</h1><p>这是一种<strong>学习率调整策略</strong>，全称是 Stochastic Gradient Descent with Warm Restarts (SGDR)。传统的学习率调整策略通常是单调递减的。而 Warm Restarts 策略则是<strong>周期性地“重启”学习率</strong>。</p><p>具体来说，学习率会从一个较高的初始值开始，按照一个预设的函数（如余弦函数）逐渐下降。当下降到最低点后，它会<strong>突然被重置回较高的初始值</strong>，然后开始下一轮的下降。这个过程就像在模型训练陷入一个局部最优点时，通过突然增大学习率来“踢它一脚”，帮助它<strong>跳出当前的局部最小值</strong>，去探索更广阔的参数空间，从而有机会找到一个更好的全局最优解。</p><h1 id="GA遗传算法"><a href="#GA遗传算法" class="headerlink" title="GA遗传算法"></a>GA遗传算法</h1><h3 id="场景：小偷的烦恼"><a href="#场景：小偷的烦恼" class="headerlink" title="场景：小偷的烦恼"></a>场景：小偷的烦恼</h3><p>想象一个小偷进入一个珠宝店，他有一个背包，<strong>最大承重是 10 公斤</strong>。店里有四件宝物，每件宝物的重量和价值如下：</p><table><thead><tr><th>宝物</th><th>重量 (kg)</th><th>价值 (元)</th></tr></thead><tbody><tr><td>A (钻石)</td><td>5</td><td>12</td></tr><tr><td>B (黄金)</td><td>4</td><td>10</td></tr><tr><td>C (画作)</td><td>3</td><td>8</td></tr><tr><td>D (花瓶)</td><td>2</td><td>5</td></tr></tbody></table><p><strong>目标：</strong> 小偷应该如何选择宝物放入背包，才能在<strong>不超过背包承重（10kg）<strong>的前提下，让</strong>总价值最高</strong>？</p><p>这个问题如果用暴力破解，需要计算 24=16 种组合。当宝物有几十件时，暴力破解就不可行了。这时，遗传算法就派上用场了。</p><hr><h3 id="遗传算法的解决步骤"><a href="#遗传算法的解决步骤" class="headerlink" title="遗传算法的解决步骤"></a>遗传算法的解决步骤</h3><h4 id="第1步：基因编码-Encoding"><a href="#第1步：基因编码-Encoding" class="headerlink" title="第1步：基因编码 (Encoding)"></a>第1步：基因编码 (Encoding)</h4><p>首先，我们需要把一个“解决方案”（即一种拿宝物的组合）表示成一串“基因”，也就是<strong>染色体 (Chromosome)</strong>。</p><p>最简单的方法是用一个长度为4的二进制字符串，每一位对应一件宝物。</p><ul><li><p><code>1</code> 代表“拿这件宝物”</p></li><li><p><code>0</code> 代表“不拿这件宝物”</p></li></ul><p><strong>例如：</strong></p><ul><li><p><strong><code>[1, 0, 1, 0]</code></strong> 代表：拿A(钻石)和C(画作)，不拿B和D。</p></li><li><p><strong><code>[0, 1, 1, 1]</code></strong> 代表：拿B(黄金)、C(画作)和D(花瓶)。</p></li></ul><h4 id="第2步：初始化种群-Initialization"><a href="#第2步：初始化种群-Initialization" class="headerlink" title="第2步：初始化种群 (Initialization)"></a>第2步：初始化种群 (Initialization)</h4><p>遗传算法不是从一个解开始，而是从一个<strong>种群 (Population)</strong> 开始。我们随机生成一组初始的染色体（解决方案）。假设我们随机生成了下面4个个体组成了我们的初始种群：</p><ul><li><p><strong>个体1</strong>: <code>[1, 1, 0, 0]</code></p></li><li><p><strong>个体2</strong>: <code>[0, 1, 1, 1]</code></p></li><li><p><strong>个体3</strong>: <code>[1, 0, 1, 0]</code></p></li><li><p><strong>个体4</strong>: <code>[0, 0, 1, 1]</code></p></li></ul><h4 id="第3步：适应度评估-Fitness-Evaluation"><a href="#第3步：适应度评估-Fitness-Evaluation" class="headerlink" title="第3步：适应度评估 (Fitness Evaluation)"></a>第3步：适应度评估 (Fitness Evaluation)</h4><p>现在，我们需要一个函数来评估每个个体（解决方案）的好坏，这就是<strong>适应度函数 (Fitness Function)</strong>。</p><p>在这个问题里，适应度就是所选宝物的总价值。但有一个关键规则：</p><p>如果总重量超过背包承重(10kg)，那么这个方案是无效的，适应度为 0。</p><p>我们来计算一下初始种群的适应度：</p><ul><li><p><strong>个体1 <code>[1,1,0,0]</code></strong>:</p><ul><li><p>重量: 5 + 4 = 9kg (≤ 10kg) -&gt; 有效</p></li><li><p>价值: 12 + 10 = 22</p></li><li><p><strong>适应度 = 22</strong></p></li></ul></li><li><p><strong>个体2 <code>[0,1,1,1]</code></strong>:</p><ul><li><p>重量: 4 + 3 + 2 = 9kg (≤ 10kg) -&gt; 有效</p></li><li><p>价值: 10 + 8 + 5 = 23</p></li><li><p><strong>适应度 = 23</strong></p></li></ul></li><li><p><strong>个体3 <code>[1,0,1,0]</code></strong>:</p><ul><li><p>重量: 5 + 3 = 8kg (≤ 10kg) -&gt; 有效</p></li><li><p>价值: 12 + 8 = 20</p></li><li><p><strong>适应度 = 20</strong></p></li></ul></li><li><p><strong>个体4 <code>[0,0,1,1]</code></strong>:</p><ul><li><p>重量: 3 + 2 = 5kg (≤ 10kg) -&gt; 有效</p></li><li><p>价值: 8 + 5 = 13</p></li><li><p><strong>适应度 = 13</strong></p></li></ul></li></ul><p>目前来看，<strong>个体2 <code>[0,1,1,1]</code> 是当前种群中最好的解决方案</strong>。</p><h4 id="第4步：选择-Selection"><a href="#第4步：选择-Selection" class="headerlink" title="第4步：选择 (Selection)"></a>第4步：选择 (Selection)</h4><p>遵循“优胜劣汰”的自然法则，适应度越高的个体，越有可能被选中作为“父母”来繁衍下一代。</p><p>常见的选择方法是<strong>轮盘赌选择法</strong>。想象一个轮盘，每个个体的扇区大小与它的适应度成正比。适应度为23的个体2，扇区最大，最容易被指针选到。</p><p>假设经过选择，我们选中了<strong>个体2</strong>和<strong>个体1</strong>作为父母进行繁殖。</p><h4 id="第5步：交叉-Crossover"><a href="#第5步：交叉-Crossover" class="headerlink" title="第5步：交叉 (Crossover)"></a>第5步：交叉 (Crossover)</h4><p>交叉是模拟生物繁殖，父母双方交换部分基因，产生全新的后代。</p><p>我们随机选择一个交叉点，比如在第2位基因后面。然后将两个父代染色体的后半部分进行交换。</p><ul><li><p><strong>父代1</strong>: <code>[0, 1 | 1, 1]</code> (来自个体2)</p></li><li><p><strong>父代2</strong>: <code>[1, 1 | 0, 0]</code> (来自个体1)</p></li></ul><p>交换<code>|</code>后面的部分，产生两个新的子代：</p><ul><li><p><strong>子代1</strong>: <code>[0, 1, 0, 0]</code></p></li><li><p><strong>子代2</strong>: <code>[1, 1, 1, 1]</code></p></li></ul><h4 id="第6步：变异-Mutation"><a href="#第6步：变异-Mutation" class="headerlink" title="第6步：变异 (Mutation)"></a>第6步：变异 (Mutation)</h4><p>为了防止算法陷入局部最优（比如所有个体都长得差不多），我们需要引入<strong>变异</strong>，以一个很小的概率随机改变基因。</p><p>比如，我们对<strong>子代1</strong>进行变异：</p><ul><li><p>变异前: <code>[0, 1, 0, 0]</code></p></li><li><p>随机选择第4位进行变异（0 -&gt; 1）</p></li><li><p><strong>变异后</strong>: <code>[0, 1, 0, 1]</code></p></li></ul><p>这个变异后的新个体 <code>[0,1,0,1]</code> 代表拿B和D，总重6kg，价值15，这是一个全新的、可能不错的解决方案！</p><h4 id="第7步：新一代与循环"><a href="#第7步：新一代与循环" class="headerlink" title="第7步：新一代与循环"></a>第7步：新一代与循环</h4><p>通过交叉和变异产生的新个体（子代）将组成<strong>新一代的种群</strong>。然后，算法回到<strong>第3步（适应度评估）</strong>，对新种群进行评估，然后再次进行选择、交叉、变异。</p><p>这个过程周而复始，一代又一代地“进化”。</p><hr><h3 id="最终结果"><a href="#最终结果" class="headerlink" title="最终结果"></a>最终结果</h3><p>经过很多代的进化后，种群中适应度最高的个体将趋于稳定。最终，算法可能会收敛到 <code>[0,1,1,1]</code> (价值23) 或者 <code>[1,1,0,0]</code> (价值22) 或者其他更好的解。在这个简单例子里，最优解就是 <code>[0,1,1,1]</code>，总价值23。遗传算法通过模仿进化，很有可能找到这个最优解。</p><h1 id="AHP和TOPSIS"><a href="#AHP和TOPSIS" class="headerlink" title="AHP和TOPSIS"></a>AHP和TOPSIS</h1><ul><li><strong>AHP 是基于人的主观判断</strong>，核心在于“<strong>比较重要性</strong>”，强调<strong>结构化思考 + 权重提取</strong>；</li><li><strong>TOPSIS 是基于数据的客观距离计算</strong>，核心在于“<strong>谁更接近理想</strong>”，强调<strong>最优解的几何逼近</strong>。</li></ul><table><thead><tr><th>维度</th><th>AHP（层次分析法）</th><th>TOPSIS（理想解法）</th></tr></thead><tbody><tr><td><strong>输入依赖</strong></td><td>依赖<strong>专家主观判断</strong>（两两比较）</td><td>依赖<strong>方案原始数据矩阵</strong>（如成本、评分等）</td></tr><tr><td><strong>核心思想</strong></td><td>通过成对比较提取每个准则的重要性权重</td><td>选出离正理想解最近、离负理想解最远的方案</td></tr><tr><td><strong>数学依据</strong></td><td>特征值理论（判断矩阵的主特征向量）</td><td>欧几里得距离（几何空间距离）</td></tr><tr><td><strong>输出结果</strong></td><td>准则权重、方案得分</td><td>方案的贴近度 Ci，排序</td></tr><tr><td><strong>数据需求</strong></td><td>需要构建判断矩阵，规模太大效率低</td><td>只需标准化原始数据，不需要主观比较</td></tr><tr><td><strong>一致性检验</strong></td><td>需进行一致性比率 CR 检验</td><td>不需要一致性检验</td></tr><tr><td><strong>适用场景</strong></td><td>人工可比主观偏好强的情境（战略、政策等）</td><td>有客观指标、数据齐全，需数值化评估的情境（选产品）</td></tr><tr><td><strong>优点</strong></td><td>可量化主观偏好，结构清晰</td><td>简单直观、计算快速，适用性广</td></tr><tr><td><strong>缺点</strong></td><td>主观性强，维度多时构建判断矩阵困难</td><td>忽略指标之间可能的权重差异或相关性</td></tr></tbody></table><p>TOPSIS（原始决策矩阵+每个指标的权重）<br>返回参数的排序</p><table><thead><tr><th>方案</th><th>价格（万元）</th><th>性能（分）</th><th>重量（kg）</th><th>续航（小时）</th></tr></thead><tbody><tr><td>A</td><td>5</td><td>80</td><td>1.5</td><td>8</td></tr><tr><td>B</td><td>6</td><td>90</td><td>1.2</td><td>10</td></tr><tr><td>C</td><td>4.5</td><td>70</td><td>1.8</td><td>6</td></tr><tr><td>这反映了决策者对各个指标“重要程度”的主观或客观判断：</td><td></td><td></td><td></td><td></td></tr></tbody></table><p>权重向量 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="19.924ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 8806.6 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mo" transform="translate(993.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(2049.6,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="msub" transform="translate(2327.6,0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mn" transform="translate(749,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(3480.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(3924.8,0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mn" transform="translate(749,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(5077.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(5522,0)"><path data-c="2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path></g><g data-mml-node="mo" transform="translate(6860.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(7305.3,0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mi" transform="translate(749,-150) scale(0.707)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(8528.6,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container>, <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="9.274ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 4099.2 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="msub" transform="translate(1222.7,0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mi" transform="translate(749,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(2265.6,0)"><g data-mml-node="mo"><path data-c="200B" d=""></path></g></g><g data-mml-node="mo" transform="translate(2543.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(3599.2,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container></p><p>比如：</p><ul><li>价格 0.3（越低越好）</li><li>性能 0.4（越高越好）</li><li>重量 0.1（越低越好）</li><li>续航 0.2（越高越好）</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;Gradient Descent ，Stochastic Gradient Descent 和Adaptive Moment Estimation&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://jayli19707.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="梯度下降" scheme="https://jayli19707.github.io/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode-15. 三数之和</title>
    <link href="https://jayli19707.github.io/2025/07/23/Leetcode-15.%20%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C/"/>
    <id>https://jayli19707.github.io/2025/07/23/Leetcode-15.%20%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C/</id>
    <published>2025-07-23T09:30:00.000Z</published>
    <updated>2025-07-23T09:50:53.439Z</updated>
    
    <content type="html"><![CDATA[<p>排序 + 双指针<br>本题的难点在于如何去除重复解</p><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250723173647918.png" alt="image.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">threeSum</span>(<span class="params">self,nums</span>):</span><br><span class="line"></span><br><span class="line">        nums.sort()</span><br><span class="line"></span><br><span class="line">        a=[]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)-<span class="number">2</span>):</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> nums[k]==nums[k-<span class="number">1</span>] <span class="keyword">and</span> k&gt;<span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            i=k+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">            j=<span class="built_in">len</span>(nums)-<span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> i&lt;j:</span><br><span class="line"></span><br><span class="line">                left=nums[i]</span><br><span class="line"></span><br><span class="line">                right=nums[j]</span><br><span class="line"></span><br><span class="line">                total=nums[k]+left+right</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> total==<span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">                    a.append([nums[k],nums[i],nums[j]])</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">while</span> i&lt;j <span class="keyword">and</span> nums[i]==nums[i+<span class="number">1</span>]:</span><br><span class="line"></span><br><span class="line">                        i+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">                    <span class="keyword">while</span> i&lt;j <span class="keyword">and</span> nums[j]==nums[j-<span class="number">1</span>]:</span><br><span class="line"></span><br><span class="line">                        j-=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">                    i+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">                    j-=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> total&lt;<span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">                    i+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">                    j-=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> a</span><br></pre></td></tr></table></figure><p>特判，对于数组长度 n，如果数组为 null 或者数组长度小于 3，返回 []。</p><p>对数组进行排序。<br>遍历排序后数组：<br>若 nums[i]&gt;0：因为已经排序好，所以后面不可能有三个数加和等于 0，直接返回结果。</p><p>对于重复元素：跳过，避免出现重复解<br>令左指针 L=i+1，右指针 R=n−1，当 L&lt;R 时，执行循环：<br>当 nums[i]+nums[L]+nums[R]== 0</p><p>执行循环，判断左界和右界是否和下一位置重复，去除重复解。<br>(这一步最细，因为同一个num[i]可以配不同的num[L],num[R],即使一开始有total=0，后续也可以有一对，所以这里还有去重和检查一遍)</p><p>并同时将 L,R 移到下一位置，寻找新的解<br>若和大于 0，说明 nums[R] 太大，R 左移<br>若和小于 0，说明 nums[L] 太小，L 右移</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;排序 + 双指针&lt;br&gt;本题的难点在于如何去除重复解&lt;/p&gt;</summary>
    
    
    
    <category term="Leetcode" scheme="https://jayli19707.github.io/categories/Leetcode/"/>
    
    
  </entry>
  
  <entry>
    <title>Leetcode-11.盛最多水的容器</title>
    <link href="https://jayli19707.github.io/2025/07/22/Leetcode-11.%E7%9B%9B%E6%9C%80%E5%A4%9A%E6%B0%B4%E7%9A%84%E5%AE%B9%E5%99%A8/"/>
    <id>https://jayli19707.github.io/2025/07/22/Leetcode-11.%E7%9B%9B%E6%9C%80%E5%A4%9A%E6%B0%B4%E7%9A%84%E5%AE%B9%E5%99%A8/</id>
    <published>2025-07-22T13:30:00.000Z</published>
    <updated>2025-07-22T13:34:40.412Z</updated>
    
    <content type="html"><![CDATA[<p>本题采用双指针来解决<br>矩阵的面积与两个因素有关：<br>矩阵的长度：两条垂直线的距离<br>矩阵的宽度：两条垂直线其中较短一条的长度<br>因此，要矩阵面积最大化，两条垂直线的距离越远越好，两条垂直线的最短长度也要越长越好。</p><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250722192326067.png" alt="image.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maxArea</span>(<span class="params">self, height: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line"></span><br><span class="line">        i=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">        j=<span class="built_in">len</span>(height)-<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        maxvolume=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> i &lt; j:</span><br><span class="line"></span><br><span class="line">            left = height[i]</span><br><span class="line"></span><br><span class="line">            right= height[j]</span><br><span class="line"></span><br><span class="line">            L=j-i</span><br><span class="line"></span><br><span class="line">            currentvolume=<span class="built_in">min</span>(left,right)*L</span><br><span class="line">  </span><br><span class="line">            <span class="keyword">if</span> maxvolume&lt;currentvolume:</span><br><span class="line"></span><br><span class="line">                maxvolume=currentvolume</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> left&lt;right:</span><br><span class="line"></span><br><span class="line">                i+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">                j-=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> maxvolume</span><br></pre></td></tr></table></figure><p>在每个状态下，无论长板或短板向中间收窄一格，都会导致水槽 底边宽度 −1​ 变短：</p><p>若向内 移动短板 ，水槽的短板 min(h[i],h[j]) 可能变大，因此下个水槽的面积 可能增大 。<br>若向内 移动长板 ，水槽的短板 min(h[i],h[j])​ 不变或变小，因此下个水槽的面积 一定变小 。</p><p>因此，初始化双指针分列水槽左右两端，循环每轮将短板向内移动一格，并更新面积最大值，直到两指针相遇时跳出；即可获得最大面积。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本题采用双指针来解决&lt;br&gt;矩阵的面积与两个因素有关：&lt;br&gt;矩阵的长度：两条垂直线的距离&lt;br&gt;矩阵的宽度：两条垂直线其中较短一条的长度&lt;br&gt;因此，要矩阵面积最大化，两条垂直线的距离越远越好，两条垂直线的最短长度也要越长越好。&lt;/p&gt;</summary>
    
    
    
    <category term="Leetcode" scheme="https://jayli19707.github.io/categories/Leetcode/"/>
    
    
  </entry>
  
  <entry>
    <title>深度学习-超越线性，迈向深度</title>
    <link href="https://jayli19707.github.io/2025/07/22/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E8%B6%85%E8%B6%8A%E7%BA%BF%E6%80%A7%EF%BC%8C%E8%BF%88%E5%90%91%E6%B7%B1%E5%BA%A6/"/>
    <id>https://jayli19707.github.io/2025/07/22/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E8%B6%85%E8%B6%8A%E7%BA%BF%E6%80%A7%EF%BC%8C%E8%BF%88%E5%90%91%E6%B7%B1%E5%BA%A6/</id>
    <published>2025-07-21T17:30:00.000Z</published>
    <updated>2025-07-21T17:06:16.093Z</updated>
    
    <content type="html"><![CDATA[<p>我们了解了机器学习的基本三部曲。然而，简单的线性模型在面对复杂现实世界问题时，往往会显得力不从心。我们将打破线性模型的局限，正式迈向更强大、更灵活的“深度学习”世界。</p><span id="more"></span><h2 id="线性模型的“偏见”-Model-Bias"><a href="#线性模型的“偏见”-Model-Bias" class="headerlink" title="线性模型的“偏见” (Model Bias)"></a><strong>线性模型的“偏见” (Model Bias)</strong></h2><p>线性模型的根本问题：<strong>模型偏见（Model Bias）</strong>。<br><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250717153412613.png" alt="image.png"></p><ul><li><p><strong>核心概念</strong>：线性模型本身的结构过于简单，它假设输入和输出之间是纯粹的线性关系。这导致它无法捕捉现实世界中普遍存在的非线性规律。例如，YouTube的观看人数可能并不会一直线性增长，而是会呈现复杂的周期性波动。</p></li><li><p><strong>重要区分</strong>：这里的“Model Bias”指的是模型本身的限制，与我们之前提到的作为模型参数的“bias”（偏置项 <code>b</code>）是两个不同的概念。</p></li><li><p><strong>解决方案</strong>：要解决这个问题，我们必须构建一个更复杂、更有弹性的函数模型。</p></li></ul><h2 id="如何构建更复杂的函数？"><a href="#如何构建更复杂的函数？" class="headerlink" title="如何构建更复杂的函数？"></a><strong>如何构建更复杂的函数？</strong></h2><p>用一个非常直观的方式，为我们揭示了构建复杂函数的秘诀：<br><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250717154512334.png" alt="image.png"></p><ol><li><p><strong>分段线性曲线 (Piecewise Linear Curves)</strong>：任何复杂的连续曲线，都可以通过足够多的微小线段来逼近。</p></li><li><p><strong>“蓝色函数” (Hard Sigmoid)</strong>：这些微小的线段，可以由一种阶梯状的函数（视频中称为“蓝色函数”）来组合而成。</p></li><li><p><strong>Sigmoid 函数</strong>：在数学上，我们可以用一个更平滑、更易于处理的函数——<strong>Sigmoid 函数</strong>——来近似这个“蓝色函数”。</p></li></ol><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250721190158409.png" alt="image.png"></p><p>通过调整 Sigmoid 函数的参数（<code>w</code>, <code>b</code>, <code>c</code>），我们可以改变它的形状、位置和高度，从而组合出任意复杂的曲线，以此来逼近我们想要的目标函数。<br><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250721191635975.png" alt="image.png"></p><h2 id="linear-model到Curve："><a href="#linear-model到Curve：" class="headerlink" title="linear model到Curve："></a>linear model到Curve：</h2><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250721192153451.png" alt="image.png"></p><h3 id="多个features"><a href="#多个features" class="headerlink" title="多个features"></a>多个features</h3><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250721192655480.png" alt="image.png"></p><h3 id="线性代数表示"><a href="#线性代数表示" class="headerlink" title="线性代数表示"></a>线性代数表示</h3><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250721193816301.png" alt="image.png"></p><h2 id="从单个特征到多个特征：神经网络的雏形"><a href="#从单个特征到多个特征：神经网络的雏形" class="headerlink" title="从单个特征到多个特征：神经网络的雏形"></a><strong>从单个特征到多个特征：神经网络的雏形</strong></h2><p>当我们的输入不再是单一的“前一天观看人数”，而是包含前7天、前28天等多个特征（features）时，模型也需要相应地升级。</p><ul><li><p><strong>模型结构</strong>：</p><ol><li><p><strong>输入层 (Input Layer)</strong>：接收所有的输入特征 <code>x</code>。</p></li><li><p><strong>隐藏层 (Hidden Layer)</strong>：每个 Sigmoid 函数（现在被称为“神经元” Neuron）接收所有输入特征的加权和，并经过激活函数（Sigmoid）处理，得到一个激活值 <code>a</code>。</p></li><li><p><strong>输出层 (Output Layer)</strong>：将所有隐藏层神经元的输出 <code>a</code> 进行加权求和，最终得到预测结果 <code>y</code>。</p></li></ol></li><li><p><strong>数学表示</strong>：这个过程可以通过矩阵和向量运算高效地完成，所有的未知参数（权重 <code>w</code> 和偏置 <code>b</code>）可以被整合到一个大的参数向量 <code>θ</code> 中。</p></li></ul><h2 id="训练神经网络：同样的配方，更强的模型"><a href="#训练神经网络：同样的配方，更强的模型" class="headerlink" title="训练神经网络：同样的配方，更强的模型"></a><strong>训练神经网络：同样的配方，更强的模型</strong></h2><p>尽管模型变得复杂了，但训练它的核心思想依然是我们熟悉的老朋友：</p><ol><li><p><strong>损失函数 (Loss Function)</strong>：和之前一样，我们定义一个损失函数 <code>L(θ)</code> 来衡量模型预测值与真实值之间的差距。</p></li><li><p><strong>优化 (Optimization)</strong>：我们依然使用<strong>梯度下降 (Gradient Descent)</strong> 算法来寻找使损失最小化的最佳参数 <code>θ</code>。通过计算损失函数对每一个参数的偏导数（梯度），来指导参数的更新方向。</p></li></ol><h2 id="训练中的实用技巧"><a href="#训练中的实用技巧" class="headerlink" title="训练中的实用技巧"></a><strong>训练中的实用技巧</strong></h2><ul><li><p><strong>Batch 与 Epoch</strong>：在实际训练中，我们通常不会一次性将所有数据都用于计算梯度。而是将数据分成一小批一小批（<strong>Batch</strong>），每次只用一个 Batch 的数据来更新一次参数。当所有 Batch 的数据都被使用过一次后，就完成了一个<strong>Epoch</strong>。</p></li><li><p><strong>激活函数 (Activation Function)</strong>：除了 Sigmoid，<strong>ReLU (Rectified Linear Unit)</strong> 是另一个非常流行且有效的激活函数。它的形式更简单 <code>max(0, x)</code>，并且在实践中往往能取得更好的效果。</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250722004434083.png" alt="image.png"></p><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250722004518575.png" alt="image.png"></p><h2 id="深度学习-Deep-Learning-的诞生"><a href="#深度学习-Deep-Learning-的诞生" class="headerlink" title="深度学习 (Deep Learning) 的诞生"></a><strong>深度学习 (Deep Learning) 的诞生</strong></h2><ul><li><strong>“深度”的含义</strong>：当我们将多个隐藏层堆叠在一起时，就构成了“深度”神经网络。这就是**深度学习（Deep Learning）**名字的由来。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250722005232139.png" alt="image.png"></p><p>层数：2<br>参数更多了：b和b‘，w和w’均是不同的参数<br>Neuron：sigmoid和ReLu</p><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250722005745940.png" alt="image.png"></p><ul><li><strong>过拟合 (Overfitting)</strong>：实验结果显示，增加模型的深度（层数）和宽度（每层的神经元数量）可以降低在训练数据上的损失。但并非越深越好，过深的网络可能会导致<strong>过拟合</strong>——即模型在训练数据上表现完美，但在未见过的测试数据上表现很差。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250722010105949.png" alt="image.png"></p><ul><li><strong>核心问题</strong>：为什么我们需要“深”而不是仅仅“宽”？课程最后留下了这个引人深思的问题，也为后续更深入的探讨埋下了伏笔。</li></ul><h2 id="总结与复习要点"><a href="#总结与复习要点" class="headerlink" title="总结与复习要点"></a><strong>总结与复习要点</strong></h2><p>本节课我们完成了从线性模型到非线性模型，再到深度神经网络的认知飞跃。</p><ul><li><p><strong>核心痛点</strong>：线性模型的“模型偏见”使其无法处理复杂任务。</p></li><li><p><strong>核心思想</strong>：通过 Sigmoid 或 ReLU 等激活函数，我们可以构建出能够逼近任意复杂函数的神经网络。</p></li><li><p><strong>核心挑战</strong>：模型变得强大的同时，也带来了新的问题，如“过拟合”。如何在模型复杂度和泛化能力之间找到平衡，是深度学习中的一个永恒主题。</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;我们了解了机器学习的基本三部曲。然而，简单的线性模型在面对复杂现实世界问题时，往往会显得力不从心。我们将打破线性模型的局限，正式迈向更强大、更灵活的“深度学习”世界。&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://jayli19707.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>Leetcode-.283移动零</title>
    <link href="https://jayli19707.github.io/2025/07/19/Leetcode-.283%E7%A7%BB%E5%8A%A8%E9%9B%B6/"/>
    <id>https://jayli19707.github.io/2025/07/19/Leetcode-.283%E7%A7%BB%E5%8A%A8%E9%9B%B6/</id>
    <published>2025-07-18T19:30:00.000Z</published>
    <updated>2025-07-18T19:26:38.762Z</updated>
    
    <content type="html"><![CDATA[<p>本题采用双指针来解决</p><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/JAYLI19707/blog-pic@master/20250719031815486.png" alt="image.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">moveZeroes</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Do not return anything, modify nums in-place instead.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        pos=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> nums[i]!=<span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">                nums[pos],nums[i]=nums[i],nums[pos]</span><br><span class="line"></span><br><span class="line">                pos+=<span class="number">1</span></span><br></pre></td></tr></table></figure><p>本题运用双指针来写：一个指针用来遍历数组，一个用来记录“有效位”索引，如果遍历的时候发现元素不是0，立马就可以跟有效位置索引的数组进行交换，</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本题采用双指针来解决&lt;/p&gt;</summary>
    
    
    
    <category term="Leetcode" scheme="https://jayli19707.github.io/categories/Leetcode/"/>
    
    
  </entry>
  
</feed>
